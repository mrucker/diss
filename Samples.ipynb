{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28c953ae-f88c-4540-9026-14c519217a73",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch parameterfree pandas numpy scikit-learn matplotlib cloudpickle --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7177a09b-695a-4b98-9985-25e1820efa3d",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100e429e-68d1-4b58-9872-613f60e9ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sims_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca454801-d134-4cb9-b6d4-66b1c707b62f",
   "metadata": {},
   "source": [
    "### Utility Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a5baa3-5a82-490e-82a6-2c836165be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pow2(i):\n",
    "    return i & (i-1) == 0\n",
    "\n",
    "class OnlineMean:\n",
    "    def __init__(self):\n",
    "        self.state = [0,0]\n",
    "    def add(self, num):\n",
    "        n,v = self.state\n",
    "        self.state[1] += (num-v)/(n+1)\n",
    "        self.state[0] += 1\n",
    "    def __str__(self):\n",
    "        return str(round(self.state[1],4))\n",
    "    def __repr__(self):\n",
    "        return str(round(self.state[1],4))\n",
    "\n",
    "def plot_results(args,xlabel=None,ylabel='AUC',llabel=None):\n",
    "    from operator import itemgetter\n",
    "    from itertools import groupby\n",
    "    from matplotlib import pyplot as plt\n",
    "    \n",
    "    args = sorted(args)\n",
    "    \n",
    "    if len(args[0]) == 3:\n",
    "        for lbl, group in groupby(args,key=itemgetter(0)):\n",
    "            x,y = zip(*[g[1:] for g in group])\n",
    "            plt.plot(x,y,label=lbl)\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(title=llabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c84e7-87f6-4083-8e32-571909a00108",
   "metadata": {},
   "source": [
    "### Helpful Sources about Architectures\n",
    "\n",
    "+ If normalizing do it before activation https://forums.fast.ai/t/why-perform-batch-norm-before-relu-and-not-after/81293/4\n",
    "+ What are residual networks https://arxiv.org/pdf/1512.03385.pdf\n",
    "+ When building residual networks use pre-activation https://arxiv.org/abs/1603.05027\n",
    "+ There is not one universal best normalization method https://proceedings.neurips.cc/paper/2021/hash/2578eb9cdf020730f77793e8b58e165a-Abstract.html\n",
    "+ Adam is the standard optimizer but takes a lot of tuning. COCOB tunes automatically https://github.com/bremen79/parameterfree\n",
    "+ Smaller batches tend to be better? (this seems to be with fixed epochs though so may not relevant) https://arxiv.org/pdf/1804.07612.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce3d4ac-5672-46fe-b3ba-84c2b3f491ad",
   "metadata": {},
   "source": [
    "### Basic Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "694dfb94-56d9-43ac-a718-217ebb37b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import torch\n",
    "\n",
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, norm='l'):\n",
    "        super().__init__()\n",
    "\n",
    "        if norm == 'l': norm = [torch.nn.LayerNorm  (in_features)]\n",
    "        if norm == 'b': norm = [torch.nn.BatchNorm1d(in_features)]\n",
    "\n",
    "        input_norm   = norm or []\n",
    "        output_layer = torch.nn.Linear(in_features=in_features, out_features=out_features)\n",
    "        self.layers  = torch.nn.Sequential(*input_norm, output_layer)\n",
    "\n",
    "    def forward(self, Xs):\n",
    "        return self.layers(Xs)\n",
    "\n",
    "class Mlp(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, depth=3, width=None, norm='l'):\n",
    "        super().__init__()\n",
    "\n",
    "        def norm_layer(in_width, out_width, norm):\n",
    "            norm = torch.nn.LayerNorm(out_width) if norm == 'l' else torch.nn.BatchNorm1d(out_width)\n",
    "            return torch.nn.Sequential(torch.nn.Linear(in_features=in_width, out_features=out_width), norm, torch.nn.ReLU())\n",
    "\n",
    "        def no_norm_layer(in_width, out_width):\n",
    "            return torch.nn.Sequential(torch.nn.Linear(in_features=in_width, out_features=out_width), torch.nn.ReLU())\n",
    "\n",
    "        def layer(in_width, out_width, norm):\n",
    "            if norm:\n",
    "                return norm_layer(in_width, out_width, norm)\n",
    "            else:\n",
    "                return no_norm_layer(in_width, out_width)\n",
    "\n",
    "        width = width or in_features\n",
    "\n",
    "        input_layer   =   layer(in_features, width       , norm)\n",
    "        hidden_layers = [ layer(width      , width       , norm) for _ in range(depth) ]\n",
    "        output_layer  =   torch.nn.Linear(in_features=width, out_features=out_features)\n",
    "\n",
    "        self.layers  = torch.nn.Sequential(input_layer,*hidden_layers,output_layer)\n",
    "\n",
    "    def forward(self, Xs):\n",
    "        return self.layers(Xs)\n",
    "\n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, depth=3, width=None, norm='l'):\n",
    "        super().__init__()        \n",
    "\n",
    "        def norm_layer(in_width, out_width, norm):\n",
    "            norm = torch.nn.LayerNorm(in_width) if norm == 'l' else torch.nn.BatchNorm1d(width)\n",
    "            return torch.nn.Sequential(norm,torch.nn.ReLU(),torch.nn.Linear(in_features=in_width,out_features=out_width))\n",
    "\n",
    "        def no_norm_layer(in_width, out_width):\n",
    "            return torch.nn.Sequential(torch.nn.ReLU(),torch.nn.Linear(in_features=in_width, out_features=out_width))\n",
    "\n",
    "        def layer(in_width, out_width, norm):\n",
    "            return norm_layer(in_width, out_width, norm) if norm else no_norm_layer(in_width, out_width)\n",
    "\n",
    "        class PreActivationResidualBlock(torch.nn.Module):\n",
    "            def __init__(self, in_width, norm) -> None:\n",
    "                super().__init__()\n",
    "                self.layers = torch.nn.Sequential(layer(in_width,in_width,norm),layer(in_width,in_width,norm))\n",
    "            def forward(self, Xs):\n",
    "                return Xs+self.layers(Xs)\n",
    "\n",
    "        width  = width or in_features\n",
    "\n",
    "        input_layer   = torch.nn.Linear(in_features=in_features, out_features=width)\n",
    "        hidden_layers = [PreActivationResidualBlock(width,norm) for _ in range(depth)]\n",
    "        output_layer  = layer(width,out_features,norm)\n",
    "\n",
    "        self.layers  = torch.nn.Sequential(input_layer,*hidden_layers,output_layer)\n",
    "\n",
    "    def forward(self, Xs):\n",
    "        return self.layers(Xs)\n",
    "\n",
    "class ResNetDropout(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, depth=3, width=None, drop=[.2,.5]):\n",
    "        super().__init__()\n",
    "\n",
    "        def layer(in_width,out_width,drop):\n",
    "            return torch.nn.Sequential(torch.nn.ReLU(),torch.nn.Dropout(drop),torch.nn.Linear(in_features=in_width, out_features=out_width))\n",
    "        \n",
    "        class PreActivationResidualBlock(torch.nn.Module):\n",
    "            def __init__(self, in_width, drop) -> None:\n",
    "                super().__init__()\n",
    "                self.layers = torch.nn.Sequential(layer(in_width,in_width,drop),layer(in_width,in_width,drop))\n",
    "            def forward(self, Xs):\n",
    "                return Xs+self.layers(Xs)\n",
    "\n",
    "        width  = width or in_features\n",
    "\n",
    "        input_layer   = torch.nn.Linear(in_features=in_features, out_features=width)\n",
    "        hidden_layers = [PreActivationResidualBlock(width,drop[1]) for _ in range(depth)]\n",
    "        output_layer  = layer(width,out_features,drop[1])\n",
    "\n",
    "        self.layers  = torch.nn.Sequential(torch.nn.Dropout(drop[0]),input_layer,*hidden_layers,output_layer)\n",
    "\n",
    "    def forward(self, Xs):\n",
    "        return self.layers(Xs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f52e5-cbab-444e-ab3b-a4d2bd5d8895",
   "metadata": {},
   "source": [
    "### Simple Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "468c0bc6-d662-4957-96db-832fe4dc8c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 25.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 16, 'b', 1, 0.559564942543666),\n",
       " (4, 16, 'b', 2, 0.5828707672679304),\n",
       " (5, 16, 'b', 1, 0.5706564252663544),\n",
       " (5, 16, 'b', 2, 0.5920975530904609)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import cloudpickle\n",
    "from eval import eval\n",
    "from itertools import product\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "numthreads = 1\n",
    "maxworkers = 12\n",
    "\n",
    "b = 16\n",
    "\n",
    "def local(device):\n",
    "    from itertools import product\n",
    "    from sklearn.metrics import roc_auc_score \n",
    "    from collections import defaultdict\n",
    "\n",
    "    ins  = []\n",
    "    outs = defaultdict(lambda:([],[]))\n",
    "\n",
    "    for d,w,n,e in product([4,5],[16],['b'],[1,2]):\n",
    "        model = cloudpickle.dumps(ResNet(13,1,depth=d,width=w,norm=n))\n",
    "        key   = (d,w,n,e)\n",
    "        for _ in range(3):\n",
    "            for pid in sorted(set(df.participant_id)):\n",
    "                ins.append( (model,pid,key,b,e,numthreads,device,None) )\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=maxworkers) as executor:\n",
    "        mapper = map if maxworkers == 1 else executor.map\n",
    "        for k,s,l in mapper(eval,ins):\n",
    "            outs[k][0].extend(s)\n",
    "            outs[k][1].extend(l)\n",
    "\n",
    "    return [ (*k,roc_auc_score(labels,scores)) for k,(scores,labels) in outs.items() ]\n",
    "\n",
    "local('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f8ff05-a3c0-478c-94a3-8a8146c384d3",
   "metadata": {},
   "source": [
    "### Hyperparameter Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9e14b5e-c356-45e8-9b9d-dac637a2c330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 24, 'b', 0.6274477844250891),\n",
       " (4, 16, 'l', 0.6249837388295325),\n",
       " (6, 24, 'b', 0.6247434561223881),\n",
       " (2, 16, 'b', 0.6241366275021158),\n",
       " (2, 16, 'l', 0.6236882018129866),\n",
       " (6, 16, 'b', 0.6228793520631408),\n",
       " (2, 24, None, 0.6227844633507652),\n",
       " (6, 8, None, 0.6224531180890026),\n",
       " (2, 24, 'b', 0.6212180343650184),\n",
       " (4, 16, 'b', 0.6212126777441586),\n",
       " (6, 16, None, 0.6209134722075553),\n",
       " (6, 16, 'l', 0.6198742877607335),\n",
       " (6, 24, None, 0.618057628057674),\n",
       " (4, 24, None, 0.6173256840787453),\n",
       " (4, 16, None, 0.616851240516868),\n",
       " (2, 24, 'l', 0.6157642290980828),\n",
       " (2, 16, None, 0.612146214322992),\n",
       " (4, 24, 'l', 0.6117957382724439),\n",
       " (6, 8, 'b', 0.6112187536826769),\n",
       " (6, 24, 'l', 0.6107703279935476),\n",
       " (2, 8, None, 0.6097028299793235),\n",
       " (4, 8, 'l', 0.6047758866355369),\n",
       " (4, 8, None, 0.6010951228732302),\n",
       " (4, 8, 'b', 0.6002973689808799),\n",
       " (2, 8, 'l', 0.5992711934704322),\n",
       " (2, 8, 'b', 0.5971844070297231),\n",
       " (6, 8, 'l', 0.5901519290722179)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def local(device):\n",
    "    import parameterfree\n",
    "    from itertools import product\n",
    "    from sklearn.metrics import roc_auc_score \n",
    "\n",
    "    X_all = torch.tensor(df.iloc[:,7:].to_numpy())\n",
    "    y_all = torch.tensor(((df['experience_id'] != 1) & (df['phase_id'] == 1)).astype(int).to_numpy())[:,None]\n",
    "    \n",
    "    X_all = X_all.float()\n",
    "    y_all = y_all.float()\n",
    "\n",
    "    outs = []\n",
    "    for d,w,n in product([2,4,6],[8,16,24],['l','b',None]):\n",
    "        scores,labels=[],[]\n",
    "        for pid in sorted(set(df.participant_id)):\n",
    "            X_trn = X_all[df.participant_id!=pid]\n",
    "            y_trn = y_all[df.participant_id!=pid]\n",
    "            X_tst = X_all[df.participant_id==pid]\n",
    "            y_tst = y_all[df.participant_id==pid]\n",
    "    \n",
    "            model = ResNet(13,1,depth=d,width=w,norm=n).to(device)\n",
    "            loss  = torch.nn.BCEWithLogitsLoss()\n",
    "            opt   = parameterfree.COCOB(model.parameters())\n",
    "    \n",
    "            model = train_model(X_trn,y_trn,model,opt,None,loss,24,3,device)\n",
    "            with torch.no_grad():\n",
    "                scores.extend(model(X_tst.to(device)).squeeze().tolist())\n",
    "                labels.extend(y_tst.squeeze().tolist())\n",
    "        \n",
    "        outs.append((d,w,n,roc_auc_score(labels,scores)))\n",
    "    return outs\n",
    "outs1 = local('cpu')\n",
    "from operator import itemgetter\n",
    "sorted(outs1,key=itemgetter(-1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d6e0207-6a73-40b8-9463-936a392d50d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 32, 0.2, 6, 0.6316634450418352),\n",
       " (4, 32, 0.4, 6, 0.6297855668146625),\n",
       " (4, 16, 0.2, 3, 0.628193885187719),\n",
       " (6, 32, 0.4, 6, 0.6228797346789166),\n",
       " (8, 32, 0.2, 6, 0.6222977760840653),\n",
       " (6, 24, 0.4, 6, 0.620748947424001),\n",
       " (8, 16, 0.2, 6, 0.6207160424672902),\n",
       " (8, 16, 0.4, 6, 0.6206747199635138),\n",
       " (6, 32, 0.2, 3, 0.6193355647485372),\n",
       " (4, 16, 0.2, 6, 0.6183920342456423),\n",
       " (8, 24, 0.2, 6, 0.6179512608720272),\n",
       " (8, 32, 0.4, 6, 0.6177836751622673),\n",
       " (6, 24, 0.2, 3, 0.6177779359256317),\n",
       " (4, 24, 0.4, 6, 0.6169564598551875),\n",
       " (6, 16, 0.2, 3, 0.6167865784507734),\n",
       " (8, 24, 0.4, 6, 0.6156701056172588),\n",
       " (6, 32, 0.4, 3, 0.6155859301466031),\n",
       " (6, 24, 0.2, 6, 0.6155407814850696),\n",
       " (8, 32, 0.4, 3, 0.6148130462796737),\n",
       " (4, 24, 0.2, 6, 0.6140524061175672),\n",
       " (8, 32, 0.2, 3, 0.6133797675838731),\n",
       " (6, 24, 0.4, 3, 0.6133782371207703),\n",
       " (6, 16, 0.2, 6, 0.6129183329583698),\n",
       " (4, 32, 0.2, 3, 0.6120635693154391),\n",
       " (4, 24, 0.4, 3, 0.6104190867114481),\n",
       " (8, 16, 0.2, 3, 0.6104175562483452),\n",
       " (6, 16, 0.4, 6, 0.610129829185013),\n",
       " (4, 16, 0.4, 6, 0.6095161134807782),\n",
       " (8, 24, 0.2, 3, 0.6093033791094847),\n",
       " (8, 24, 0.4, 3, 0.6082465943369804),\n",
       " (4, 32, 0.2, 6, 0.607650478958428),\n",
       " (6, 16, 0.4, 3, 0.605034917515691),\n",
       " (4, 32, 0.4, 3, 0.6016502983637818),\n",
       " (4, 16, 0.4, 3, 0.6011280278299411),\n",
       " (4, 24, 0.2, 3, 0.6002093673524671),\n",
       " (8, 16, 0.4, 3, 0.5921526269633928)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def local(device):\n",
    "    import parameterfree\n",
    "    from itertools import product\n",
    "    from sklearn.metrics import roc_auc_score \n",
    "\n",
    "    X_all = torch.tensor(df.iloc[:,7:].to_numpy())\n",
    "    y_all = torch.tensor(((df['experience_id'] != 1) & (df['phase_id'] == 1)).astype(int).to_numpy())[:,None]\n",
    "    \n",
    "    X_all = X_all.float()\n",
    "    y_all = y_all.float()\n",
    "\n",
    "    outs = []\n",
    "    for d,w,n,e in product([4,6,8],[16,24,32],[.2,.4],[3,6]):\n",
    "        scores,labels=[],[]\n",
    "        for pid in sorted(set(df.participant_id)):\n",
    "            X_trn = X_all[df.participant_id!=pid]\n",
    "            y_trn = y_all[df.participant_id!=pid]\n",
    "            X_tst = X_all[df.participant_id==pid]\n",
    "            y_tst = y_all[df.participant_id==pid]\n",
    "    \n",
    "            model = ResNetDropout(13,1,depth=d,width=w,drop=[.2,n]).to(device)\n",
    "            loss  = torch.nn.BCEWithLogitsLoss()\n",
    "            opt   = parameterfree.COCOB(model.parameters())\n",
    "    \n",
    "            model = train_model(X_trn,y_trn,model,opt,None,loss,24,e,device)\n",
    "            with torch.no_grad():\n",
    "                scores.extend(model(X_tst.to(device)).squeeze().tolist())\n",
    "                labels.extend(y_tst.squeeze().tolist())\n",
    "        \n",
    "        outs.append((d,w,n,e,roc_auc_score(labels,scores)))\n",
    "    return outs\n",
    "outs2 = local('cpu')\n",
    "from operator import itemgetter\n",
    "sorted(outs2,key=itemgetter(-1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c13a174-e704-4d7c-855f-0e26dcdc316e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 16, 'b', 5, 0.6304536139590479),\n",
       " (4, 24, 'b', 5, 0.6247887748353774),\n",
       " (4, 16, 'b', 4, 0.6229591487088078),\n",
       " (4, 24, 'b', 3, 0.6180165181182173),\n",
       " (4, 24, 'b', 4, 0.6167185578684254),\n",
       " (4, 16, 'b', 3, 0.6072754304725066)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def local(device):\n",
    "    import parameterfree\n",
    "    from itertools import product\n",
    "    from sklearn.metrics import roc_auc_score \n",
    "\n",
    "    X_all = torch.tensor(df.iloc[:,7:].to_numpy())\n",
    "    y_all = torch.tensor(((df['experience_id'] != 1) & (df['phase_id'] == 1)).astype(int).to_numpy())[:,None]\n",
    "    \n",
    "    X_all = X_all.float()\n",
    "    y_all = y_all.float()\n",
    "\n",
    "    outs = []\n",
    "    for d,w,n,e in product([4],[16,24],['b'],[3,4,5]):\n",
    "        scores,labels=[],[]\n",
    "        for _ in range(3):\n",
    "            for pid in sorted(set(df.participant_id)):\n",
    "                X_trn = X_all[df.participant_id!=pid]\n",
    "                y_trn = y_all[df.participant_id!=pid]\n",
    "                X_tst = X_all[df.participant_id==pid]\n",
    "                y_tst = y_all[df.participant_id==pid]\n",
    "        \n",
    "                model = ResNet(13,1,depth=d,width=w,norm=n).to(device)\n",
    "                loss  = torch.nn.BCEWithLogitsLoss()\n",
    "                opt   = parameterfree.COCOB(model.parameters())\n",
    "        \n",
    "                model = train_model(X_trn,y_trn,model,opt,None,loss,24,e,device)\n",
    "                with torch.no_grad():\n",
    "                    scores.extend(model(X_tst.to(device)).squeeze().tolist())\n",
    "                    labels.extend(y_tst.squeeze().tolist())\n",
    "        outs.append((d,w,n,e,roc_auc_score(labels,scores)))\n",
    "    return outs\n",
    "outs3 = local('cpu')\n",
    "from operator import itemgetter\n",
    "sorted(outs3,key=itemgetter(-1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9ca68f-1ce8-4cc1-9f50-9e65af1a939c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 16, 'b', 6, 0.6272364954911707),\n",
       " (5, 16, 'b', 7, 0.624532804881429),\n",
       " (4, 16, 'b', 7, 0.619482446693545),\n",
       " (5, 16, 'b', 6, 0.6168667151993521)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def local(device):\n",
    "    import parameterfree\n",
    "    from itertools import product\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    X_all = torch.tensor(df.iloc[:,7:].to_numpy())\n",
    "    y_all = torch.tensor(((df['experience_id'] != 1) & (df['phase_id'] == 1)).astype(int).to_numpy())[:,None]\n",
    "    \n",
    "    X_all = X_all.float()\n",
    "    y_all = y_all.float()\n",
    "\n",
    "    outs = []\n",
    "    for d,w,n,e in product([4,5],[16],['b'],[6,7]):\n",
    "        scores,labels=[],[]\n",
    "        for _ in range(3):\n",
    "            for pid in sorted(set(df.participant_id)):\n",
    "                X_trn = X_all[df.participant_id!=pid]\n",
    "                y_trn = y_all[df.participant_id!=pid]\n",
    "                X_tst = X_all[df.participant_id==pid]\n",
    "                y_tst = y_all[df.participant_id==pid]\n",
    "        \n",
    "                model = ResNet(13,1,depth=d,width=w,norm=n).to(device)\n",
    "                loss  = torch.nn.BCEWithLogitsLoss()\n",
    "                opt   = parameterfree.COCOB(model.parameters())\n",
    "        \n",
    "                model = train_model(X_trn,y_trn,model,opt,None,loss,24,e,device)\n",
    "                with torch.no_grad():\n",
    "                    scores.extend(model(X_tst.to(device)).squeeze().tolist())\n",
    "                    labels.extend(y_tst.squeeze().tolist())\n",
    "        outs.append((d,w,n,e,roc_auc_score(labels,scores)))\n",
    "    return outs\n",
    "outs3 = local('cpu')\n",
    "from operator import itemgetter\n",
    "sorted(outs3,key=itemgetter(-1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "d5c6e83c-a82d-4191-9b37-6eb9a8caf003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 16, 'b', 7, 0.7040816326530612),\n",
       " (4, 16, 'b', 7, 0.5918367346938775),\n",
       " (4, 16, 'b', 6, 0.3137755102040816),\n",
       " (5, 16, 'b', 6, 0.24744897959183673)]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def local(device):\n",
    "    import parameterfree\n",
    "    from itertools import product\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    X_all = torch.tensor(df.iloc[:,7:].to_numpy())\n",
    "    y_all = torch.tensor(((df['experience_id'] != 1) & (df['phase_id'] == 1)).astype(int).to_numpy())[:,None]\n",
    "    \n",
    "    X_all = X_all.float()\n",
    "    y_all = y_all.float()\n",
    "\n",
    "    outs = []\n",
    "    for d,w,n,e in product([4,5],[16],['b'],[6,7]):\n",
    "        scores,labels=[],[]\n",
    "        for _ in range(1):\n",
    "            for pid in sorted(set(df.participant_id))[:1]:\n",
    "                X_trn = X_all[df.participant_id!=pid]\n",
    "                y_trn = y_all[df.participant_id!=pid]\n",
    "                X_tst = X_all[df.participant_id==pid]\n",
    "                y_tst = y_all[df.participant_id==pid]\n",
    "        \n",
    "                model = ResNet(13,1,depth=d,width=w,norm=n).to(device)\n",
    "                loss  = torch.nn.BCEWithLogitsLoss()\n",
    "                opt   = parameterfree.COCOB(model.parameters())\n",
    "        \n",
    "                model = train_model(X_trn,y_trn,model,opt,None,loss,24,e,device)\n",
    "                with torch.no_grad():\n",
    "                    scores.extend(sigmoid(model(X_tst.to(device))).squeeze().tolist())\n",
    "                    labels.extend(y_tst.squeeze().tolist())\n",
    "        outs.append((d,w,n,e,roc_auc_score(labels,scores)))\n",
    "    return outs\n",
    "outs3 = local('cpu')\n",
    "from operator import itemgetter\n",
    "sorted(outs3,key=itemgetter(-1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cff51688-ec69-4a3e-b030-4c5b68b915a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2075])\n",
      "tensor([-0.2182])\n",
      "tensor([-0.2298])\n",
      "0.0032805311493575573\n",
      "tensor([-0.2075])\n",
      "tensor([-0.2182])\n",
      "tensor([-0.2298])\n",
      "0.0017711040563881397\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "\n",
    "def func1():\n",
    "    torch.max(L, torch.abs(grad), out=L)\n",
    "    sum_negative_gradients.sub_(grad)\n",
    "    grad_norm_sum.add_(torch.abs(grad))\n",
    "    reward.addcmul_(grad, data.sub(x0), value=-1)\n",
    "    torch.maximum(reward, torch.zeros_like(reward), out=reward)\n",
    "    den = torch.maximum(grad_norm_sum.add(L), L.mul(alpha)).mul(L)\n",
    "    data.copy_(reward.add(L).mul(sum_negative_gradients).div(den).add(x0))\n",
    "    print(data)\n",
    "    \n",
    "def func2():\n",
    "    absgrad = torch.abs(grad)\n",
    "    torch.maximum(L, absgrad, out=L)\n",
    "    sum_negative_gradients.sub_(grad)\n",
    "    grad_norm_sum.add_(absgrad)\n",
    "    reward.sub_(grad*old).clamp_(0)\n",
    "    den = torch.maximum(grad_norm_sum+L, L*alpha)*L\n",
    "    new = reward.add(L)*sum_negative_gradients.div(den)\n",
    "    data.sub_(old).add_(new)\n",
    "    old.copy_(new)\n",
    "    print(data)\n",
    "\n",
    "sum_negative_gradients, grad_norm_sum, L, reward, x0 = state['sum_negative_gradients'],state['grad_norm_sum'],state['L'],state['reward'],state['x0']\n",
    "data,grad,sum_negative_gradients = torch.clone(p.data),torch.clone(p.grad),torch.clone(sum_negative_gradients)\n",
    "grad_norm_sum,L,reward,x0 = torch.clone(grad_norm_sum),torch.clone(L),torch.clone(reward),torch.clone(x0)\n",
    "alpha,Z,O = 100,torch.zeros_like(reward),torch.ones_like(reward)\n",
    "print(timeit.timeit(func1,number=3))\n",
    "\n",
    "sum_negative_gradients, grad_norm_sum, L, reward, x0 = state['sum_negative_gradients'],state['grad_norm_sum'],state['L'],state['reward'],state['x0']\n",
    "data,grad,sum_negative_gradients = torch.clone(p.data),torch.clone(p.grad),torch.clone(sum_negative_gradients)\n",
    "grad_norm_sum,L,reward,x0 = torch.clone(grad_norm_sum),torch.clone(L),torch.clone(reward),torch.clone(x0)\n",
    "old = p.data-x0\n",
    "alpha,Z = 100,torch.zeros_like(reward)\n",
    "print(timeit.timeit(func2,number=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "e3395286-b326-4c2f-bac2-0d9b890c29a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39min 50s, sys: 1.2 s, total: 39min 51s\n",
      "Wall time: 2min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 16, 'b', 1, 0.536012562041148), (5, 16, 'b', 1, 0.536012562041148)]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from itertools import islice\n",
    "\n",
    "def train_model(Xs, ys, model, opt, sched, loss, batch=8, epoch=1, device='cpu',autotype=None):\n",
    "    loader = DataLoader(TensorDataset(Xs,ys),batch_size=batch,pin_memory=(device!='cpu'),drop_last=True,shuffle=False)\n",
    "    for _ in range(epoch):\n",
    "        for X,y in loader:\n",
    "            opt.zero_grad()\n",
    "            X,y = X.to(device),y.to(device)\n",
    "            if not autotype:\n",
    "                l = loss(model(X),y)\n",
    "            else:\n",
    "                with torch.autocast(device_type=device,dtype=autotype):\n",
    "                    l = loss(model(X),y)\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "        if sched: sched.step()\n",
    "    return model.eval()\n",
    "\n",
    "def local(device):\n",
    "    import parameterfree\n",
    "    from itertools import product\n",
    "    from sklearn.metrics import roc_auc_score \n",
    "\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    X_all = torch.tensor(df.iloc[:,7:].to_numpy())\n",
    "    y_all = torch.tensor(((df['experience_id'] != 1) & (df['phase_id'] == 1)).astype(int).to_numpy())[:,None]\n",
    "\n",
    "    X_all = X_all.float()\n",
    "    y_all = y_all.float()\n",
    "\n",
    "    outs = []\n",
    "    for d,w,n,e in product([4,5],[16],['b'],[1]):\n",
    "        scores,labels=[],[]\n",
    "        for _ in range(1):\n",
    "            for pid in sorted(set(df.participant_id)):\n",
    "                \n",
    "                X_trn = X_all[df.participant_id!=pid]\n",
    "                y_trn = y_all[df.participant_id!=pid]\n",
    "                X_tst = X_all[df.participant_id==pid]\n",
    "                y_tst = y_all[df.participant_id==pid]\n",
    "\n",
    "                #model = ResNet(13,1,depth=d,width=w,norm=n).to(device)\n",
    "                model = copy.deepcopy(M).to(device)\n",
    "                loss  = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "                opt   = parameterfree.COCOB(model.parameters())\n",
    "                #opt   = COCOB(model.parameters(),i=None)\n",
    "\n",
    "                model = train_model(X_trn,y_trn,model,opt,None,loss,16,1,device)\n",
    "                #model = train_model(X_trn,y_trn,model,opt,None,loss,16,e,device,autotype=torch.bfloat16)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    scores.extend(sigmoid(model(X_tst.to(device))).squeeze().tolist())\n",
    "                    labels.extend(y_tst.squeeze().tolist())\n",
    "        outs.append((d,w,n,e,roc_auc_score(labels,scores)))\n",
    "    return outs\n",
    "local('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d58228ac-0c54-43a2-be1e-235ddcb0973c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:56\u001b[0m\n",
      "File \u001b[1;32m<timed exec>:54\u001b[0m, in \u001b[0;36mlocal\u001b[1;34m(device)\u001b[0m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\diss\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\diss\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:618\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) \\\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03mfrom prediction scores.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;124;03marray([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])\u001b[39;00m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    617\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 618\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    619\u001b[0m y_score \u001b[38;5;241m=\u001b[39m check_array(y_score, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    622\u001b[0m     y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    623\u001b[0m ):\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;66;03m# do not support partial ROC computation for multiclass\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\diss\\lib\\site-packages\\sklearn\\utils\\validation.py:1072\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m   1071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m-> 1072\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1073\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1074\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1075\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m   1076\u001b[0m         )\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1079\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f119ab7f-b42c-4daf-8ad2-1f8db4a817bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27971268631517887\n",
      "0.2534223939292133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3, 4])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor([1,2])\n",
    "t2 = torch.tensor([3,4])\n",
    "\n",
    "import timeit\n",
    "\n",
    "print(timeit.timeit(lambda:t1.add(t2),number=100000))\n",
    "print(timeit.timeit(lambda:t1.sub(t2),number=100000))\n",
    "\n",
    "torch.maximum(t1,t2)\n",
    "#t1.clamp(min=t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d11950-2c6c-4ec9-a35c-257872063d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "M = ResNet(13,1,depth=4,width=16,norm='b')\n",
    "copy.deepcopy(M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47f10de8-e175-4bbc-b32a-0df56bafc3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min, sys: 163 ms, total: 4min\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def local(device):\n",
    "    import parameterfree\n",
    "    from itertools import product\n",
    "    from sklearn.metrics import roc_auc_score \n",
    "\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    X_all = torch.tensor(df.iloc[:,7:].to_numpy())\n",
    "    y_all = torch.tensor(((df['experience_id'] != 1) & (df['phase_id'] == 1)).astype(int).to_numpy())[:,None]\n",
    "    \n",
    "    X_all = X_all.float()\n",
    "    y_all = y_all.float()\n",
    "\n",
    "    outs = []\n",
    "    for d,w,n,e in product([4,5],[16],['b'],[5]):\n",
    "        scores,labels=[],[]\n",
    "        for _ in range(1):\n",
    "            for pid in sorted(set(df.participant_id))[:1]:\n",
    "                X_trn = X_all[df.participant_id!=pid]\n",
    "                y_trn = y_all[df.participant_id!=pid]\n",
    "                X_tst = X_all[df.participant_id==pid]\n",
    "                y_tst = y_all[df.participant_id==pid]\n",
    "        \n",
    "                model = ResNet2(13,1,depth=d,width=w,norm=n).to(device)\n",
    "                loss  = torch.nn.BCELoss()\n",
    "                opt   = parameterfree.COCOB(model.parameters())\n",
    "        \n",
    "                model = train_model(X_trn,y_trn,model,opt,None,loss,24,e,device)\n",
    "                with torch.no_grad():\n",
    "                    scores.extend((model(X_tst)).squeeze().tolist())\n",
    "                    labels.extend(y_tst.squeeze().tolist())\n",
    "        outs.append((d,w,n,e,roc_auc_score(labels,scores)))\n",
    "    return outs\n",
    "outs3 = local('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6358132a-9cea-47bf-8c43-081c16367d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "def train_model(Xs, ys, model, opt, sched, loss, batch=8, epoch=1, device='cpu'):\n",
    "    loader = DataLoader(TensorDataset(Xs,ys),batch_size=batch,drop_last=True,shuffle=True)\n",
    "    for _ in range(epoch):\n",
    "        for X,y in loader:\n",
    "            #opt.zero_grad()\n",
    "            loss(model(X),y).backward()\n",
    "            #opt.step()\n",
    "        if sched: sched.step()\n",
    "    return model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
