{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "203f7238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/mrucker/miniconda3/envs/diss/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import islice, chain, count, product, repeat\n",
    "from contextlib import nullcontext\n",
    "\n",
    "data_dir = \"../data\"\n",
    "\n",
    "import coba as cb\n",
    "\n",
    "import warnings\n",
    "\n",
    "import time\n",
    "import csv\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import RobustScaler, QuantileTransformer, MinMaxScaler, StandardScaler, Binarizer\n",
    "from sklearn.feature_selection import  mutual_info_classif, f_classif, GenericUnivariateSelect\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, StratifiedKFold, GridSearchCV, LeaveOneGroupOut, StratifiedShuffleSplit\n",
    "from sklearn.metrics import balanced_accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import torch\n",
    "from parameterfree import COCOB\n",
    "\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import coba as cb\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "try:\n",
    "    torch.set_num_threads(3)\n",
    "    torch.set_num_interop_threads(3)\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "c0 = \"#444\"\n",
    "c1 = \"#0072B2\"\n",
    "c2 = \"#E69F00\"\n",
    "c3 = \"#009E73\"\n",
    "c4 = \"#56B4E9\"\n",
    "c5 = \"#D55E00\"\n",
    "c6 = \"#F0E442\"\n",
    "c7 = \"#CC79A7\"\n",
    "c8 = \"#000000\"\n",
    "c9 = \"#332288\"\n",
    "\n",
    "torch.set_default_device('cpu')\n",
    "plt.rc('font', **{'size': 20})\n",
    "\n",
    "df = pd.read_csv(f\"{data_dir}/all_features_1h_v3.csv\")\n",
    "\n",
    "G  = df[\"id_participant\"].to_numpy()\n",
    "X1 = df[[c for c in df.columns if c.startswith(\"acc_\")]].to_numpy()\n",
    "X2 = df[[c for c in df.columns if c.startswith(\"acc_\") or c.startswith(\"gps_\") or c.startswith(\"motion_\")]].to_numpy()\n",
    "Y1 = df[\"ER_desire\"].astype(float).to_numpy()\n",
    "Y2 = (df[\"INT_availability\"] == \"yes\").astype(float).to_numpy()\n",
    "\n",
    "#no_na = ~(np.isnan(X2).any(axis=1) | np.isnan(Y1) | np.isnan(Y2))\n",
    "no_na = ~(np.isnan(Y1) | np.isnan(Y2))\n",
    "#no_na = ~(np.isnan(Y2))\n",
    "\n",
    "G  = G [no_na]\n",
    "X1 = X1[no_na]\n",
    "X2 = X2[no_na]\n",
    "X3 = X2.copy()\n",
    "X4 = X2.copy()\n",
    "Y1 = np.expand_dims(Y1[no_na],axis=1)\n",
    "Y2 = np.expand_dims(Y2[no_na],axis=1)\n",
    "\n",
    "for g in set(G):\n",
    "    Y1[G == g] = Binarizer(threshold=np.mean(Y1[G == g].squeeze())).fit_transform(Y1[G == g])\n",
    "    X1[G == g] = StandardScaler().fit_transform(X1[G == g])\n",
    "    X2[G == g] = StandardScaler().fit_transform(X2[G == g])\n",
    "    X3[G == g] = StandardScaler().fit_transform(X3[G == g])\n",
    "    X4[G == g] = StandardScaler().fit_transform(X4[G == g])\n",
    "\n",
    "X3 = np.concatenate([X3, np.expand_dims((df[\"Platform\"] == \"Android\").astype(float).to_numpy(),1)[no_na]],axis=1)\n",
    "X3 = np.concatenate([X3, np.expand_dims((df[\"Platform\"] == \"iPhone\" ).astype(float).to_numpy(),1)[no_na]],axis=1)\n",
    "\n",
    "X4 = np.concatenate([X4, np.expand_dims((df[\"Platform\"] == \"Android\").astype(float).to_numpy(),1)[no_na]],axis=1)\n",
    "X4 = np.concatenate([X4, np.expand_dims((df[\"Platform\"] == \"iPhone\" ).astype(float).to_numpy(),1)[no_na]],axis=1)\n",
    "X4 = np.concatenate([X4, np.expand_dims((df[\"tag\"] == \"evening\" ).astype(float).to_numpy(),1)[no_na]],axis=1)\n",
    "X4 = np.concatenate([X4, np.expand_dims((df[\"tag\"] == \"morning\" ).astype(float).to_numpy(),1)[no_na]],axis=1)\n",
    "X4 = np.concatenate([X4, np.expand_dims((df[\"tag\"] == \"afternoon\" ).astype(float).to_numpy(),1)[no_na]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8275be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [82, 87, 89, 99, 103, 111, 117, 146, 196, 227, 246, 311, 357, 377, 390, 451, 455]\n",
      "{'Learners': 1, 'Environments': 910, 'Interactions': 229320}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr):\n",
    "\n",
    "        by_class  = {y: self.train_X[(self.train_Y==y)].tolist() for y in set(self.train_Y.tolist())}\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "\n",
    "        def choose_unique(items,item):\n",
    "            while items[i:=rng.randint(0,len(items)-1)]==item:\n",
    "                pass\n",
    "            return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            while True:\n",
    "                indexes.add(rng.randint(0,len(items)-1))\n",
    "                if len(indexes)==n: return [items[i] for i in indexes]\n",
    "\n",
    "        for _ in range(sr):\n",
    "            anchor, positive, negative = [], [], []\n",
    "            for x,y in zip(self.train_X.tolist(),self.train_Y.tolist()):\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(by_class[y],x))\n",
    "                negative.append(choose_n(by_class[1-y],neg))\n",
    "\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s1, s2, s3, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, pers_lrn_cnt, pers_mem_cnt, pers_mem_rpt, pers_mem_rcl):\n",
    "\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "        self.s3  = s3  #sl + online\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "        \n",
    "        self.ws_steps = ws_steps\n",
    "\n",
    "        self.pers_lrn_cnt = pers_lrn_cnt \n",
    "        self.pers_mem_cnt = pers_mem_cnt\n",
    "        self.pers_mem_rpt = pers_mem_rpt\n",
    "        self.pers_mem_rcl = pers_mem_rcl\n",
    "        \n",
    "        self.params = {'s1': s1, 's2':s2, 's3':s3, 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'pers': (pers_lrn_cnt,pers_mem_cnt,pers_mem_rpt,pers_mem_rcl)}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        s1 = FeedForward(self.s1[:len(self.s1)-self.ssl_dropn])\n",
    "        sb = FeedForward(self.s1[len(self.s1)-self.ssl_dropn:])\n",
    "        s2 = FeedForward(self.s2)\n",
    "        s3 = FeedForward(self.s3)\n",
    "\n",
    "        s1.train()\n",
    "        sb.train()\n",
    "        s2.train()\n",
    "        s3.train()\n",
    "\n",
    "        s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "        sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "        s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        if self.ssl_samps:\n",
    "\n",
    "            if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "            if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            \n",
    "            for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps):\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=64,drop_last=True,shuffle=True)\n",
    "\n",
    "                for _A, _P, _N in torch_loader:\n",
    "                    #https://arxiv.org/pdf/2002.05709\n",
    "                    _A = sb(s1(_A))\n",
    "                    _P = sb(s1(_P))\n",
    "                    _N = sb(s1(_N))\n",
    "\n",
    "                    p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                    n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                    p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                    n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                    p = torch.exp(p/self.ssl_tau)\n",
    "                    n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if sbopt: sbopt.zero_grad()\n",
    "                    (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if sbopt: sbopt.step()\n",
    "\n",
    "        if self.ws_steps:\n",
    "\n",
    "            if s1opt: s1opt.zero_grad()\n",
    "            if s2opt: s2opt.zero_grad()\n",
    "            if s3opt: s3opt.zero_grad()\n",
    "\n",
    "            X, Y = env.train()\n",
    "\n",
    "            loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            for _ in range(self.ws_steps):\n",
    "                for _X,_y in torch_loader:\n",
    "\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if s2opt: s2opt.zero_grad()\n",
    "                    if s3opt: s3opt.zero_grad()\n",
    "                    loss(s3(s2(s1(_X))),_y).backward()\n",
    "                    if s3opt: s3opt.step()\n",
    "                    if s2opt: s2opt.step()\n",
    "                    if s1opt: s1opt.step()\n",
    "\n",
    "        s1.eval()\n",
    "        s2.eval()\n",
    "        s3.eval()\n",
    "\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        X, Y = env.test()\n",
    "\n",
    "        rng = cb.CobaRandom(1)\n",
    "        while len(set(Y[35:].squeeze().tolist())) == 1:\n",
    "            ind = rng.shuffle(range(len(Y)))\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind]\n",
    "\n",
    "        if s1opt: s1opt.zero_grad()\n",
    "        if s2opt: s2opt.zero_grad()\n",
    "\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        lrnx = []\n",
    "        lrny = []\n",
    "        mems = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            yield {'auc': roc_auc_score(Y[35:],torch.sigmoid(s3(s2(s1(X[35:,:])))))}\n",
    "        \n",
    "        for i in range(35):\n",
    "\n",
    "            x,y = X[i,:],Y[i]\n",
    "\n",
    "            if self.pers_lrn_cnt:\n",
    "                lrnx.append(x)\n",
    "                lrny.append(y)\n",
    "\n",
    "            if self.pers_mem_cnt: \n",
    "                mems.append([x,y,self.pers_mem_rpt])\n",
    "\n",
    "            if len(mems) > self.pers_mem_cnt:\n",
    "                rng.shuffle(mems, inplace=True)\n",
    "                for j in reversed(range(self.pers_mem_rcl)):\n",
    "                    x,y,n = mems[j]\n",
    "                    lrnx.append(x)\n",
    "                    lrny.append(y)\n",
    "                    if n == 1: mems.pop(j)\n",
    "                    else: mems[j] = [x,y,n-1]\n",
    "\n",
    "            if len(lrnx) >= self.pers_lrn_cnt:\n",
    "                x = torch.stack(lrnx[:self.pers_lrn_cnt])\n",
    "                y = torch.stack(lrny[:self.pers_lrn_cnt])\n",
    "                if s3opt: s3opt.zero_grad()\n",
    "                loss(s3(s2(s1(x))),y).backward()\n",
    "                if s3opt: s3opt.step()\n",
    "                lrnx = lrnx[self.pers_lrn_cnt:]\n",
    "                lrny = lrny[self.pers_lrn_cnt:]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                yield {'auc': roc_auc_score(Y[35:],torch.sigmoid(s3(s2(s1(X[35:,:])))))}\n",
    "\n",
    "def make_envs(X, Y, G):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "    all_equal = set()\n",
    "    envs = []\n",
    "    for rng in range(5):\n",
    "        for g in sorted(set(G.tolist())):\n",
    "            if (g==G).sum() < 50: continue\n",
    "            trn_x,trn_y = X[g!=G],Y[g!=G]\n",
    "            tst_x,tst_y = X[g==G],Y[g==G]\n",
    "\n",
    "            if len(set(tst_y.squeeze().tolist())) == 1:\n",
    "                all_equal.add(g)\n",
    "            else:\n",
    "                envs.append(MyEnvironment(trn_x,trn_y,tst_x,tst_y,g,rng))\n",
    "    \n",
    "    if len(all_equal) > 0:\n",
    "        print(f\"All Equal, no environment added for {sorted(all_equal)}\") \n",
    "\n",
    "    return envs\n",
    "\n",
    "r = lambda w:  ['l', 'r', w, 'l', 'r', w]\n",
    "\n",
    "lrns = [ FeedForward([]) ]\n",
    "\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((), (len(x),30,'l','r'), (30,1), 0, 0, 0, 0, 3, 3, 20, 2, 2),\n",
    "    MyEvaluator((), (len(x),30,'l','r'), (30,1), 0, 0, 0, 0, 3, 2, 20, 2, 2),\n",
    "    MyEvaluator((), (len(x),30,'l','r'), (30,1), 0, 0, 0, 0, 3, 2, 20, 1, 1),\n",
    "    MyEvaluator((), (len(x),30,'l','r'), (30,1), 0, 0, 0, 0, 3, 2,  0, 0, 0),\n",
    "    MyEvaluator((), (len(x),30,'l','r'), (30,1), 0, 0, 0, 0, 3, 1,  0, 0, 0),\n",
    "    MyEvaluator((), (len(x),30,'l','r'), (30,1), 0, 0, 0, 0, 3, 1, 10, 1, 1),\n",
    "    MyEvaluator((), (len(x),30,'l','r'), (30,1), 0, 0, 0, 0, 3, 1, 20, 2, 2),\n",
    "]\n",
    "\n",
    "envs = make_envs(X3,Y2,G)\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/5/out5_1.log',processes=35,quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd6e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [2, 25, 61, 82, 87, 89, 99, 103, 111, 117, 146, 196, 203, 227, 246, 311, 319, 357, 377, 390, 451, 455]\n",
      "{'Learners': 1, 'Environments': 661, 'Interactions': 46332}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr):\n",
    "\n",
    "        by_class  = {y: self.train_X[(self.train_Y==y)].tolist() for y in set(self.train_Y.tolist())}\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "\n",
    "        def choose_unique(items,item):\n",
    "            while items[i:=rng.randint(0,len(items)-1)]==item:\n",
    "                pass\n",
    "            return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            while True:\n",
    "                indexes.add(rng.randint(0,len(items)-1))\n",
    "                if len(indexes)==n: return [items[i] for i in indexes]\n",
    "\n",
    "        for _ in range(sr):\n",
    "            anchor, positive, negative = [], [], []\n",
    "            for x,y in zip(self.train_X.tolist(),self.train_Y.tolist()):\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(by_class[y],x))\n",
    "                negative.append(choose_n(by_class[1-y],neg))\n",
    "\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s0, s1, s2, s3, dae_steps, dae_dropn, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, pers_lrn_cnt, pers_mem_cnt, pers_mem_rpt, pers_mem_rcl):\n",
    "\n",
    "        self.s0  = s0  #dae + sl\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "        self.s3  = s3  #sl + online\n",
    "\n",
    "        self.dae_steps = dae_steps\n",
    "        self.dae_dropn = dae_dropn\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "\n",
    "        self.pers_lrn_cnt = pers_lrn_cnt\n",
    "        self.pers_mem_cnt = pers_mem_cnt\n",
    "        self.pers_mem_rpt = pers_mem_rpt\n",
    "        self.pers_mem_rcl = pers_mem_rcl\n",
    "\n",
    "        self.params = {'s0', s0, 's1': s1, 's2':s2, 's3':s3, 'dae': (dae_steps,dae_dropn), 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'pers': (pers_lrn_cnt,pers_mem_cnt,pers_mem_rpt,pers_mem_rcl)}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        s0 = FeedForward(self.s0)\n",
    "        s1 = FeedForward(self.s1)\n",
    "        s2 = FeedForward(self.s2)\n",
    "        s3 = FeedForward(self.s3)\n",
    "\n",
    "        sa = torch.nn.Sequential(*list(s0.children())[len(self.s0)-self.dae_dropn:])\n",
    "        s0 = torch.nn.Sequential(*list(s0.children())[:len(self.s0)-self.dae_dropn])\n",
    "\n",
    "        sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "        s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "        s0.train()\n",
    "        sa.train()\n",
    "        s1.train()\n",
    "        sb.train()\n",
    "        s2.train()\n",
    "        s3.train()\n",
    "\n",
    "        s0opt = COCOB(s0.parameters()) if list(s0.parameters()) else None\n",
    "        saopt = COCOB(sa.parameters()) if list(sa.parameters()) else None\n",
    "        s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "        sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "        s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        if self.dae_steps:\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            X, Y = env.train()\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.L1Loss(reduction='none')\n",
    "            for _ in range(self.dae_steps):\n",
    "                for (_X,) in torch_loader:\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if saopt: saopt.zero_grad()\n",
    "                    loss(sa(s0(_X.nan_to_num())),_X).nanmean().backward()\n",
    "                    if s0opt: s0opt.step()\n",
    "                    if saopt: saopt.step()\n",
    "\n",
    "        if self.ssl_samps:\n",
    "\n",
    "            if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "            if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "\n",
    "            for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps):\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=64,drop_last=True,shuffle=True)\n",
    "\n",
    "                for _A, _P, _N in torch_loader:\n",
    "                    #https://arxiv.org/pdf/2002.05709\n",
    "                    _A = sb(s1(s0(_A.nan_to_num())))\n",
    "                    _P = sb(s1(s0(_P.nan_to_num())))\n",
    "                    _N = sb(s1(s0(_N.nan_to_num())))\n",
    "\n",
    "                    p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                    n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                    p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                    n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                    p = torch.exp(p/self.ssl_tau)\n",
    "                    n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if sbopt: sbopt.zero_grad()\n",
    "                    (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if sbopt: sbopt.step()\n",
    "\n",
    "        if self.ws_steps:\n",
    "\n",
    "            if s0opt: s0opt.zero_grad()\n",
    "            if s1opt: s1opt.zero_grad()\n",
    "            if s2opt: s2opt.zero_grad()\n",
    "            if s3opt: s3opt.zero_grad()\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            X, Y = env.train()\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.BCEWithLogitsLoss()\n",
    "            for _ in range(self.ws_steps):\n",
    "                for _X,_y in torch_loader:\n",
    "\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if s2opt: s2opt.zero_grad()\n",
    "                    if s3opt: s3opt.zero_grad()\n",
    "                    loss(s3(s2(s1(s0(_X.nan_to_num())))),_y).backward()\n",
    "                    if s3opt: s3opt.step()\n",
    "                    if s2opt: s2opt.step()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if s0opt: s0opt.step()\n",
    "\n",
    "        s0.eval()\n",
    "        s1.eval()\n",
    "        s2.eval()\n",
    "        s3.eval()\n",
    "\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        X, Y = env.test()\n",
    "\n",
    "        rng = cb.CobaRandom(1)\n",
    "        while len(set(Y[35:].squeeze().tolist())) == 1:\n",
    "            ind = rng.shuffle(range(len(Y)))\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind]\n",
    "\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        lrnx = []\n",
    "        lrny = []\n",
    "        mems = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            yield {'auc': roc_auc_score(Y[35:],torch.sigmoid(s3(s2(s1(s0(X[35:,:].nan_to_num()))))))}\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "        for i in range(35):\n",
    "\n",
    "            x,y = X[i,:],Y[i]\n",
    "\n",
    "            if self.pers_lrn_cnt:\n",
    "                lrnx.append(x)\n",
    "                lrny.append(y)\n",
    "\n",
    "            if self.pers_mem_cnt: \n",
    "                mems.append([x,y,self.pers_mem_rpt])\n",
    "\n",
    "            if len(mems) > self.pers_mem_cnt:\n",
    "                rng.shuffle(mems, inplace=True)\n",
    "                for j in reversed(range(self.pers_mem_rcl)):\n",
    "                    x,y,n = mems[j]\n",
    "                    lrnx.append(x)\n",
    "                    lrny.append(y)\n",
    "                    if n == 1: mems.pop(j)\n",
    "                    else: mems[j] = [x,y,n-1]\n",
    "\n",
    "            if len(lrnx) >= self.pers_lrn_cnt:\n",
    "                x = torch.stack(lrnx[:self.pers_lrn_cnt])\n",
    "                y = torch.stack(lrny[:self.pers_lrn_cnt])\n",
    "                if s3opt: s3opt.zero_grad()\n",
    "                loss(s3(s2(s1(s0(x.nan_to_num())))),y).backward()\n",
    "                if s3opt: s3opt.step()\n",
    "                lrnx = lrnx[self.pers_lrn_cnt:]\n",
    "                lrny = lrny[self.pers_lrn_cnt:]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                yield {'auc': roc_auc_score(Y[35:],torch.sigmoid(s3(s2(s1(s0(X[35:,:].nan_to_num()))))))}\n",
    "\n",
    "def make_envs(X, Y, G):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "    all_equal = set()\n",
    "    envs = []\n",
    "    for rng in range(5):\n",
    "        for g in sorted(set(G.tolist())):\n",
    "            if (g==G).sum() < 50: continue\n",
    "            trn_x,trn_y = X[g!=G],Y[g!=G]\n",
    "            tst_x,tst_y = X[g==G],Y[g==G]\n",
    "\n",
    "            if len(set(tst_y.squeeze().tolist())) == 1:\n",
    "                all_equal.add(g)\n",
    "            else:\n",
    "                envs.append(MyEnvironment(trn_x,trn_y,tst_x,tst_y,g,rng))\n",
    "\n",
    "    if len(all_equal) > 0:\n",
    "        print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    return envs\n",
    "\n",
    "r = lambda w:  ['l', 'r', w, 'l', 'r', w]\n",
    "\n",
    "lrns = [ FeedForward([]) ]\n",
    "\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((), (), (len(x),30,'l','r'), (30,1), 0, 0, 0, 0, 0, 0, 3, 3, 20, 2, 2),\n",
    "    MyEvaluator((len(x),.2,90,'l','r',len(x)), (), (90,30,'l','r'), (30,1), 16, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2),\n",
    "]\n",
    "\n",
    "envs = make_envs(X3,Y2,G)\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/5/out5_2.log',processes=35,quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70fb137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [2, 25, 61, 82, 87, 89, 99, 103, 111, 117, 146, 196, 203, 227, 246, 311, 319, 357, 377, 390, 451, 455]\n",
      "{'Learners': 1, 'Environments': 228, 'Interactions': 65664}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr):\n",
    "\n",
    "        by_class  = {y: self.train_X[(self.train_Y==y)].tolist() for y in set(self.train_Y.tolist())}\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "\n",
    "        def choose_unique(items,item):\n",
    "            while items[i:=rng.randint(0,len(items)-1)]==item:\n",
    "                pass\n",
    "            return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            while True:\n",
    "                indexes.add(rng.randint(0,len(items)-1))\n",
    "                if len(indexes)==n: return [items[i] for i in indexes]\n",
    "\n",
    "        for _ in range(sr):\n",
    "            anchor, positive, negative = [], [], []\n",
    "            for x,y in zip(self.train_X.tolist(),self.train_Y.tolist()):\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(by_class[y],x))\n",
    "                negative.append(choose_n(by_class[1-y],neg))\n",
    "\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s0, s1, s2, s3, dae_steps, dae_dropn, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, pers_lrn_cnt, pers_mem_cnt, pers_mem_rpt, pers_mem_rcl, v):\n",
    "\n",
    "        self.s0  = s0  #dae + sl\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "        self.s3  = s3  #sl + online\n",
    "\n",
    "        self.dae_steps = dae_steps\n",
    "        self.dae_dropn = dae_dropn\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "\n",
    "        self.pers_lrn_cnt = pers_lrn_cnt\n",
    "        self.pers_mem_cnt = pers_mem_cnt\n",
    "        self.pers_mem_rpt = pers_mem_rpt\n",
    "        self.pers_mem_rcl = pers_mem_rcl\n",
    "\n",
    "        self.v = v\n",
    "\n",
    "        self.params = {'s0': s0, 's1': s1, 's2':s2, 's3':s3, 'dae': (dae_steps,dae_dropn), 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'pers': (pers_lrn_cnt,pers_mem_cnt,pers_mem_rpt,pers_mem_rcl)}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        s0 = FeedForward(self.s0)\n",
    "        s1 = FeedForward(self.s1)\n",
    "        s2 = FeedForward(self.s2)\n",
    "        s3 = FeedForward(self.s3)\n",
    "\n",
    "        sa = torch.nn.Sequential(*list(s0.children())[len(self.s0)-self.dae_dropn:])\n",
    "        s0 = torch.nn.Sequential(*list(s0.children())[:len(self.s0)-self.dae_dropn])\n",
    "\n",
    "        sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "        s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "        s0.train()\n",
    "        sa.train()\n",
    "        s1.train()\n",
    "        sb.train()\n",
    "        s2.train()\n",
    "        s3.train()\n",
    "\n",
    "        s0opt = COCOB(s0.parameters()) if list(s0.parameters()) else None\n",
    "        saopt = COCOB(sa.parameters()) if list(sa.parameters()) else None\n",
    "        s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "        sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "        s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        if self.dae_steps:\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            X, Y = env.train()\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.L1Loss(reduction='none')\n",
    "            for _ in range(self.dae_steps):\n",
    "                for (_X,) in torch_loader:\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if saopt: saopt.zero_grad()\n",
    "                    loss(sa(s0(_X.nan_to_num())),_X).nanmean().backward()\n",
    "                    if s0opt: s0opt.step()\n",
    "                    if saopt: saopt.step()\n",
    "\n",
    "        if self.ssl_samps:\n",
    "\n",
    "            if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "            if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "\n",
    "            for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps):\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=64,drop_last=True,shuffle=True)\n",
    "\n",
    "                for _A, _P, _N in torch_loader:\n",
    "                    #https://arxiv.org/pdf/2002.05709\n",
    "                    _A = sb(s1(s0(_A.nan_to_num())))\n",
    "                    _P = sb(s1(s0(_P.nan_to_num())))\n",
    "                    _N = sb(s1(s0(_N.nan_to_num())))\n",
    "\n",
    "                    p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                    n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                    p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                    n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                    p = torch.exp(p/self.ssl_tau)\n",
    "                    n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if sbopt: sbopt.zero_grad()\n",
    "                    (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if sbopt: sbopt.step()\n",
    "\n",
    "        if self.ws_steps:\n",
    "\n",
    "            if s0opt and self.v: s0opt.zero_grad()\n",
    "            if s1opt: s1opt.zero_grad()\n",
    "            if s2opt: s2opt.zero_grad()\n",
    "            if s3opt: s3opt.zero_grad()\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            X, Y = env.train()\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.BCEWithLogitsLoss()\n",
    "            for _ in range(self.ws_steps):\n",
    "                for _X,_y in torch_loader:\n",
    "\n",
    "                    if s0opt and self.v: s0opt.zero_grad()\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if s2opt: s2opt.zero_grad()\n",
    "                    if s3opt: s3opt.zero_grad()\n",
    "                    loss(s3(s2(s1(s0(_X.nan_to_num())))),_y).backward()\n",
    "                    if s3opt: s3opt.step()\n",
    "                    if s2opt: s2opt.step()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if s0opt and self.v: s0opt.step()\n",
    "\n",
    "        s0.eval()\n",
    "        s1.eval()\n",
    "        s2.eval()\n",
    "        s3.eval()\n",
    "\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        X, Y = env.test()\n",
    "\n",
    "        rng = cb.CobaRandom(1)\n",
    "        while len(set(Y[35:].squeeze().tolist())) == 1:\n",
    "            ind = rng.shuffle(range(len(Y)))\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind]\n",
    "\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        lrnx = []\n",
    "        lrny = []\n",
    "        mems = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            yield {'auc': roc_auc_score(Y[35:],torch.sigmoid(s3(s2(s1(s0(X[35:,:].nan_to_num()))))))}\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "        for i in range(35):\n",
    "\n",
    "            x,y = X[i,:],Y[i]\n",
    "\n",
    "            if self.pers_lrn_cnt:\n",
    "                lrnx.append(x)\n",
    "                lrny.append(y)\n",
    "\n",
    "            if self.pers_mem_cnt: \n",
    "                mems.append([x,y,self.pers_mem_rpt])\n",
    "\n",
    "            if len(mems) > self.pers_mem_cnt:\n",
    "                rng.shuffle(mems, inplace=True)\n",
    "                for j in reversed(range(self.pers_mem_rcl)):\n",
    "                    x,y,n = mems[j]\n",
    "                    lrnx.append(x)\n",
    "                    lrny.append(y)\n",
    "                    if n == 1: mems.pop(j)\n",
    "                    else: mems[j] = [x,y,n-1]\n",
    "\n",
    "            if len(lrnx) >= self.pers_lrn_cnt:\n",
    "                x = torch.stack(lrnx[:self.pers_lrn_cnt])\n",
    "                y = torch.stack(lrny[:self.pers_lrn_cnt])\n",
    "                if s3opt: s3opt.zero_grad()\n",
    "                loss(s3(s2(s1(s0(x.nan_to_num())))),y).backward()\n",
    "                if s3opt: s3opt.step()\n",
    "                lrnx = lrnx[self.pers_lrn_cnt:]\n",
    "                lrny = lrny[self.pers_lrn_cnt:]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                yield {'auc': roc_auc_score(Y[35:],torch.sigmoid(s3(s2(s1(s0(X[35:,:].nan_to_num()))))))}\n",
    "\n",
    "def make_envs(X, Y, G):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "    all_equal = set()\n",
    "    envs = []\n",
    "    for rng in range(1):\n",
    "        for g in sorted(set(G.tolist())):\n",
    "            if (g==G).sum() < 50: continue\n",
    "            trn_x,trn_y = X[g!=G],Y[g!=G]\n",
    "            tst_x,tst_y = X[g==G],Y[g==G]\n",
    "\n",
    "            if len(set(tst_y.squeeze().tolist())) == 1:\n",
    "                all_equal.add(g)\n",
    "            else:\n",
    "                envs.append(MyEnvironment(trn_x,trn_y,tst_x,tst_y,g,rng))\n",
    "\n",
    "    if len(all_equal) > 0:\n",
    "        print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    return envs\n",
    "\n",
    "r = lambda w:  ['l', 'r', w, 'l', 'r', w]\n",
    "\n",
    "lrns = [ FeedForward([]) ]\n",
    "\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),.1,90,'l','r',len(x)), (), (90,30,'l','r'), (30,1), 8, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.2,90,'l','r',len(x)), (), (90,30,'l','r'), (30,1), 8, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.3,90,'l','r',len(x)), (), (90,30,'l','r'), (30,1), 8, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.2,90,'l','r',len(x)), (), (90,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.2,90,'l','r',len(x)), (), (90,30,'l','r'), (30,1), 4, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.2,90,'l','r',len(x)), (), (90,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, False),\n",
    "    MyEvaluator((len(x),.2,90,'l','r',len(x)), (), (90,30,'l','r'), (30,1), 0, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),   90,'l','r',len(x)), (), (90,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "]\n",
    "\n",
    "envs = make_envs(X3,Y2,G)\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/5/out5_3.log',processes=35,quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a88fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [2, 25, 61, 82, 87, 89, 99, 103, 111, 117, 146, 196, 203, 227, 246, 311, 319, 357, 377, 390, 451, 455]\n",
      "{'Learners': 1, 'Environments': 228, 'Interactions': 139536}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr):\n",
    "\n",
    "        by_class  = {y: self.train_X[(self.train_Y==y)].tolist() for y in set(self.train_Y.tolist())}\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "\n",
    "        def choose_unique(items,item):\n",
    "            while items[i:=rng.randint(0,len(items)-1)]==item:\n",
    "                pass\n",
    "            return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            while True:\n",
    "                indexes.add(rng.randint(0,len(items)-1))\n",
    "                if len(indexes)==n: return [items[i] for i in indexes]\n",
    "\n",
    "        for _ in range(sr):\n",
    "            anchor, positive, negative = [], [], []\n",
    "            for x,y in zip(self.train_X.tolist(),self.train_Y.tolist()):\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(by_class[y],x))\n",
    "                negative.append(choose_n(by_class[1-y],neg))\n",
    "\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s0, s1, s2, s3, dae_steps, dae_dropn, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, pers_lrn_cnt, pers_mem_cnt, pers_mem_rpt, pers_mem_rcl, v):\n",
    "\n",
    "        self.s0  = s0  #dae + sl\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "        self.s3  = s3  #sl + online\n",
    "\n",
    "        self.dae_steps = dae_steps\n",
    "        self.dae_dropn = dae_dropn\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "\n",
    "        self.pers_lrn_cnt = pers_lrn_cnt\n",
    "        self.pers_mem_cnt = pers_mem_cnt\n",
    "        self.pers_mem_rpt = pers_mem_rpt\n",
    "        self.pers_mem_rcl = pers_mem_rcl\n",
    "\n",
    "        self.v = v\n",
    "\n",
    "        self.params = {'s0': s0, 's1': s1, 's2':s2, 's3':s3, 'dae': (dae_steps,dae_dropn), 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'pers': (pers_lrn_cnt,pers_mem_cnt,pers_mem_rpt,pers_mem_rcl)}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        s0 = FeedForward(self.s0)\n",
    "        s1 = FeedForward(self.s1)\n",
    "        s2 = FeedForward(self.s2)\n",
    "        s3 = FeedForward(self.s3)\n",
    "\n",
    "        sa = torch.nn.Sequential(*list(s0.children())[len(self.s0)-self.dae_dropn:])\n",
    "        s0 = torch.nn.Sequential(*list(s0.children())[:len(self.s0)-self.dae_dropn])\n",
    "\n",
    "        sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "        s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "        s0.train()\n",
    "        sa.train()\n",
    "        s1.train()\n",
    "        sb.train()\n",
    "        s2.train()\n",
    "        s3.train()\n",
    "\n",
    "        s0opt = COCOB(s0.parameters()) if list(s0.parameters()) else None\n",
    "        saopt = COCOB(sa.parameters()) if list(sa.parameters()) else None\n",
    "        s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "        sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "        s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        if self.dae_steps:\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            X, Y = env.train()\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.L1Loss(reduction='none')\n",
    "            for _ in range(self.dae_steps):\n",
    "                for (_X,) in torch_loader:\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if saopt: saopt.zero_grad()\n",
    "                    loss(sa(s0(_X.nan_to_num())),_X).nanmean().backward()\n",
    "                    if s0opt: s0opt.step()\n",
    "                    if saopt: saopt.step()\n",
    "\n",
    "        if self.ssl_samps:\n",
    "\n",
    "            if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "            if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "\n",
    "            for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps):\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=64,drop_last=True,shuffle=True)\n",
    "\n",
    "                for _A, _P, _N in torch_loader:\n",
    "                    #https://arxiv.org/pdf/2002.05709\n",
    "                    _A = sb(s1(s0(_A.nan_to_num())))\n",
    "                    _P = sb(s1(s0(_P.nan_to_num())))\n",
    "                    _N = sb(s1(s0(_N.nan_to_num())))\n",
    "\n",
    "                    p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                    n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                    p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                    n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                    p = torch.exp(p/self.ssl_tau)\n",
    "                    n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if sbopt: sbopt.zero_grad()\n",
    "                    (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if sbopt: sbopt.step()\n",
    "\n",
    "        if self.ws_steps:\n",
    "\n",
    "            if s0opt and self.v: s0opt.zero_grad()\n",
    "            if s1opt: s1opt.zero_grad()\n",
    "            if s2opt: s2opt.zero_grad()\n",
    "            if s3opt: s3opt.zero_grad()\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            X, Y = env.train()\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.BCEWithLogitsLoss()\n",
    "            for _ in range(self.ws_steps):\n",
    "                for _X,_y in torch_loader:\n",
    "\n",
    "                    if s0opt and self.v: s0opt.zero_grad()\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if s2opt: s2opt.zero_grad()\n",
    "                    if s3opt: s3opt.zero_grad()\n",
    "                    loss(s3(s2(s1(s0(_X.nan_to_num())))),_y).backward()\n",
    "                    if s3opt: s3opt.step()\n",
    "                    if s2opt: s2opt.step()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if s0opt and self.v: s0opt.step()\n",
    "\n",
    "        s0.eval()\n",
    "        s1.eval()\n",
    "        s2.eval()\n",
    "        s3.eval()\n",
    "\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        X, Y = env.test()\n",
    "\n",
    "        rng = cb.CobaRandom(1)\n",
    "        while len(set(Y[35:].squeeze().tolist())) == 1:\n",
    "            ind = rng.shuffle(range(len(Y)))\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind]\n",
    "\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        lrnx = []\n",
    "        lrny = []\n",
    "        mems = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            yield {'auc': roc_auc_score(Y[35:],torch.sigmoid(s3(s2(s1(s0(X[35:,:].nan_to_num()))))))}\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "        for i in range(35):\n",
    "\n",
    "            x,y = X[i,:],Y[i]\n",
    "\n",
    "            if self.pers_lrn_cnt:\n",
    "                lrnx.append(x)\n",
    "                lrny.append(y)\n",
    "\n",
    "            if self.pers_mem_cnt: \n",
    "                mems.append([x,y,self.pers_mem_rpt])\n",
    "\n",
    "            if len(mems) > self.pers_mem_cnt:\n",
    "                rng.shuffle(mems, inplace=True)\n",
    "                for j in reversed(range(self.pers_mem_rcl)):\n",
    "                    x,y,n = mems[j]\n",
    "                    lrnx.append(x)\n",
    "                    lrny.append(y)\n",
    "                    if n == 1: mems.pop(j)\n",
    "                    else: mems[j] = [x,y,n-1]\n",
    "\n",
    "            if len(lrnx) >= self.pers_lrn_cnt:\n",
    "                x = torch.stack(lrnx[:self.pers_lrn_cnt])\n",
    "                y = torch.stack(lrny[:self.pers_lrn_cnt])\n",
    "                if s3opt: s3opt.zero_grad()\n",
    "                loss(s3(s2(s1(s0(x.nan_to_num())))),y).backward()\n",
    "                if s3opt: s3opt.step()\n",
    "                lrnx = lrnx[self.pers_lrn_cnt:]\n",
    "                lrny = lrny[self.pers_lrn_cnt:]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                yield {'auc': roc_auc_score(Y[35:],torch.sigmoid(s3(s2(s1(s0(X[35:,:].nan_to_num()))))))}\n",
    "\n",
    "def make_envs(X, Y, G):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "    all_equal = set()\n",
    "    envs = []\n",
    "    for rng in range(1):\n",
    "        for g in sorted(set(G.tolist())):\n",
    "            if (g==G).sum() < 50: continue\n",
    "            trn_x,trn_y = X[g!=G],Y[g!=G]\n",
    "            tst_x,tst_y = X[g==G],Y[g==G]\n",
    "\n",
    "            if len(set(tst_y.squeeze().tolist())) == 1:\n",
    "                all_equal.add(g)\n",
    "            else:\n",
    "                envs.append(MyEnvironment(trn_x,trn_y,tst_x,tst_y,g,rng))\n",
    "\n",
    "    if len(all_equal) > 0:\n",
    "        print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    return envs\n",
    "\n",
    "r = lambda w:  ['l', 'r', w, 'l', 'r', w]\n",
    "\n",
    "lrns = [ FeedForward([]) ]\n",
    "\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),.1,90 ,'l','r',len(x)), (), (90 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.3,90 ,'l','r',len(x)), (), (90 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x)   ,45 ,'l','r',len(x)), (), (45 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.1,45 ,'l','r',len(x)), (), (45 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.2,45 ,'l','r',len(x)), (), (45 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.3,45 ,'l','r',len(x)), (), (45 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x)   ,30 ,'l','r',len(x)), (), (30 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.1,30 ,'l','r',len(x)), (), (30 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.2,30 ,'l','r',len(x)), (), (30 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.3,30 ,'l','r',len(x)), (), (30 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.2,75 ,'l','r',len(x)), (), (75 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.2,120,'l','r',len(x)), (), (120,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',90,'l','r',len(x)), (), (90,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',30,'l','r',len(x)), (), (30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (), (90,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "    MyEvaluator((len(x),.2,90 ,.2,'r',90,'l','r',len(x)), (), (90,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, True),\n",
    "]\n",
    "\n",
    "envs = make_envs(X3,Y2,G)\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/5/out5_4.log',processes=35,quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a01024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [2, 25, 61, 82, 87, 89, 99, 103, 111, 117, 146, 196, 203, 227, 246, 311, 319, 357, 377, 390, 447, 451, 455, 469]\n",
      "{'Learners': 1, 'Environments': 226, 'Interactions': 122040}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr):\n",
    "\n",
    "        by_class  = {y: self.train_X[(self.train_Y==y)].tolist() for y in set(self.train_Y.tolist())}\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "\n",
    "        def choose_unique(items,item):\n",
    "            while items[i:=rng.randint(0,len(items)-1)]==item:\n",
    "                pass\n",
    "            return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            while True:\n",
    "                indexes.add(rng.randint(0,len(items)-1))\n",
    "                if len(indexes)==n: return [items[i] for i in indexes]\n",
    "\n",
    "        for _ in range(sr):\n",
    "            anchor, positive, negative = [], [], []\n",
    "            for x,y in zip(self.train_X.tolist(),self.train_Y.tolist()):\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(by_class[y],x))\n",
    "                negative.append(choose_n(by_class[1-y],neg))\n",
    "\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s0, s1, s2, s3, dae_steps, dae_dropn, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, pers_lrn_cnt, pers_mem_cnt, pers_mem_rpt, pers_mem_rcl, y):\n",
    "\n",
    "        self.s0  = s0  #dae + sl\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "        self.s3  = s3  #sl + pers\n",
    "\n",
    "        self.dae_steps = dae_steps\n",
    "        self.dae_dropn = dae_dropn\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "\n",
    "        self.pers_lrn_cnt = pers_lrn_cnt\n",
    "        self.pers_mem_cnt = pers_mem_cnt\n",
    "        self.pers_mem_rpt = pers_mem_rpt\n",
    "        self.pers_mem_rcl = pers_mem_rcl\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = {'s0': s0, 's1': s1, 's2':s2, 's3':s3, 'dae': (dae_steps,dae_dropn), 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'pers': (pers_lrn_cnt,pers_mem_cnt,pers_mem_rpt,pers_mem_rcl), 'y': y}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        s0 = FeedForward(self.s0)\n",
    "        s1 = FeedForward(self.s1)\n",
    "        s2 = FeedForward(self.s2)\n",
    "        s3 = FeedForward(self.s3)\n",
    "\n",
    "        sa = torch.nn.Sequential(*list(s0.children())[len(self.s0)-self.dae_dropn:])\n",
    "        s0 = torch.nn.Sequential(*list(s0.children())[:len(self.s0)-self.dae_dropn])\n",
    "\n",
    "        sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "        s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "        s0.train()\n",
    "        sa.train()\n",
    "        s1.train()\n",
    "        sb.train()\n",
    "        s2.train()\n",
    "        s3.train()\n",
    "\n",
    "        s0opt = COCOB(s0.parameters()) if list(s0.parameters()) else None\n",
    "        saopt = COCOB(sa.parameters()) if list(sa.parameters()) else None\n",
    "        s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "        sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "        s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        if self.dae_steps:\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            X = env.train()[0]\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.L1Loss(reduction='none')\n",
    "            for _ in range(self.dae_steps):\n",
    "                for (_X,) in torch_loader:\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if saopt: saopt.zero_grad()\n",
    "                    loss(sa(s0(_X.nan_to_num())),_X).nanmean().backward()\n",
    "                    if s0opt: s0opt.step()\n",
    "                    if saopt: saopt.step()\n",
    "\n",
    "        if self.ssl_samps:\n",
    "\n",
    "            if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "            if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "\n",
    "            for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps):\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=64,drop_last=True,shuffle=True)\n",
    "\n",
    "                for _A, _P, _N in torch_loader:\n",
    "                    #https://arxiv.org/pdf/2002.05709\n",
    "                    _A = sb(s1(s0(_A.nan_to_num())))\n",
    "                    _P = sb(s1(s0(_P.nan_to_num())))\n",
    "                    _N = sb(s1(s0(_N.nan_to_num())))\n",
    "\n",
    "                    p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                    n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                    p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                    n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                    p = torch.exp(p/self.ssl_tau)\n",
    "                    n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if sbopt: sbopt.zero_grad()\n",
    "                    (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if sbopt: sbopt.step()\n",
    "\n",
    "        if self.ws_steps:\n",
    "\n",
    "            if s0opt: s0opt.zero_grad()\n",
    "            if s1opt: s1opt.zero_grad()\n",
    "            if s2opt: s2opt.zero_grad()\n",
    "            if s3opt: s3opt.zero_grad()\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            \n",
    "            X, Y = env.train()\n",
    "            Y = Y[:,self.y]\n",
    "            \n",
    "            torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.BCEWithLogitsLoss()\n",
    "            for _ in range(self.ws_steps):\n",
    "                for _X,_y in torch_loader:\n",
    "\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if s2opt: s2opt.zero_grad()\n",
    "                    if s3opt: s3opt.zero_grad()\n",
    "                    loss(s3(s2(s1(s0(_X.nan_to_num())))),_y).backward()\n",
    "                    if s3opt: s3opt.step()\n",
    "                    if s2opt: s2opt.step()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if s0opt: s0opt.step()\n",
    "\n",
    "        s0.eval()\n",
    "        s1.eval()\n",
    "        s2.eval()\n",
    "        s3.eval()\n",
    "\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        rng = cb.CobaRandom(1)\n",
    "        while 1 in [len(set(Y[35:,i].tolist())) for i in range(Y.shape[1])]:\n",
    "            ind = rng.shuffle(range(len(Y)))\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind,:]\n",
    "\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        lrnx = []\n",
    "        lrny = []\n",
    "        mems = []\n",
    "\n",
    "        def predict(X):\n",
    "            return torch.sigmoid(s3(s2(s1(s0(X.nan_to_num())))))\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X[:,:])[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "        for i in range(35):\n",
    "\n",
    "            x,y = X[i,:], Y[i,:]\n",
    "\n",
    "            if self.pers_lrn_cnt:\n",
    "                lrnx.append(x)\n",
    "                lrny.append(y)\n",
    "\n",
    "            if self.pers_mem_cnt: \n",
    "                mems.append([x,y,self.pers_mem_rpt])\n",
    "\n",
    "            if len(mems) > self.pers_mem_cnt:\n",
    "                rng.shuffle(mems, inplace=True)\n",
    "                for j in reversed(range(self.pers_mem_rcl)):\n",
    "                    x,y,n = mems[j]\n",
    "                    lrnx.append(x)\n",
    "                    lrny.append(y)\n",
    "                    if n == 1: mems.pop(j)\n",
    "                    else: mems[j] = [x,y,n-1]\n",
    "\n",
    "            if len(lrnx) >= self.pers_lrn_cnt:\n",
    "                x = torch.stack(lrnx[:self.pers_lrn_cnt])\n",
    "                y = torch.stack(lrny[:self.pers_lrn_cnt])\n",
    "                if s3opt: s3opt.zero_grad()\n",
    "                loss(s3(s2(s1(s0(x.nan_to_num())))),y).backward()\n",
    "                if s3opt: s3opt.step()\n",
    "                lrnx = lrnx[self.pers_lrn_cnt:]\n",
    "                lrny = lrny[self.pers_lrn_cnt:]\n",
    "\n",
    "            yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "def make_envs(X, Y, G):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "    all_equal = set()\n",
    "    envs = []\n",
    "    for rng in range(1):\n",
    "        for g in sorted(set(G.tolist())):\n",
    "            if (g==G).sum() < 50: continue\n",
    "            trn_x,trn_y = X[g!=G],Y[g!=G]\n",
    "            tst_x,tst_y = X[g==G],Y[g==G]\n",
    "\n",
    "            if 1 in [len(set(tst_y[:,i].tolist())) for i in range(tst_y.shape[1])]:\n",
    "                all_equal.add(g)\n",
    "                continue\n",
    "\n",
    "            envs.append(MyEnvironment(trn_x,trn_y,tst_x,tst_y,g,rng))\n",
    "\n",
    "    if len(all_equal) > 0:\n",
    "        print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    return envs\n",
    "\n",
    "r = lambda w:  ['l', 'r', w, 'l', 'r', w]\n",
    "\n",
    "lrns = [ FeedForward([]) ]\n",
    "\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [0]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,30,'l','r'), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,30,'l','r'), (30,2), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [0,1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,30,'l','r'), (30,2), 2, 3, 0, 0, 0, 0, 4, 3, 20, 2, 2, [0,1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,30,'l','r'), (30,2), 2, 3, 0, 0, 0, 0, 5, 3, 20, 2, 2, [0,1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,45,'l','r'), (45,2), 2, 3, 0, 0, 0, 0, 4, 3, 20, 2, 2, [0,1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,45,'l','r'), (45,2), 2, 3, 0, 0, 0, 0, 5, 3, 20, 2, 2, [0,1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,30,'l','r'), (30,2), 2, 3, 0, 0, 0, 0, 6, 3, 20, 2, 2, [0,1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,30,'l','r'), (30,2), 2, 3, 0, 0, 0, 0, 7, 3, 20, 2, 2, [0,1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,45,'l','r'), (45,2), 2, 3, 0, 0, 0, 0, 6, 3, 20, 2, 2, [0,1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,45,'l','r'), (45,2), 2, 3, 0, 0, 0, 0, 7, 3, 20, 2, 2, [0,1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,90,'l','r'), (90,2), 2, 3, 0, 0, 0, 0, 7, 3, 20, 2, 2, [0,1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,45,'l','r'), (45,1), 2, 3, 0, 0, 0, 0, 7, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,45,'l','r'), (45,2), 2, 3, 0, 0, 0, 0, 10, 3, 20, 2, 2, [0,1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90 ,90,'l','r'), (90,2), 2, 3, 0, 0, 0, 0, 10, 3, 20, 2, 2, [0,1]),\n",
    "]\n",
    "\n",
    "envs = make_envs(X3,np.hstack([Y1,Y2]),G)\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/5/out5_5.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f4da73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [2, 25, 61, 82, 87, 89, 99, 103, 111, 117, 146, 196, 203, 227, 246, 311, 319, 357, 377, 390, 447, 451, 455, 469]\n",
      "{'Learners': 1, 'Environments': 226, 'Interactions': 146448}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,i):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()    \n",
    "        Y = self.train_Y[:,i]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_indexes))\n",
    "        Y = list(map(Y.__getitem__,rng_indexes))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "\n",
    "        def choose_unique(items,item):\n",
    "            while items[i:=rng.randint(0,len(items)-1)]==item:\n",
    "                pass\n",
    "            return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            while True:\n",
    "                indexes.add(rng.randint(0,len(items)-1))\n",
    "                if len(indexes)==n: return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],x))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for x,y in zip(X,Y):\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],x))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s0, s1, s2, s3, dae_steps, dae_dropn, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, pers_lrn_cnt, pers_mem_cnt, pers_mem_rpt, pers_mem_rcl, y):\n",
    "\n",
    "        self.s0  = s0  #dae + sl\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "        self.s3  = s3  #sl + pers\n",
    "\n",
    "        self.dae_steps = dae_steps\n",
    "        self.dae_dropn = dae_dropn\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "\n",
    "        self.pers_lrn_cnt = pers_lrn_cnt\n",
    "        self.pers_mem_cnt = pers_mem_cnt\n",
    "        self.pers_mem_rpt = pers_mem_rpt\n",
    "        self.pers_mem_rcl = pers_mem_rcl\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = {'s0': s0, 's1': s1, 's2':s2, 's3':s3, 'dae': (dae_steps,dae_dropn), 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'pers': (pers_lrn_cnt,pers_mem_cnt,pers_mem_rpt,pers_mem_rcl), 'y': y}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        s0 = FeedForward(self.s0)\n",
    "        s1 = FeedForward(self.s1)\n",
    "        s2 = FeedForward(self.s2)\n",
    "        s3 = FeedForward(self.s3)\n",
    "\n",
    "        sa = torch.nn.Sequential(*list(s0.children())[len(self.s0)-self.dae_dropn:])\n",
    "        s0 = torch.nn.Sequential(*list(s0.children())[:len(self.s0)-self.dae_dropn])\n",
    "\n",
    "        sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "        s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "        s0.train()\n",
    "        sa.train()\n",
    "        s1.train()\n",
    "        sb.train()\n",
    "        s2.train()\n",
    "        s3.train()\n",
    "\n",
    "        s0opt = COCOB(s0.parameters()) if list(s0.parameters()) else None\n",
    "        saopt = COCOB(sa.parameters()) if list(sa.parameters()) else None\n",
    "        s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "        sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "        s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        if self.dae_steps:\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            X = env.train()[0]\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.L1Loss(reduction='none')\n",
    "            for _ in range(self.dae_steps):\n",
    "                for (_X,) in torch_loader:\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if saopt: saopt.zero_grad()\n",
    "                    loss(sa(s0(_X.nan_to_num())),_X).nanmean().backward()\n",
    "                    if s0opt: s0opt.step()\n",
    "                    if saopt: saopt.step()\n",
    "\n",
    "        if self.ssl_samps:\n",
    "\n",
    "            if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "            if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "\n",
    "            for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=64,drop_last=True,shuffle=True)\n",
    "\n",
    "                for _A, _P, _N in torch_loader:\n",
    "                    #https://arxiv.org/pdf/2002.05709\n",
    "                    _A = sb(s1(s0(_A.nan_to_num())))\n",
    "                    _P = sb(s1(s0(_P.nan_to_num())))\n",
    "                    _N = sb(s1(s0(_N.nan_to_num())))\n",
    "\n",
    "                    p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                    n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                    p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                    n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                    p = torch.exp(p/self.ssl_tau)\n",
    "                    n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if sbopt: sbopt.zero_grad()\n",
    "                    (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if sbopt: sbopt.step()\n",
    "\n",
    "        if self.ws_steps:\n",
    "\n",
    "            if s0opt: s0opt.zero_grad()\n",
    "            if s1opt: s1opt.zero_grad()\n",
    "            if s2opt: s2opt.zero_grad()\n",
    "            if s3opt: s3opt.zero_grad()\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            \n",
    "            X, Y = env.train()\n",
    "            Y = Y[:,self.y]\n",
    "            \n",
    "            torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.BCEWithLogitsLoss()\n",
    "            for _ in range(self.ws_steps):\n",
    "                for _X,_y in torch_loader:\n",
    "\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if s2opt: s2opt.zero_grad()\n",
    "                    if s3opt: s3opt.zero_grad()\n",
    "                    loss(s3(s2(s1(s0(_X.nan_to_num())))),_y).backward()\n",
    "                    if s3opt: s3opt.step()\n",
    "                    if s2opt: s2opt.step()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if s0opt: s0opt.step()\n",
    "\n",
    "        s0.eval()\n",
    "        s1.eval()\n",
    "        s2.eval()\n",
    "        s3.eval()\n",
    "\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        rng = cb.CobaRandom(1)\n",
    "        while 1 in [len(set(Y[35:,i].tolist())) for i in range(Y.shape[1])]:\n",
    "            ind = rng.shuffle(range(len(Y)))\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind,:]\n",
    "\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        lrnx = []\n",
    "        lrny = []\n",
    "        mems = []\n",
    "\n",
    "        def predict(X):\n",
    "            return torch.sigmoid(s3(s2(s1(s0(X.nan_to_num())))))\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X[:,:])[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "        for i in range(35):\n",
    "\n",
    "            x,y = X[i,:], Y[i,:]\n",
    "\n",
    "            if self.pers_lrn_cnt:\n",
    "                lrnx.append(x)\n",
    "                lrny.append(y)\n",
    "\n",
    "            if self.pers_mem_cnt: \n",
    "                mems.append([x,y,self.pers_mem_rpt])\n",
    "\n",
    "            if len(mems) > self.pers_mem_cnt:\n",
    "                rng.shuffle(mems, inplace=True)\n",
    "                for j in reversed(range(self.pers_mem_rcl)):\n",
    "                    x,y,n = mems[j]\n",
    "                    lrnx.append(x)\n",
    "                    lrny.append(y)\n",
    "                    if n == 1: mems.pop(j)\n",
    "                    else: mems[j] = [x,y,n-1]\n",
    "\n",
    "            if len(lrnx) >= self.pers_lrn_cnt:\n",
    "                x = torch.stack(lrnx[:self.pers_lrn_cnt])\n",
    "                y = torch.stack(lrny[:self.pers_lrn_cnt])\n",
    "                if s3opt: s3opt.zero_grad()\n",
    "                loss(s3(s2(s1(s0(x.nan_to_num())))),y).backward()\n",
    "                if s3opt: s3opt.step()\n",
    "                lrnx = lrnx[self.pers_lrn_cnt:]\n",
    "                lrny = lrny[self.pers_lrn_cnt:]\n",
    "\n",
    "            yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "def make_envs(X, Y, G):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "    all_equal = set()\n",
    "    envs = []\n",
    "    for rng in range(1):\n",
    "        for g in sorted(set(G.tolist())):\n",
    "            if (g==G).sum() < 50: continue\n",
    "            trn_x,trn_y = X[g!=G],Y[g!=G]\n",
    "            tst_x,tst_y = X[g==G],Y[g==G]\n",
    "\n",
    "            if 1 in [len(set(tst_y[:,i].tolist())) for i in range(tst_y.shape[1])]:\n",
    "                all_equal.add(g)\n",
    "                continue\n",
    "\n",
    "            envs.append(MyEnvironment(trn_x,trn_y,tst_x,tst_y,g,rng))\n",
    "\n",
    "    if len(all_equal) > 0:\n",
    "        print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    return envs\n",
    "\n",
    "r = lambda w:  ['l', 'r', w, 'l', 'r', w]\n",
    "\n",
    "lrns = [ FeedForward([]) ]\n",
    "\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,30,'l','r',30,'l','r',30,'l','r'), (), (30,1), 2, 3, 1, 5, 3, 1, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,30,'l','r',30,'l','r',30,'l','r'), (), (30,1), 2, 3, 2, 5, 3, 1, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,30,'l','r',30,'l','r',30,'l','r'), (), (30,1), 2, 3, 0, 5, 3, 1, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,30,'l','r',30,'l','r',30,'l','r'), (), (30,1), 2, 3, .5, 5, 3, 1, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,30,'l','r',30,'l','r',30,'l','r'), (), (30,1), 2, 3, .5, 5, 6, 1, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,30,'l','r',), (), (30,1), 2, 3, .5, 5, 0, 1, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,30,'l','r',), (), (30,1), 2, 3, .25, 5, 0, 1, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,30,'l','r',), (), (30,1), 2, 3, .75, 5, 0, 1, 3, 3, 20, 2, 2, [1]),    \n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,30,'l','r',), (), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,30,'l','r',30,'l','r',), (), (30,1), 2, 3, .25, 5, 3, 1, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,30,'l','r',30,'l','r',), (), (30,1), 2, 3, .50, 5, 3, 1, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,30,'l','r',30,'l','r',), (), (30,1), 2, 3, .75, 5, 3, 1, 3, 3, 20, 2, 2, [1]),\n",
    "\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,45,'l','r',), (), (45,1), 2, 3, .5, 5, 0, 1, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,90,'l','r',), (), (90,1), 2, 3, .5, 5, 0, 1, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,90,'l','r',), (), (90,1), 2, 3, .5, 5, 0, 1, 3, 5, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,45,'l','r',), (), (45,1), 2, 3, .25, 5, 0, 1, 3, 3, 20, 2, 2, [1]),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (90,45,'l','r',), (), (45,1), 2, 3, .75, 5, 0, 1, 3, 3, 20, 2, 2, [1]),\n",
    "]\n",
    "\n",
    "envs = make_envs(X3,np.hstack([Y1,Y2]),G)\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/5/out5_6.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd9f4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [2, 25, 61, 82, 87, 89, 99, 103, 111, 117, 146, 196, 203, 227, 246, 311, 319, 357, 377, 390, 447, 451, 455, 469]\n",
      "{'Learners': 1, 'Environments': 92, 'Interactions': 8676}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class EMT:\n",
    "\n",
    "    def __init__(self, split:int = 100, scorer:str=\"self_consistent_rank\", bound:int=0, features=[1,'x']) -> None:\n",
    "\n",
    "        self.params = {'split':split, 'scorer':scorer, 'bound':bound, 'features':features}\n",
    "\n",
    "        feat_args = []\n",
    "        if 1   not in features: feat_args.append('--noconstant')\n",
    "        if 'a' not in features: feat_args.append('--ignore_linear a')\n",
    "        if 'x' not in features: feat_args.append('--ignore_linear x')\n",
    "        feat_args += [ f'--interactions {f}' for f in features if f not in {1, 'a', 'x'} ]\n",
    "\n",
    "        vw_args = [\n",
    "            \"--emt\",\n",
    "            f\"--emt_tree {bound}\",\n",
    "            f\"--emt_leaf {split}\",\n",
    "            f\"--emt_scorer {scorer}\",\n",
    "            f\"--emt_router {'eigen'}\",\n",
    "            f\"-b {26}\",\n",
    "            \"--min_prediction 0\",\n",
    "            \"--max_prediction 3\",\n",
    "            \"--coin\",\n",
    "            \"--initial_weight 0\",\n",
    "            *feat_args,\n",
    "            '--quiet',\n",
    "            '--random_seed 1337'\n",
    "        ]\n",
    "\n",
    "        self._vw = cb.VowpalMediator()\n",
    "        self._vw_args = ' '.join(vw_args)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self._vw.is_initialized: self._vw.init_learner(self._vw_args, label_type=2)\n",
    "        return torch.tensor([[float(self._vw.predict(self._vw.make_example({'x':x}, None)))] for x in X.tolist()])\n",
    "\n",
    "    def learn(self, X, Y):\n",
    "        if not self._vw.is_initialized: self._vw.init_learner(self._vw_args, label_type=2)\n",
    "        for x,y in zip(X.tolist(),Y.squeeze(1).tolist()):\n",
    "            self._vw.learn(self._vw.make_example({'x':x}, f\"{int(y)} 1\"))\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,i):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()    \n",
    "        Y = self.train_Y[:,i]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_indexes))\n",
    "        Y = list(map(Y.__getitem__,rng_indexes))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "\n",
    "        def choose_unique(items,item):\n",
    "            while items[i:=rng.randint(0,len(items)-1)]==item:\n",
    "                pass\n",
    "            return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            while True:\n",
    "                indexes.add(rng.randint(0,len(items)-1))\n",
    "                if len(indexes)==n: return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],x))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for x,y in zip(X,Y):\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],x))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s0, s1, s2, s3, dae_steps, dae_dropn, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, pers_lrn_cnt, pers_mem_cnt, pers_mem_rpt, pers_mem_rcl, y, emt_cnt, emt_bound):\n",
    "\n",
    "        self.s0  = s0  #dae + sl\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "        self.s3  = s3  #sl + pers\n",
    "\n",
    "        self.dae_steps = dae_steps\n",
    "        self.dae_dropn = dae_dropn\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "\n",
    "        self.pers_lrn_cnt = pers_lrn_cnt\n",
    "        self.pers_mem_cnt = pers_mem_cnt\n",
    "        self.pers_mem_rpt = pers_mem_rpt\n",
    "        self.pers_mem_rcl = pers_mem_rcl\n",
    "\n",
    "        self.emt_cnt = emt_cnt\n",
    "        self.emt_bound = emt_bound\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = {'s0': s0, 's1': s1, 's2':s2, 's3':s3, 'dae': (dae_steps,dae_dropn), 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'pers': (pers_lrn_cnt,pers_mem_cnt,pers_mem_rpt,pers_mem_rcl), 'y': y, 'emt':(emt_cnt,emt_bound)}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        emt = EMT(bound=self.emt_bound)\n",
    "\n",
    "        s0 = FeedForward(self.s0)\n",
    "        s1 = FeedForward(self.s1)\n",
    "        s2 = FeedForward(self.s2)\n",
    "        s3 = FeedForward(self.s3)\n",
    "\n",
    "        sa = torch.nn.Sequential(*list(s0.children())[len(self.s0)-self.dae_dropn:])\n",
    "        s0 = torch.nn.Sequential(*list(s0.children())[:len(self.s0)-self.dae_dropn])\n",
    "\n",
    "        sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "        s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "        s0.train()\n",
    "        sa.train()\n",
    "        s1.train()\n",
    "        sb.train()\n",
    "        s2.train()\n",
    "        s3.train()\n",
    "\n",
    "        s0opt = COCOB(s0.parameters()) if list(s0.parameters()) else None\n",
    "        saopt = COCOB(sa.parameters()) if list(sa.parameters()) else None\n",
    "        s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "        sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "        s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        if self.dae_steps:\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            X = env.train()[0]\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.L1Loss(reduction='none')\n",
    "            for _ in range(self.dae_steps):\n",
    "                for (_X,) in torch_loader:\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if saopt: saopt.zero_grad()\n",
    "                    loss(sa(s0(_X.nan_to_num())),_X).nanmean().backward()\n",
    "                    if s0opt: s0opt.step()\n",
    "                    if saopt: saopt.step()\n",
    "\n",
    "        if self.ssl_samps:\n",
    "\n",
    "            if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "            if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "\n",
    "            for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=64,drop_last=True,shuffle=True)\n",
    "\n",
    "                for _A, _P, _N in torch_loader:\n",
    "                    #https://arxiv.org/pdf/2002.05709\n",
    "                    _A = sb(s1(s0(_A.nan_to_num())))\n",
    "                    _P = sb(s1(s0(_P.nan_to_num())))\n",
    "                    _N = sb(s1(s0(_N.nan_to_num())))\n",
    "\n",
    "                    p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                    n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                    p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                    n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                    p = torch.exp(p/self.ssl_tau)\n",
    "                    n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if sbopt: sbopt.zero_grad()\n",
    "                    (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if sbopt: sbopt.step()\n",
    "\n",
    "        if self.ws_steps:\n",
    "\n",
    "            if s0opt: s0opt.zero_grad()\n",
    "            if s1opt: s1opt.zero_grad()\n",
    "            if s2opt: s2opt.zero_grad()\n",
    "            if s3opt: s3opt.zero_grad()\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            \n",
    "            X, Y = env.train()\n",
    "            Y = Y[:,self.y]\n",
    "            \n",
    "            torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.BCEWithLogitsLoss()\n",
    "            for _ in range(self.ws_steps):\n",
    "                for _X,_y in torch_loader:\n",
    "\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if s2opt: s2opt.zero_grad()\n",
    "                    if s3opt: s3opt.zero_grad()\n",
    "                    loss(s3(s2(s1(s0(_X.nan_to_num())))),_y).backward()\n",
    "                    if s3opt: s3opt.step()\n",
    "                    if s2opt: s2opt.step()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if s0opt: s0opt.step()\n",
    "\n",
    "            rng = cb.CobaRandom(1)\n",
    "            ind = rng.shuffle(range(len(Y)))[:self.emt_cnt]\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind,:]\n",
    "\n",
    "            emt.learn(s2(s1(s0(X.nan_to_num()))),Y)\n",
    "\n",
    "        s0.eval()\n",
    "        s1.eval()\n",
    "        s2.eval()\n",
    "        s3.eval()\n",
    "\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        rng = cb.CobaRandom(1)\n",
    "        while 1 in [len(set(Y[35:,i].tolist())) for i in range(Y.shape[1])]:\n",
    "            ind = rng.shuffle(range(len(Y)))\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind,:]\n",
    "\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        lrnx = []\n",
    "        lrny = []\n",
    "        mems = []\n",
    "\n",
    "        def predict(X):\n",
    "            return emt.predict(s2(s1(s0(X.nan_to_num()))))\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X[:,:])[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "        for i in range(35):\n",
    "\n",
    "            x,y = X[[i],:], Y[[i],:]\n",
    "\n",
    "            emt.learn(s2(s1(s0(x.nan_to_num()))),y)\n",
    "\n",
    "            yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "def make_envs(X, Y, G):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "    all_equal = set()\n",
    "    envs = []\n",
    "    for rng in range(1):\n",
    "        for g in sorted(set(G.tolist())):\n",
    "            if (g==G).sum() < 50: continue\n",
    "            trn_x,trn_y = X[g!=G],Y[g!=G]\n",
    "            tst_x,tst_y = X[g==G],Y[g==G]\n",
    "\n",
    "            if 1 in [len(set(tst_y[:,i].tolist())) for i in range(tst_y.shape[1])]:\n",
    "                all_equal.add(g)\n",
    "                continue\n",
    "\n",
    "            envs.append(MyEnvironment(trn_x,trn_y,tst_x,tst_y,g,rng))\n",
    "\n",
    "    if len(all_equal) > 0:\n",
    "        print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    return envs\n",
    "\n",
    "lrns = [ FeedForward([]) ]\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 5000, 100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 10000, 100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 100),\n",
    "]\n",
    "envs = make_envs(X3,np.hstack([Y1,Y2]),G)\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/5/out5_7.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b850b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [2, 25, 61, 82, 87, 89, 99, 103, 111, 117, 146, 196, 203, 227, 246, 311, 319, 357, 377, 390, 447, 451, 455, 469]\n",
      "{'Learners': 1, 'Environments': 223, 'Interactions': 94824}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class EMT:\n",
    "\n",
    "    def __init__(self, split:int = 100, scorer:str=\"self_consistent_rank\", bound:int=0, features=[1,'x']) -> None:\n",
    "\n",
    "        self.params = {'split':split, 'scorer':scorer, 'bound':bound, 'features':features}\n",
    "\n",
    "        feat_args = []\n",
    "        if 1   not in features: feat_args.append('--noconstant')\n",
    "        if 'a' not in features: feat_args.append('--ignore_linear a')\n",
    "        if 'x' not in features: feat_args.append('--ignore_linear x')\n",
    "        feat_args += [ f'--interactions {f}' for f in features if f not in {1, 'a', 'x'} ]\n",
    "\n",
    "        vw_args = [\n",
    "            \"--emt\",\n",
    "            f\"--emt_tree {bound}\",\n",
    "            f\"--emt_leaf {split}\",\n",
    "            f\"--emt_scorer {scorer}\",\n",
    "            f\"--emt_router {'eigen'}\",\n",
    "            f\"-b {26}\",\n",
    "            \"--min_prediction 0\",\n",
    "            \"--max_prediction 3\",\n",
    "            \"--coin\",\n",
    "            \"--initial_weight 0\",\n",
    "            *feat_args,\n",
    "            '--quiet',\n",
    "            '--random_seed 1337'\n",
    "        ]\n",
    "\n",
    "        self._vw = cb.VowpalMediator()\n",
    "        self._vw_args = ' '.join(vw_args)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self._vw.is_initialized: self._vw.init_learner(self._vw_args, label_type=2)\n",
    "        return torch.tensor([[float(self._vw.predict(self._vw.make_example({\"x\":x}, None)))] for x in X.tolist()])\n",
    "\n",
    "    def learn(self, X, Y):\n",
    "        if not self._vw.is_initialized: self._vw.init_learner(self._vw_args, label_type=2)\n",
    "        for x,y in zip(X.tolist(),Y.squeeze(1).tolist()):\n",
    "            self._vw.learn(self._vw.make_example({'x':x}, f\"{int(y)} 1\"))\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,i):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()    \n",
    "        Y = self.train_Y[:,i]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_indexes))\n",
    "        Y = list(map(Y.__getitem__,rng_indexes))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "\n",
    "        def choose_unique(items,item):\n",
    "            while items[i:=rng.randint(0,len(items)-1)]==item:\n",
    "                pass\n",
    "            return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            while True:\n",
    "                indexes.add(rng.randint(0,len(items)-1))\n",
    "                if len(indexes)==n: return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],x))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for x,y in zip(X,Y):\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],x))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s0, s1, s2, s3, dae_steps, dae_dropn, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, pers_lrn_cnt, pers_mem_cnt, pers_mem_rpt, pers_mem_rcl, y, emt_cnt, emt_bound, emt_feats):\n",
    "\n",
    "        self.s0  = s0  #dae + sl\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "        self.s3  = s3  #sl + pers\n",
    "\n",
    "        self.dae_steps = dae_steps\n",
    "        self.dae_dropn = dae_dropn\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "\n",
    "        self.pers_lrn_cnt = pers_lrn_cnt\n",
    "        self.pers_mem_cnt = pers_mem_cnt\n",
    "        self.pers_mem_rpt = pers_mem_rpt\n",
    "        self.pers_mem_rcl = pers_mem_rcl\n",
    "\n",
    "        self.emt_cnt = emt_cnt\n",
    "        self.emt_bound = emt_bound\n",
    "        self.emt_feats = emt_feats\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = {'s0': s0, 's1': s1, 's2':s2, 's3':s3, 'dae': (dae_steps,dae_dropn), 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'pers': (pers_lrn_cnt,pers_mem_cnt,pers_mem_rpt,pers_mem_rcl), 'y': y, 'emt':(emt_cnt,emt_bound,emt_feats)}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        emt = EMT(bound=self.emt_bound,features=self.emt_feats)\n",
    "\n",
    "        s0 = FeedForward(self.s0)\n",
    "        s1 = FeedForward(self.s1)\n",
    "        s2 = FeedForward(self.s2)\n",
    "        s3 = FeedForward(self.s3)\n",
    "\n",
    "        sa = torch.nn.Sequential(*list(s0.children())[len(self.s0)-self.dae_dropn:])\n",
    "        s0 = torch.nn.Sequential(*list(s0.children())[:len(self.s0)-self.dae_dropn])\n",
    "\n",
    "        sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "        s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "        s0.train()\n",
    "        sa.train()\n",
    "        s1.train()\n",
    "        sb.train()\n",
    "        s2.train()\n",
    "        s3.train()\n",
    "\n",
    "        s0opt = COCOB(s0.parameters()) if list(s0.parameters()) else None\n",
    "        saopt = COCOB(sa.parameters()) if list(sa.parameters()) else None\n",
    "        s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "        sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "        s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        if self.dae_steps:\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            X = env.train()[0]\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.L1Loss(reduction='none')\n",
    "            for _ in range(self.dae_steps):\n",
    "                for (_X,) in torch_loader:\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if saopt: saopt.zero_grad()\n",
    "                    loss(sa(s0(_X.nan_to_num())),_X).nanmean().backward()\n",
    "                    if s0opt: s0opt.step()\n",
    "                    if saopt: saopt.step()\n",
    "\n",
    "        if self.ssl_samps:\n",
    "\n",
    "            if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "            if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "\n",
    "            for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=64,drop_last=True,shuffle=True)\n",
    "\n",
    "                for _A, _P, _N in torch_loader:\n",
    "                    #https://arxiv.org/pdf/2002.05709\n",
    "                    _A = sb(s1(s0(_A.nan_to_num())))\n",
    "                    _P = sb(s1(s0(_P.nan_to_num())))\n",
    "                    _N = sb(s1(s0(_N.nan_to_num())))\n",
    "\n",
    "                    p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                    n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                    p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                    n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                    p = torch.exp(p/self.ssl_tau)\n",
    "                    n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if sbopt: sbopt.zero_grad()\n",
    "                    (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if sbopt: sbopt.step()\n",
    "\n",
    "        if self.ws_steps:\n",
    "\n",
    "            if s0opt: s0opt.zero_grad()\n",
    "            if s1opt: s1opt.zero_grad()\n",
    "            if s2opt: s2opt.zero_grad()\n",
    "            if s3opt: s3opt.zero_grad()\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            \n",
    "            X, Y = env.train()\n",
    "            Y = Y[:,self.y]\n",
    "            \n",
    "            torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.BCEWithLogitsLoss()\n",
    "            for _ in range(self.ws_steps):\n",
    "                for _X,_y in torch_loader:\n",
    "\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if s2opt: s2opt.zero_grad()\n",
    "                    if s3opt: s3opt.zero_grad()\n",
    "                    loss(s3(s2(s1(s0(_X.nan_to_num())))),_y).backward()\n",
    "                    if s3opt: s3opt.step()\n",
    "                    if s2opt: s2opt.step()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if s0opt: s0opt.step()\n",
    "\n",
    "            rng = cb.CobaRandom(1)\n",
    "            ind = rng.shuffle(range(len(Y)))[:self.emt_cnt]\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind,:]\n",
    "\n",
    "            emt.learn(s2(s1(s0(X.nan_to_num()))),Y)\n",
    "\n",
    "        s0.eval()\n",
    "        s1.eval()\n",
    "        s2.eval()\n",
    "        s3.eval()\n",
    "\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        rng = cb.CobaRandom(1)\n",
    "        while 1 in [len(set(Y[35:,i].tolist())) for i in range(Y.shape[1])]:\n",
    "            ind = rng.shuffle(range(len(Y)))\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind,:]\n",
    "\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        lrnx = []\n",
    "        lrny = []\n",
    "        mems = []\n",
    "\n",
    "        def predict(X):\n",
    "            return emt.predict(s2(s1(s0(X.nan_to_num()))))\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X[:,:])[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "        for i in range(35):\n",
    "\n",
    "            x,y = X[[i],:], Y[[i],:]\n",
    "\n",
    "            emt.learn(s2(s1(s0(x.nan_to_num()))),y)\n",
    "\n",
    "            yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "def make_envs(X, Y, G):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "    all_equal = set()\n",
    "    envs = []\n",
    "    for rng in range(1):\n",
    "        for g in sorted(set(G.tolist())):\n",
    "            if (g==G).sum() < 50: continue\n",
    "            trn_x,trn_y = X[g!=G],Y[g!=G]\n",
    "            tst_x,tst_y = X[g==G],Y[g==G]\n",
    "\n",
    "            if 1 in [len(set(tst_y[:,i].tolist())) for i in range(tst_y.shape[1])]:\n",
    "                all_equal.add(g)\n",
    "                continue\n",
    "\n",
    "            envs.append(MyEnvironment(trn_x,trn_y,tst_x,tst_y,g,rng))\n",
    "\n",
    "    if len(all_equal) > 0:\n",
    "        print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    return envs\n",
    "\n",
    "lrns = [ FeedForward([]) ]\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 100,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 200,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 300,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 100,['x','xx']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 200,['x','xx']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 300,['x','xx']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',30), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 100,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',30), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 200,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',30), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 300,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',30), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 100,['x','xx']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',30), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 200,['x','xx']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',30), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 300,['x','xx']),\n",
    "]\n",
    "envs = make_envs(X3,np.hstack([Y1,Y2]),G)\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/5/out5_8.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b6512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [2, 25, 61, 82, 87, 89, 99, 103, 111, 117, 146, 196, 203, 227, 246, 311, 319, 357, 377, 390, 447, 451, 455, 469]\n",
      "{'Learners': 1, 'Environments': 226, 'Interactions': 73224}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class EMT:\n",
    "\n",
    "    def __init__(self, split:int = 100, scorer:str=\"self_consistent_rank\", bound:int=0, features=[1,'x']) -> None:\n",
    "\n",
    "        self.params = {'split':split, 'scorer':scorer, 'bound':bound, 'features':features}\n",
    "\n",
    "        feat_args = []\n",
    "        if 1   not in features: feat_args.append('--noconstant')\n",
    "        if 'a' not in features: feat_args.append('--ignore_linear a')\n",
    "        if 'x' not in features: feat_args.append('--ignore_linear x')\n",
    "        feat_args += [ f'--interactions {f}' for f in features if f not in {1, 'a', 'x'} ]\n",
    "\n",
    "        vw_args = [\n",
    "            \"--emt\",\n",
    "            f\"--emt_tree {bound}\",\n",
    "            f\"--emt_leaf {split}\",\n",
    "            f\"--emt_scorer {scorer}\",\n",
    "            f\"--emt_router {'eigen'}\",\n",
    "            f\"-b {26}\",\n",
    "            \"--min_prediction 0\",\n",
    "            \"--max_prediction 3\",\n",
    "            \"--coin\",\n",
    "            \"--initial_weight 0\",\n",
    "            *feat_args,\n",
    "            '--quiet',\n",
    "            '--random_seed 1337'\n",
    "        ]\n",
    "\n",
    "        self._vw = cb.VowpalMediator()\n",
    "        self._vw_args = ' '.join(vw_args)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self._vw.is_initialized: self._vw.init_learner(self._vw_args, label_type=2)\n",
    "        return torch.tensor([[float(self._vw.predict(self._vw.make_example({\"x\":x}, None)))] for x in X.tolist()])\n",
    "\n",
    "    def learn(self, X, Y):\n",
    "        if not self._vw.is_initialized: self._vw.init_learner(self._vw_args, label_type=2)\n",
    "        for x,y in zip(X.tolist(),Y.squeeze(1).tolist()):\n",
    "            self._vw.learn(self._vw.make_example({'x':x}, f\"{int(y)} 1\"))\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,i):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()    \n",
    "        Y = self.train_Y[:,i]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_indexes))\n",
    "        Y = list(map(Y.__getitem__,rng_indexes))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "\n",
    "        def choose_unique(items,item):\n",
    "            while items[i:=rng.randint(0,len(items)-1)]==item:\n",
    "                pass\n",
    "            return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            while True:\n",
    "                indexes.add(rng.randint(0,len(items)-1))\n",
    "                if len(indexes)==n: return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],x))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for x,y in zip(X,Y):\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],x))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s0, s1, s2, s3, dae_steps, dae_dropn, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, pers_lrn_cnt, pers_mem_cnt, pers_mem_rpt, pers_mem_rcl, y, emt_cnt, emt_bound, emt_feats):\n",
    "\n",
    "        self.s0  = s0  #dae + sl\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "        self.s3  = s3  #sl + pers\n",
    "\n",
    "        self.dae_steps = dae_steps\n",
    "        self.dae_dropn = dae_dropn\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "\n",
    "        self.pers_lrn_cnt = pers_lrn_cnt\n",
    "        self.pers_mem_cnt = pers_mem_cnt\n",
    "        self.pers_mem_rpt = pers_mem_rpt\n",
    "        self.pers_mem_rcl = pers_mem_rcl\n",
    "\n",
    "        self.emt_cnt = emt_cnt\n",
    "        self.emt_bound = emt_bound\n",
    "        self.emt_feats = emt_feats\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = {'s0': s0, 's1': s1, 's2':s2, 's3':s3, 'dae': (dae_steps,dae_dropn), 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'pers': (pers_lrn_cnt,pers_mem_cnt,pers_mem_rpt,pers_mem_rcl), 'y': y, 'emt':(emt_cnt,emt_bound,emt_feats)}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        emt = EMT(bound=self.emt_bound,features=self.emt_feats)\n",
    "\n",
    "        s0 = FeedForward(self.s0)\n",
    "        s1 = FeedForward(self.s1)\n",
    "        s2 = FeedForward(self.s2)\n",
    "        s3 = FeedForward(self.s3)\n",
    "\n",
    "        sa = torch.nn.Sequential(*list(s0.children())[len(self.s0)-self.dae_dropn:])\n",
    "        s0 = torch.nn.Sequential(*list(s0.children())[:len(self.s0)-self.dae_dropn])\n",
    "\n",
    "        sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "        s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "        s0.train()\n",
    "        sa.train()\n",
    "        s1.train()\n",
    "        sb.train()\n",
    "        s2.train()\n",
    "        s3.train()\n",
    "\n",
    "        s0opt = COCOB(s0.parameters()) if list(s0.parameters()) else None\n",
    "        saopt = COCOB(sa.parameters()) if list(sa.parameters()) else None\n",
    "        s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "        sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "        s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        if self.dae_steps:\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            X = env.train()[0]\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.L1Loss(reduction='none')\n",
    "            for _ in range(self.dae_steps):\n",
    "                for (_X,) in torch_loader:\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if saopt: saopt.zero_grad()\n",
    "                    loss(sa(s0(_X.nan_to_num())),_X).nanmean().backward()\n",
    "                    if s0opt: s0opt.step()\n",
    "                    if saopt: saopt.step()\n",
    "\n",
    "        if self.ssl_samps:\n",
    "\n",
    "            if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "            if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "\n",
    "            for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=64,drop_last=True,shuffle=True)\n",
    "\n",
    "                for _A, _P, _N in torch_loader:\n",
    "                    #https://arxiv.org/pdf/2002.05709\n",
    "                    _A = sb(s1(s0(_A.nan_to_num())))\n",
    "                    _P = sb(s1(s0(_P.nan_to_num())))\n",
    "                    _N = sb(s1(s0(_N.nan_to_num())))\n",
    "\n",
    "                    p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                    n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                    p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                    n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                    p = torch.exp(p/self.ssl_tau)\n",
    "                    n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if sbopt: sbopt.zero_grad()\n",
    "                    (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if sbopt: sbopt.step()\n",
    "\n",
    "        if self.ws_steps:\n",
    "\n",
    "            if s0opt: s0opt.zero_grad()\n",
    "            if s1opt: s1opt.zero_grad()\n",
    "            if s2opt: s2opt.zero_grad()\n",
    "            if s3opt: s3opt.zero_grad()\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            \n",
    "            X, Y = env.train()\n",
    "            Y = Y[:,self.y]\n",
    "            \n",
    "            torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.BCEWithLogitsLoss()\n",
    "            for _ in range(self.ws_steps):\n",
    "                for _X,_y in torch_loader:\n",
    "\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if s2opt: s2opt.zero_grad()\n",
    "                    if s3opt: s3opt.zero_grad()\n",
    "                    loss(s3(s2(s1(s0(_X.nan_to_num())))),_y).backward()\n",
    "                    if s3opt: s3opt.step()\n",
    "                    if s2opt: s2opt.step()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if s0opt: s0opt.step()\n",
    "\n",
    "            rng = cb.CobaRandom(1)\n",
    "            ind = rng.shuffle(range(len(Y)))[:self.emt_cnt]\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind,:]\n",
    "\n",
    "            emt.learn(s2(s1(s0(X.nan_to_num()))),Y)\n",
    "\n",
    "        s0.eval()\n",
    "        s1.eval()\n",
    "        s2.eval()\n",
    "        s3.eval()\n",
    "\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        rng = cb.CobaRandom(1)\n",
    "        while 1 in [len(set(Y[35:,i].tolist())) for i in range(Y.shape[1])]:\n",
    "            ind = rng.shuffle(range(len(Y)))\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind,:]\n",
    "\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        lrnx = []\n",
    "        lrny = []\n",
    "        mems = []\n",
    "\n",
    "        def predict(X):\n",
    "            return emt.predict(s2(s1(s0(X.nan_to_num()))))\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X[:,:])[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "        for i in range(35):\n",
    "\n",
    "            x,y = X[[i],:], Y[[i],:]\n",
    "\n",
    "            emt.learn(s2(s1(s0(x.nan_to_num()))),y)\n",
    "\n",
    "            yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "def make_envs(X, Y, G):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "    all_equal = set()\n",
    "    envs = []\n",
    "    for rng in range(1):\n",
    "        for g in sorted(set(G.tolist())):\n",
    "            if (g==G).sum() < 50: continue\n",
    "            trn_x,trn_y = X[g!=G],Y[g!=G]\n",
    "            tst_x,tst_y = X[g==G],Y[g==G]\n",
    "\n",
    "            if 1 in [len(set(tst_y[:,i].tolist())) for i in range(tst_y.shape[1])]:\n",
    "                all_equal.add(g)\n",
    "                continue\n",
    "\n",
    "            envs.append(MyEnvironment(trn_x,trn_y,tst_x,tst_y,g,rng))\n",
    "\n",
    "    if len(all_equal) > 0:\n",
    "        print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    return envs\n",
    "\n",
    "lrns = [ FeedForward([]) ]\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,15,'l','r',), (15,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 50 ,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,15,'l','r',), (15,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 100,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,15,'l','r',), (15,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 150,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 50 ,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 100,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 150,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,45,'l','r',), (45,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 50 ,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,45,'l','r',), (45,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 100,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,45,'l','r',), (45,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 150,['x']),\n",
    "]\n",
    "envs = make_envs(X3,np.hstack([Y1,Y2]),G)\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/5/out5_9.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551f9695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [2, 25, 61, 82, 87, 89, 99, 103, 111, 117, 146, 196, 203, 227, 246, 311, 319, 357, 377, 390, 447, 451, 455, 469]\n",
      "{'Learners': 1, 'Environments': 170, 'Interactions': 11016}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class EMT:\n",
    "\n",
    "    def __init__(self, split:int = 100, scorer:str=\"self_consistent_rank\", bound:int=0, features=[1,'x']) -> None:\n",
    "\n",
    "        self.params = {'split':split, 'scorer':scorer, 'bound':bound, 'features':features}\n",
    "\n",
    "        feat_args = []\n",
    "        if 1   not in features: feat_args.append('--noconstant')\n",
    "        if 'a' not in features: feat_args.append('--ignore_linear a')\n",
    "        if 'x' not in features: feat_args.append('--ignore_linear x')\n",
    "        feat_args += [ f'--interactions {f}' for f in features if f not in {1, 'a', 'x'} ]\n",
    "\n",
    "        vw_args = [\n",
    "            \"--emt\",\n",
    "            f\"--emt_tree {bound}\",\n",
    "            f\"--emt_leaf {split}\",\n",
    "            f\"--emt_scorer {scorer}\",\n",
    "            f\"--emt_router {'eigen'}\",\n",
    "            f\"-b {26}\",\n",
    "            \"--min_prediction 0\",\n",
    "            \"--max_prediction 3\",\n",
    "            \"--coin\",\n",
    "            \"--initial_weight 0\",\n",
    "            *feat_args,\n",
    "            '--quiet',\n",
    "            '--random_seed 1337'\n",
    "        ]\n",
    "\n",
    "        self._vw = cb.VowpalMediator()\n",
    "        self._vw_args = ' '.join(vw_args)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self._vw.is_initialized: self._vw.init_learner(self._vw_args, label_type=2)\n",
    "        return torch.tensor([[float(self._vw.predict(self._vw.make_example({\"x\":x}, None)))] for x in X.tolist()])\n",
    "\n",
    "    def learn(self, X, Y):\n",
    "        if not self._vw.is_initialized: self._vw.init_learner(self._vw_args, label_type=2)\n",
    "        for x,y in zip(X.tolist(),Y.squeeze(1).tolist()):\n",
    "            self._vw.learn(self._vw.make_example({'x':x}, f\"{int(y)} 1\"))\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,i):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()    \n",
    "        Y = self.train_Y[:,i]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_indexes))\n",
    "        Y = list(map(Y.__getitem__,rng_indexes))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "\n",
    "        def choose_unique(items,item):\n",
    "            while items[i:=rng.randint(0,len(items)-1)]==item:\n",
    "                pass\n",
    "            return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            while True:\n",
    "                indexes.add(rng.randint(0,len(items)-1))\n",
    "                if len(indexes)==n: return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],x))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for x,y in zip(X,Y):\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],x))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s0, s1, s2, s3, dae_steps, dae_dropn, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, pers_lrn_cnt, pers_mem_cnt, pers_mem_rpt, pers_mem_rcl, y, emt_cnt, emt_bound, emt_feats):\n",
    "\n",
    "        self.s0  = s0  #dae + sl\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "        self.s3  = s3  #sl + pers\n",
    "\n",
    "        self.dae_steps = dae_steps\n",
    "        self.dae_dropn = dae_dropn\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "\n",
    "        self.pers_lrn_cnt = pers_lrn_cnt\n",
    "        self.pers_mem_cnt = pers_mem_cnt\n",
    "        self.pers_mem_rpt = pers_mem_rpt\n",
    "        self.pers_mem_rcl = pers_mem_rcl\n",
    "\n",
    "        self.emt_cnt = emt_cnt\n",
    "        self.emt_bound = emt_bound\n",
    "        self.emt_feats = emt_feats\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = {'s0': s0, 's1': s1, 's2':s2, 's3':s3, 'dae': (dae_steps,dae_dropn), 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'pers': (pers_lrn_cnt,pers_mem_cnt,pers_mem_rpt,pers_mem_rcl), 'y': y, 'emt':(emt_cnt,emt_bound,emt_feats)}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        emt = EMT(bound=self.emt_bound,features=self.emt_feats)\n",
    "\n",
    "        s0 = FeedForward(self.s0)\n",
    "        s1 = FeedForward(self.s1)\n",
    "        s2 = FeedForward(self.s2)\n",
    "        s3 = FeedForward(self.s3)\n",
    "\n",
    "        sa = torch.nn.Sequential(*list(s0.children())[len(self.s0)-self.dae_dropn:])\n",
    "        s0 = torch.nn.Sequential(*list(s0.children())[:len(self.s0)-self.dae_dropn])\n",
    "\n",
    "        sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "        s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "        s0.train()\n",
    "        sa.train()\n",
    "        s1.train()\n",
    "        sb.train()\n",
    "        s2.train()\n",
    "        s3.train()\n",
    "\n",
    "        s0opt = COCOB(s0.parameters()) if list(s0.parameters()) else None\n",
    "        saopt = COCOB(sa.parameters()) if list(sa.parameters()) else None\n",
    "        s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "        sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "        s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        if self.dae_steps:\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            X = env.train()[0]\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.L1Loss(reduction='none')\n",
    "            for _ in range(self.dae_steps):\n",
    "                for (_X,) in torch_loader:\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if saopt: saopt.zero_grad()\n",
    "                    loss(sa(s0(_X.nan_to_num())),_X).nanmean().backward()\n",
    "                    if s0opt: s0opt.step()\n",
    "                    if saopt: saopt.step()\n",
    "\n",
    "        if self.ssl_samps:\n",
    "\n",
    "            if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "            if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "\n",
    "            for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=64,drop_last=True,shuffle=True)\n",
    "\n",
    "                for _A, _P, _N in torch_loader:\n",
    "                    #https://arxiv.org/pdf/2002.05709\n",
    "                    _A = sb(s1(s0(_A.nan_to_num())))\n",
    "                    _P = sb(s1(s0(_P.nan_to_num())))\n",
    "                    _N = sb(s1(s0(_N.nan_to_num())))\n",
    "\n",
    "                    p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                    n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                    p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                    n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                    p = torch.exp(p/self.ssl_tau)\n",
    "                    n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if sbopt: sbopt.zero_grad()\n",
    "                    (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if sbopt: sbopt.step()\n",
    "\n",
    "        if self.ws_steps:\n",
    "\n",
    "            if s0opt: s0opt.zero_grad()\n",
    "            if s1opt: s1opt.zero_grad()\n",
    "            if s2opt: s2opt.zero_grad()\n",
    "            if s3opt: s3opt.zero_grad()\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            \n",
    "            X, Y = env.train()\n",
    "            Y = Y[:,self.y]\n",
    "            \n",
    "            torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.BCEWithLogitsLoss()\n",
    "            for _ in range(self.ws_steps):\n",
    "                for _X,_y in torch_loader:\n",
    "\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if s2opt: s2opt.zero_grad()\n",
    "                    if s3opt: s3opt.zero_grad()\n",
    "                    loss(s3(s2(s1(s0(_X.nan_to_num())))),_y).backward()\n",
    "                    if s3opt: s3opt.step()\n",
    "                    if s2opt: s2opt.step()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if s0opt: s0opt.step()\n",
    "\n",
    "            rng = cb.CobaRandom(1)\n",
    "            ind = rng.shuffle(range(len(Y)))[:self.emt_cnt]\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind,:]\n",
    "\n",
    "            emt.learn(s2(s1(s0(X.nan_to_num()))),Y)\n",
    "\n",
    "        s0.eval()\n",
    "        s1.eval()\n",
    "        s2.eval()\n",
    "        s3.eval()\n",
    "\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        rng = cb.CobaRandom(1)\n",
    "        while 1 in [len(set(Y[35:,i].tolist())) for i in range(Y.shape[1])]:\n",
    "            ind = rng.shuffle(range(len(Y)))\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind,:]\n",
    "\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        lrnx = []\n",
    "        lrny = []\n",
    "        mems = []\n",
    "\n",
    "        def predict(X):\n",
    "            return emt.predict(s2(s1(s0(X.nan_to_num()))))\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X[:,:])[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "        for i in range(35):\n",
    "\n",
    "            x,y = X[[i],:], Y[[i],:]\n",
    "\n",
    "            emt.learn(s2(s1(s0(x.nan_to_num()))),y)\n",
    "\n",
    "            yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "def make_envs(X, Y, G):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "    all_equal = set()\n",
    "    envs = []\n",
    "    for rng in range(1):\n",
    "        for g in sorted(set(G.tolist())):\n",
    "            if (g==G).sum() < 50: continue\n",
    "            trn_x,trn_y = X[g!=G],Y[g!=G]\n",
    "            tst_x,tst_y = X[g==G],Y[g==G]\n",
    "\n",
    "            if 1 in [len(set(tst_y[:,i].tolist())) for i in range(tst_y.shape[1])]:\n",
    "                all_equal.add(g)\n",
    "                continue\n",
    "\n",
    "            envs.append(MyEnvironment(trn_x,trn_y,tst_x,tst_y,g,rng))\n",
    "\n",
    "    if len(all_equal) > 0:\n",
    "        print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    return envs\n",
    "\n",
    "lrns = [ FeedForward([]) ]\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 50   ,['x']),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 20000, 10000,['x']),\n",
    "]\n",
    "envs = make_envs(X3,np.hstack([Y1,Y2]),G)\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/5/out5_10.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68af16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [2, 25, 61, 82, 87, 89, 99, 103, 111, 117, 146, 196, 203, 227, 246, 311, 319, 357, 377, 390, 447, 451, 455, 469]\n",
      "{'Learners': 1, 'Environments': 226, 'Interactions': 138312}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class EMT:\n",
    "\n",
    "    def __init__(self, split:int = 100, scorer:str=\"self_consistent_rank\", bound:int=0, features=[1,'x']) -> None:\n",
    "\n",
    "        self.params = {'split':split, 'scorer':scorer, 'bound':bound, 'features':features}\n",
    "\n",
    "        feat_args = []\n",
    "        if 1   not in features: feat_args.append('--noconstant')\n",
    "        if 'a' not in features: feat_args.append('--ignore_linear a')\n",
    "        if 'x' not in features: feat_args.append('--ignore_linear x')\n",
    "        feat_args += [ f'--interactions {f}' for f in features if f not in {1, 'a', 'x'} ]\n",
    "\n",
    "        vw_args = [\n",
    "            \"--emt\",\n",
    "            f\"--emt_tree {bound}\",\n",
    "            f\"--emt_leaf {split}\",\n",
    "            f\"--emt_scorer {scorer}\",\n",
    "            f\"--emt_router {'eigen'}\",\n",
    "            f\"-b {26}\",\n",
    "            \"--min_prediction 0\",\n",
    "            \"--max_prediction 3\",\n",
    "            \"--coin\",\n",
    "            \"--initial_weight 0\",\n",
    "            *feat_args,\n",
    "            '--quiet',\n",
    "            '--random_seed 1337'\n",
    "        ]\n",
    "\n",
    "        self._vw = cb.VowpalMediator()\n",
    "        self._vw_args = ' '.join(vw_args)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self._vw.is_initialized: self._vw.init_learner(self._vw_args, label_type=2)\n",
    "        return torch.tensor([[float(self._vw.predict(self._vw.make_example({\"x\":x}, None)))] for x in X.tolist()])\n",
    "\n",
    "    def learn(self, X, Y):\n",
    "        if not self._vw.is_initialized: self._vw.init_learner(self._vw_args, label_type=2)\n",
    "        for x,y in zip(X.tolist(),Y.squeeze(1).tolist()):\n",
    "            self._vw.learn(self._vw.make_example({'x':x}, f\"{int(y)} 1\"))\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,i):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()    \n",
    "        Y = self.train_Y[:,i]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_indexes))\n",
    "        Y = list(map(Y.__getitem__,rng_indexes))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "\n",
    "        def choose_unique(items,item):\n",
    "            while items[i:=rng.randint(0,len(items)-1)]==item:\n",
    "                pass\n",
    "            return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            while True:\n",
    "                indexes.add(rng.randint(0,len(items)-1))\n",
    "                if len(indexes)==n: return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],x))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for x,y in zip(X,Y):\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],x))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s0, s1, s2, s3, dae_steps, dae_dropn, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, pers_lrn_cnt, pers_mem_cnt, pers_mem_rpt, pers_mem_rcl, y, emt_cnt, emt_bound, emt_feats, emt_split):\n",
    "\n",
    "        self.s0  = s0  #dae + sl\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "        self.s3  = s3  #sl + pers\n",
    "\n",
    "        self.dae_steps = dae_steps\n",
    "        self.dae_dropn = dae_dropn\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "\n",
    "        self.pers_lrn_cnt = pers_lrn_cnt\n",
    "        self.pers_mem_cnt = pers_mem_cnt\n",
    "        self.pers_mem_rpt = pers_mem_rpt\n",
    "        self.pers_mem_rcl = pers_mem_rcl\n",
    "\n",
    "        self.emt_cnt = emt_cnt\n",
    "        self.emt_bound = emt_bound\n",
    "        self.emt_feats = emt_feats\n",
    "        self.emt_split = emt_split\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = {'s0': s0, 's1': s1, 's2':s2, 's3':s3, 'dae': (dae_steps,dae_dropn), 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'pers': (pers_lrn_cnt,pers_mem_cnt,pers_mem_rpt,pers_mem_rcl), 'y': y, 'emt':(emt_cnt,emt_bound,emt_feats,emt_split)}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        emts = [EMT(bound=self.emt_bound,features=self.emt_feats,split=self.emt_split) for _ in range(self.emt_cnt)]\n",
    "\n",
    "        s0 = FeedForward(self.s0)\n",
    "        s1 = FeedForward(self.s1)\n",
    "        s2 = FeedForward(self.s2)\n",
    "        s3 = FeedForward(self.s3)\n",
    "\n",
    "        sa = torch.nn.Sequential(*list(s0.children())[len(self.s0)-self.dae_dropn:])\n",
    "        s0 = torch.nn.Sequential(*list(s0.children())[:len(self.s0)-self.dae_dropn])\n",
    "\n",
    "        sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "        s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "        s0.train()\n",
    "        sa.train()\n",
    "        s1.train()\n",
    "        sb.train()\n",
    "        s2.train()\n",
    "        s3.train()\n",
    "\n",
    "        s0opt = COCOB(s0.parameters()) if list(s0.parameters()) else None\n",
    "        saopt = COCOB(sa.parameters()) if list(sa.parameters()) else None\n",
    "        s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "        sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "        s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        if self.dae_steps:\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            X = env.train()[0]\n",
    "            torch_dataset = torch.utils.data.TensorDataset(X)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.L1Loss(reduction='none')\n",
    "            for _ in range(self.dae_steps):\n",
    "                for (_X,) in torch_loader:\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if saopt: saopt.zero_grad()\n",
    "                    loss(sa(s0(_X.nan_to_num())),_X).nanmean().backward()\n",
    "                    if s0opt: s0opt.step()\n",
    "                    if saopt: saopt.step()\n",
    "\n",
    "        if self.ssl_samps:\n",
    "\n",
    "            if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "            if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "\n",
    "            for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=64,drop_last=True,shuffle=True)\n",
    "\n",
    "                for _A, _P, _N in torch_loader:\n",
    "                    #https://arxiv.org/pdf/2002.05709\n",
    "                    _A = sb(s1(s0(_A.nan_to_num())))\n",
    "                    _P = sb(s1(s0(_P.nan_to_num())))\n",
    "                    _N = sb(s1(s0(_N.nan_to_num())))\n",
    "\n",
    "                    p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                    n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                    p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                    n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                    p = torch.exp(p/self.ssl_tau)\n",
    "                    n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if sbopt: sbopt.zero_grad()\n",
    "                    (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if sbopt: sbopt.step()\n",
    "\n",
    "        if self.ws_steps:\n",
    "\n",
    "            if s0opt: s0opt.zero_grad()\n",
    "            if s1opt: s1opt.zero_grad()\n",
    "            if s2opt: s2opt.zero_grad()\n",
    "            if s3opt: s3opt.zero_grad()\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            \n",
    "            X, Y = env.train()\n",
    "            Y = Y[:,self.y]\n",
    "            \n",
    "            torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "            torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "            loss = torch.nn.BCEWithLogitsLoss()\n",
    "            for _ in range(self.ws_steps):\n",
    "                for _X,_y in torch_loader:\n",
    "\n",
    "                    if s0opt: s0opt.zero_grad()\n",
    "                    if s1opt: s1opt.zero_grad()\n",
    "                    if s2opt: s2opt.zero_grad()\n",
    "                    if s3opt: s3opt.zero_grad()\n",
    "                    loss(s3(s2(s1(s0(_X.nan_to_num())))),_y).backward()\n",
    "                    if s3opt: s3opt.step()\n",
    "                    if s2opt: s2opt.step()\n",
    "                    if s1opt: s1opt.step()\n",
    "                    if s0opt: s0opt.step()\n",
    "\n",
    "            rng = cb.CobaRandom(1)\n",
    "            for emt in emts:            \n",
    "                ind = rng.shuffle(range(len(Y)))\n",
    "                emt.learn(s2(s1(s0(X[ind,:].nan_to_num()))),Y[ind,:])\n",
    "\n",
    "        s0.eval()\n",
    "        s1.eval()\n",
    "        s2.eval()\n",
    "        s3.eval()\n",
    "\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        rng = cb.CobaRandom(1)\n",
    "        while 1 in [len(set(Y[35:,i].tolist())) for i in range(Y.shape[1])]:\n",
    "            ind = rng.shuffle(range(len(Y)))\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind,:]\n",
    "\n",
    "        s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "        lrnx = []\n",
    "        lrny = []\n",
    "        mems = []\n",
    "\n",
    "        def predict(X):\n",
    "            return sum([emt.predict(s2(s1(s0(X.nan_to_num())))) for emt in emts])/len(emts)\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X[:,:])[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "        for i in range(35):\n",
    "\n",
    "            x,y = X[[i],:], Y[[i],:]\n",
    "\n",
    "            for emt in emts:\n",
    "                emt.learn(s2(s1(s0(x.nan_to_num()))),y)\n",
    "\n",
    "            yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "def make_envs(X, Y, G):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "    all_equal = set()\n",
    "    envs = []\n",
    "    for rng in range(1):\n",
    "        for g in sorted(set(G.tolist())):\n",
    "            if (g==G).sum() < 50: continue\n",
    "            trn_x,trn_y = X[g!=G],Y[g!=G]\n",
    "            tst_x,tst_y = X[g==G],Y[g==G]\n",
    "\n",
    "            if 1 in [len(set(tst_y[:,i].tolist())) for i in range(tst_y.shape[1])]:\n",
    "                all_equal.add(g)\n",
    "                continue\n",
    "\n",
    "            envs.append(MyEnvironment(trn_x,trn_y,tst_x,tst_y,g,rng))\n",
    "\n",
    "    if len(all_equal) > 0:\n",
    "        print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    return envs\n",
    "\n",
    "lrns = [ FeedForward([]) ]\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 1, 75,['x'],100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 2, 75,['x'],100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 4, 75,['x'],100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 8, 75,['x'],100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 4, 100,['x'],100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 4, 100,['x','xx'],100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 16, 50,['x'],100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 16, 200,['x'],100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 16, 400,['x'],100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 16, 800,['x'],100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 32, 800,['x'],100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 16, 2400,['x'],100),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 16, 800,['x'],50),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 16, 800,['x'],150),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 16, 800,['x'],200),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 16, 10000,['x'],50),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 16, 10000,['x'],100),\n",
    "]\n",
    "envs = make_envs(X3,np.hstack([Y1,Y2]),G)\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/5/out5_11.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c4e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [2, 25, 61, 82, 87, 89, 99, 103, 111, 117, 146, 196, 203, 227, 246, 311, 319, 357, 377, 390, 447, 451, 455, 469]\n",
      "{'Learners': 1, 'Environments': 1130, 'Interactions': 203400}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,i):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()    \n",
    "        Y = self.train_Y[:,i]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_indexes))\n",
    "        Y = list(map(Y.__getitem__,rng_indexes))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "\n",
    "        def choose_unique(items,item):\n",
    "            while items[i:=rng.randint(0,len(items)-1)]==item:\n",
    "                pass\n",
    "            return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            while True:\n",
    "                indexes.add(rng.randint(0,len(items)-1))\n",
    "                if len(indexes)==n: return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],x))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for x,y in zip(X,Y):\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],x))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s0, s1, s2, s3, dae_steps, dae_dropn, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, pers_lrn_cnt, pers_mem_cnt, pers_mem_rpt, pers_mem_rcl, y, n_models):\n",
    "\n",
    "        self.s0  = s0  #dae + sl\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "        self.s3  = s3  #sl + pers\n",
    "\n",
    "        self.dae_steps = dae_steps\n",
    "        self.dae_dropn = dae_dropn\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "\n",
    "        self.pers_lrn_cnt = pers_lrn_cnt\n",
    "        self.pers_mem_cnt = pers_mem_cnt\n",
    "        self.pers_mem_rpt = pers_mem_rpt\n",
    "        self.pers_mem_rcl = pers_mem_rcl\n",
    "\n",
    "        self.n_models = n_models\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = {'s0': s0, 's1': s1, 's2':s2, 's3':s3, 'dae': (dae_steps,dae_dropn), 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'pers': (pers_lrn_cnt,pers_mem_cnt,pers_mem_rpt,pers_mem_rcl), 'y': y, 'n_models': n_models}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        mods_opts = []\n",
    "        opts = []\n",
    "\n",
    "        for _ in range(self.n_models):\n",
    "            s0 = FeedForward(self.s0)\n",
    "            s1 = FeedForward(self.s1)\n",
    "            s2 = FeedForward(self.s2)\n",
    "            s3 = FeedForward(self.s3)\n",
    "            sa = torch.nn.Sequential(*list(s0.children())[len(self.s0)-self.dae_dropn:])\n",
    "            s0 = torch.nn.Sequential(*list(s0.children())[:len(self.s0)-self.dae_dropn])\n",
    "            sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "            s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "            s0opt = COCOB(s0.parameters()) if list(s0.parameters()) else None\n",
    "            saopt = COCOB(sa.parameters()) if list(sa.parameters()) else None\n",
    "            s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "            sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "            s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "            s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "            mods = [s0,sa,s1,sb,s2,s3]\n",
    "            opts = [s0opt,saopt,s1opt,sbopt,s2opt,s3opt]\n",
    "            mods_opts.append([mods,opts])\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.train()\n",
    "\n",
    "        for mods,opts in mods_opts:\n",
    "            [s0,sa,s1,sb,s2,s3] = mods\n",
    "            [s0opt,saopt,s1opt,sbopt,s2opt,s3opt] = opts\n",
    "\n",
    "            if self.dae_steps:\n",
    "\n",
    "                X = env.train()[0]\n",
    "                #torch.manual_seed(1)\n",
    "                torch_dataset = torch.utils.data.TensorDataset(X)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "                loss = torch.nn.L1Loss(reduction='none')\n",
    "\n",
    "                for _ in range(self.dae_steps):\n",
    "                    for (_X,) in torch_loader:\n",
    "                        if s0opt: s0opt.zero_grad()\n",
    "                        if saopt: saopt.zero_grad()\n",
    "                        loss(sa(s0(_X.nan_to_num())),_X).nanmean().backward()\n",
    "                        if s0opt: s0opt.step()\n",
    "                        if saopt: saopt.step()\n",
    "\n",
    "            if self.ssl_samps:\n",
    "\n",
    "                if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "                if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "                #torch.manual_seed(1)\n",
    "                for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                    torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                    torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=64,drop_last=True,shuffle=True)\n",
    "\n",
    "                    for _A, _P, _N in torch_loader:\n",
    "                        #https://arxiv.org/pdf/2002.05709\n",
    "                        _A = sb(s1(s0(_A.nan_to_num())))\n",
    "                        _P = sb(s1(s0(_P.nan_to_num())))\n",
    "                        _N = sb(s1(s0(_N.nan_to_num())))\n",
    "\n",
    "                        p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                        n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                        p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                        n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                        p = torch.exp(p/self.ssl_tau)\n",
    "                        n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if sbopt: sbopt.zero_grad()\n",
    "                        (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                        if s1opt: s1opt.step()\n",
    "                        if sbopt: sbopt.step()\n",
    "\n",
    "            if self.ws_steps:\n",
    "\n",
    "                if s0opt: s0opt.zero_grad()\n",
    "                if s1opt: s1opt.zero_grad()\n",
    "                if s2opt: s2opt.zero_grad()\n",
    "                if s3opt: s3opt.zero_grad()\n",
    "\n",
    "                #torch.manual_seed(1)\n",
    "\n",
    "                X, Y = env.train()\n",
    "                Y = Y[:,self.y]\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "                loss = torch.nn.BCEWithLogitsLoss()\n",
    "                for _ in range(self.ws_steps):\n",
    "                    for _X,_y in torch_loader:\n",
    "\n",
    "                        if s0opt: s0opt.zero_grad()\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if s2opt: s2opt.zero_grad()\n",
    "                        if s3opt: s3opt.zero_grad()\n",
    "                        loss(s3(s2(s1(s0(_X.nan_to_num())))),_y).backward()\n",
    "                        if s3opt: s3opt.step()\n",
    "                        if s2opt: s2opt.step()\n",
    "                        if s1opt: s1opt.step()\n",
    "                        if s0opt: s0opt.step()\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.eval()\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        rng = cb.CobaRandom(1)\n",
    "        while 1 in [len(set(Y[35:,i].tolist())) for i in range(Y.shape[1])]:\n",
    "            ind = rng.shuffle(range(len(Y)))\n",
    "            X = X[ind,:]\n",
    "            Y = Y[ind,:]\n",
    "\n",
    "        for mods,opts in mods_opts:\n",
    "            s3 = mods[5]\n",
    "            s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "            opts[5] = s3opt\n",
    "\n",
    "        lrnxs = [[] for _ in range(len(mods_opts))]\n",
    "        lrnys = [[] for _ in range(len(mods_opts))]\n",
    "        memss = [[] for _ in range(len(mods_opts))]\n",
    "\n",
    "        def predict(X):\n",
    "            preds = []\n",
    "            for mods, _ in mods_opts:\n",
    "                [s0,_,s1,_,s2,s3] = mods\n",
    "                preds.append(torch.sigmoid(s3(s2(s1(s0(X.nan_to_num()))))))\n",
    "            return sum(preds)/len(preds)\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X[:,:])[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "        for i in range(35):\n",
    "\n",
    "            for lrnx,lrny,mems,(mods,opts) in zip(lrnxs,lrnys,memss,mods_opts):\n",
    "                [s0,_,s1,_,s2,s3] = mods\n",
    "                s3opt = opts[5]\n",
    "\n",
    "                x,y = X[i,:], Y[i,:]\n",
    "\n",
    "                if self.pers_lrn_cnt:\n",
    "                    lrnx.append(x)\n",
    "                    lrny.append(y)\n",
    "\n",
    "                if self.pers_mem_cnt: \n",
    "                    mems.append([x,y,self.pers_mem_rpt])\n",
    "\n",
    "                if len(mems) > self.pers_mem_cnt:\n",
    "                    rng.shuffle(mems, inplace=True)\n",
    "                    for j in reversed(range(self.pers_mem_rcl)):\n",
    "                        x,y,n = mems[j]\n",
    "                        lrnx.append(x)\n",
    "                        lrny.append(y)\n",
    "                        if n == 1: mems.pop(j)\n",
    "                        else: mems[j] = [x,y,n-1]\n",
    "\n",
    "                if len(lrnx) >= self.pers_lrn_cnt:\n",
    "                    x = torch.stack(lrnx[:self.pers_lrn_cnt])\n",
    "                    y = torch.stack(lrny[:self.pers_lrn_cnt])\n",
    "                    if s3opt: s3opt.zero_grad()\n",
    "                    loss(s3(s2(s1(s0(x.nan_to_num())))),y).backward()\n",
    "                    if s3opt: s3opt.step()\n",
    "                    del lrnx[:self.pers_lrn_cnt]\n",
    "                    del lrny[:self.pers_lrn_cnt]\n",
    "\n",
    "            yield score(X[35:,:], Y[35:,:])\n",
    "\n",
    "def make_envs(X, Y, G):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "    all_equal = set()\n",
    "    envs = []\n",
    "    for rng in range(5):\n",
    "        for g in sorted(set(G.tolist())):\n",
    "            if (g==G).sum() < 50: continue\n",
    "            trn_x,trn_y = X[g!=G],Y[g!=G]\n",
    "            tst_x,tst_y = X[g==G],Y[g==G]\n",
    "\n",
    "            if 1 in [len(set(tst_y[:,i].tolist())) for i in range(tst_y.shape[1])]:\n",
    "                all_equal.add(g)\n",
    "                continue\n",
    "\n",
    "            envs.append(MyEnvironment(trn_x,trn_y,tst_x,tst_y,g,rng))\n",
    "\n",
    "    if len(all_equal) > 0:\n",
    "        print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    return envs\n",
    "\n",
    "lrns = [ FeedForward([]) ]\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 1),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 2),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 4),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 8),\n",
    "    MyEvaluator((len(x),.2,90 ,'l','r',len(x)), (), (90,30,'l','r',), (30,1), 2, 3, 0, 0, 0, 0, 3, 3, 20, 2, 2, [1], 16),\n",
    "]\n",
    "\n",
    "envs = make_envs(X3,np.hstack([Y1,Y2]),G)\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/5/out5_12.log',processes=35,quiet=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
