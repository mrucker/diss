{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "203f7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coba as cb\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import islice, chain, count, product, repeat\n",
    "from contextlib import nullcontext\n",
    "\n",
    "data_dir = \"../data\"\n",
    "\n",
    "import coba as cb\n",
    "\n",
    "import warnings\n",
    "\n",
    "import time\n",
    "import csv\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import RobustScaler, QuantileTransformer, MinMaxScaler, StandardScaler, Binarizer\n",
    "from sklearn.feature_selection import  mutual_info_classif, f_classif, GenericUnivariateSelect\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, StratifiedKFold, GridSearchCV, LeaveOneGroupOut, StratifiedShuffleSplit\n",
    "from sklearn.metrics import balanced_accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import torch\n",
    "from parameterfree import COCOB\n",
    "\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import coba as cb\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "try:\n",
    "    torch.set_num_threads(3)\n",
    "    torch.set_num_interop_threads(3)\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "c0 = \"#444\"\n",
    "c1 = \"#0072B2\"\n",
    "c2 = \"#E69F00\"\n",
    "c3 = \"#009E73\"\n",
    "c4 = \"#56B4E9\"\n",
    "c5 = \"#D55E00\"\n",
    "c6 = \"#F0E442\"\n",
    "c7 = \"#CC79A7\"\n",
    "c8 = \"#000000\"\n",
    "c9 = \"#332288\"\n",
    "\n",
    "torch.set_default_device('cpu')\n",
    "plt.rc('font', **{'size': 20})\n",
    "\n",
    "df = pd.read_csv(f\"{data_dir}/all_features_1h_v3.csv\")\n",
    "\n",
    "G  = df[\"id_participant\"].to_numpy()\n",
    "X1 = df[[c for c in df.columns if c.startswith(\"acc_\")]].to_numpy()\n",
    "X2 = df[[c for c in df.columns if c.startswith(\"acc_\") or c.startswith(\"gps_\") or c.startswith(\"motion_\")]].to_numpy()\n",
    "Y1 = df[\"ER_desire\"].astype(float).to_numpy()\n",
    "Y2 = (df[\"INT_availability\"] == \"yes\").astype(float).to_numpy()\n",
    "\n",
    "no_na = ~(np.isnan(X2).any(axis=1) | np.isnan(Y1) | np.isnan(Y2))\n",
    "\n",
    "G  = G [no_na]\n",
    "X1 = X1[no_na]\n",
    "X2 = X2[no_na]\n",
    "X3 = X2.copy()\n",
    "X4 = X2.copy()\n",
    "Y1 = np.expand_dims(Y1[no_na],axis=1)\n",
    "Y2 = np.expand_dims(Y2[no_na],axis=1)\n",
    "\n",
    "for g in set(G):\n",
    "    Y1[G == g] = Binarizer(threshold=np.mean(Y1[G == g].squeeze())).fit_transform(Y1[G == g])\n",
    "    X1[G == g] = StandardScaler().fit_transform(X1[G == g])\n",
    "    X2[G == g] = StandardScaler().fit_transform(X2[G == g])\n",
    "    X3[G == g] = StandardScaler().fit_transform(X3[G == g])\n",
    "    X4[G == g] = StandardScaler().fit_transform(X4[G == g])\n",
    "\n",
    "X3 = np.concatenate([X3, np.expand_dims((df[\"Platform\"] == \"Android\").astype(float).to_numpy(),1)[no_na]],axis=1)\n",
    "X3 = np.concatenate([X3, np.expand_dims((df[\"Platform\"] == \"iPhone\" ).astype(float).to_numpy(),1)[no_na]],axis=1)\n",
    "\n",
    "X4 = np.concatenate([X4, np.expand_dims((df[\"Platform\"] == \"Android\").astype(float).to_numpy(),1)[no_na]],axis=1)\n",
    "X4 = np.concatenate([X4, np.expand_dims((df[\"Platform\"] == \"iPhone\" ).astype(float).to_numpy(),1)[no_na]],axis=1)\n",
    "X4 = np.concatenate([X4, np.expand_dims((df[\"tag\"] == \"evening\" ).astype(float).to_numpy(),1)[no_na]],axis=1)\n",
    "X4 = np.concatenate([X4, np.expand_dims((df[\"tag\"] == \"morning\" ).astype(float).to_numpy(),1)[no_na]],axis=1)\n",
    "X4 = np.concatenate([X4, np.expand_dims((df[\"tag\"] == \"afternoon\" ).astype(float).to_numpy(),1)[no_na]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d830c5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [54, 57, 81, 82, 87, 89, 97, 99, 103, 111, 117, 118, 121, 122, 137, 146, 181, 196, 203, 206, 227, 231, 246, 251, 293, 311, 357, 371, 373, 374, 377, 382, 390, 402, 405, 426, 442, 447, 451, 452, 455, 463, 469, 486, 536]\n",
      "{'Learners': 1, 'Environments': 1, 'Interactions': 0}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, trn, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng, 'trn':trn}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,i):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()    \n",
    "        Y = self.train_Y[:,i]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_indexes))\n",
    "        Y = list(map(Y.__getitem__,rng_indexes))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "\n",
    "        def choose_unique(items,item):\n",
    "            while items[i:=rng.randint(0,len(items)-1)]==item:\n",
    "                pass\n",
    "            return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            while True:\n",
    "                indexes.add(rng.randint(0,len(items)-1))\n",
    "                if len(indexes)==n: return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],x))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for x,y in zip(X,Y):\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],x))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s1, s2, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, y, n_models):\n",
    "\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "        self.n_models = n_models\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = { 's1': s1, 's2':s2, 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'y': y, 'n_models': n_models}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        mods_opts = []\n",
    "        opts = []\n",
    "\n",
    "        for _ in range(self.n_models):\n",
    "            s1 = FeedForward(self.s1)\n",
    "            s2 = FeedForward(self.s2)\n",
    "            sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "            s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "            s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "            sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "            s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "\n",
    "            mods = [s1,sb,s2]\n",
    "            opts = [s1opt,sbopt,s2opt]\n",
    "            mods_opts.append([mods,opts])\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.train()\n",
    "\n",
    "        for mods,opts in mods_opts:\n",
    "            [s1,sb,s2] = mods\n",
    "            [s1opt,sbopt,s2opt] = opts\n",
    "\n",
    "            if self.ssl_samps:\n",
    "\n",
    "                if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "                if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "                for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                    torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                    torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=4,drop_last=True,shuffle=True)\n",
    "\n",
    "                    for _A, _P, _N in torch_loader:\n",
    "                        #https://arxiv.org/pdf/2002.05709\n",
    "                        _A = sb(s1(_A.nan_to_num()))\n",
    "                        _P = sb(s1(_P.nan_to_num()))\n",
    "                        _N = sb(s1(_N.nan_to_num()))\n",
    "\n",
    "                        p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                        n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                        p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                        n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                        p = torch.exp(p/self.ssl_tau)\n",
    "                        n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if sbopt: sbopt.zero_grad()\n",
    "                        (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                        if s1opt: s1opt.step()\n",
    "                        if sbopt: sbopt.step()\n",
    "\n",
    "            if self.ws_steps:\n",
    "\n",
    "                if s1opt: s1opt.zero_grad()\n",
    "                if s2opt: s2opt.zero_grad()\n",
    "\n",
    "                X, Y = env.train()\n",
    "                Y = Y[:,self.y]\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=4,drop_last=True,shuffle=True)\n",
    "\n",
    "                loss = torch.nn.BCEWithLogitsLoss()\n",
    "                for _ in range(self.ws_steps):\n",
    "                    for _X,_y in torch_loader:\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if s2opt: s2opt.zero_grad()\n",
    "                        loss(s2(s1(_X.nan_to_num())),_y).backward()\n",
    "                        if s2opt: s2opt.step()\n",
    "                        if s1opt: s1opt.step()\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.eval()\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        def predict(X):\n",
    "            preds = 0\n",
    "            for mods, _ in mods_opts:\n",
    "                [s1,_,s2] = mods\n",
    "                preds += torch.sigmoid(s2(s1(X.nan_to_num())))\n",
    "            return preds/len(mods_opts)\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X)[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X, Y)\n",
    "        yield score(X, Y)\n",
    "\n",
    "def make_envs(X, Y, G, N):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "\n",
    "    too_short = set(g for g in set(G.tolist()) if (g==G).sum() < 50)\n",
    "    all_equal = set(g for g in set(G.tolist()) if any(len(set(y.tolist()))==1 for y in Y[g==G].T))\n",
    "\n",
    "    if any(all_equal): print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    for rng in range(N):\n",
    "\n",
    "        for trn,tst in StratifiedShuffleSplit(10,random_state=rng).split(X,Y):\n",
    "            yield MyEnvironment(X[trn], Y[trn], X[tst], Y[tst], 'fold', None, rng)\n",
    "\n",
    "        for g in sorted(set(G.tolist())-all_equal-too_short):\n",
    "            try:\n",
    "                Xg, Yg = X[g==G], Y[g==G]\n",
    "\n",
    "                trn,tst = next(StratifiedShuffleSplit(1,train_size=35/len(Xg),random_state=rng).split(Xg,Yg))\n",
    "                yield MyEnvironment(Xg[trn], Yg[trn], Xg[tst], Yg[tst], 'self', g, rng)\n",
    "                yield MyEnvironment(X[g!=G], Y[g!=G], Xg[tst], Yg[tst], 'rest', g, rng)\n",
    "\n",
    "            except ValueError as e:\n",
    "                if 'The least populated class in y has only 1 member' in str(e): continue\n",
    "                raise\n",
    "\n",
    "lrns = [ None ]\n",
    "envs = list(make_envs(X3,np.hstack([Y1,Y2]),G,1))\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((), (len(x),30,'l','r',30,1), 0, 0, 0, 0, 3, [1], 1),\n",
    "]\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/6/1b.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae7e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [54, 57, 81, 82, 87, 89, 97, 99, 103, 111, 117, 118, 121, 122, 137, 146, 181, 196, 203, 206, 227, 231, 246, 251, 293, 311, 357, 371, 373, 374, 377, 382, 390, 402, 405, 426, 442, 447, 451, 452, 455, 463, 469, 486, 536]\n",
      "{'Learners': 1, 'Environments': 150, 'Interactions': 2400}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, trn, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng, 'trn':trn}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,yi):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "        rng_order = rng.shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()\n",
    "        Y = self.train_Y[:,yi]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_order))\n",
    "        Y = list(map(Y.__getitem__,rng_order))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        def choose_unique(items,given_i):\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                if i != given_i:\n",
    "                    return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            indexes = set()\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                indexes.add(i)\n",
    "                if len(indexes)==n:\n",
    "                    return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],i))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for i in range(len(X)):\n",
    "                    x,y = X[i],Y[i]\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],i))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s1, s2, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, y, n_models):\n",
    "\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "        self.n_models = n_models\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = { 's1': s1, 's2':s2, 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'y': y, 'n_models': n_models}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        mods_opts = []\n",
    "        opts = []\n",
    "\n",
    "        for _ in range(self.n_models):\n",
    "            s1 = FeedForward(self.s1)\n",
    "            s2 = FeedForward(self.s2)\n",
    "            sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "            s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "            s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "            sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "            s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "\n",
    "            mods = [s1,sb,s2]\n",
    "            opts = [s1opt,sbopt,s2opt]\n",
    "            mods_opts.append([mods,opts])\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.train()\n",
    "\n",
    "        for mods,opts in mods_opts:\n",
    "            [s1,sb,s2] = mods\n",
    "            [s1opt,sbopt,s2opt] = opts\n",
    "\n",
    "            if self.ssl_samps:\n",
    "\n",
    "                if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "                if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "                for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                    torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                    torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=64,drop_last=True,shuffle=True)\n",
    "\n",
    "                    for _A, _P, _N in torch_loader:\n",
    "                        #https://arxiv.org/pdf/2002.05709\n",
    "                        _A = sb(s1(_A.nan_to_num()))\n",
    "                        _P = sb(s1(_P.nan_to_num()))\n",
    "                        _N = sb(s1(_N.nan_to_num()))\n",
    "\n",
    "                        p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                        n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                        p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                        n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                        p = torch.exp(p/self.ssl_tau)\n",
    "                        n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if sbopt: sbopt.zero_grad()\n",
    "                        (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                        if s1opt: s1opt.step()\n",
    "                        if sbopt: sbopt.step()\n",
    "\n",
    "            if self.ws_steps:\n",
    "\n",
    "                if s1opt: s1opt.zero_grad()\n",
    "                if s2opt: s2opt.zero_grad()\n",
    "\n",
    "                X, Y = env.train()\n",
    "                Y = Y[:,self.y]\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=16,drop_last=True,shuffle=True)\n",
    "\n",
    "                loss = torch.nn.BCEWithLogitsLoss()\n",
    "                for _ in range(self.ws_steps):\n",
    "                    for _X,_y in torch_loader:\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if s2opt: s2opt.zero_grad()\n",
    "                        loss(s2(s1(_X.nan_to_num())),_y).backward()\n",
    "                        if s2opt: s2opt.step()\n",
    "                        if s1opt: s1opt.step()\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.eval()\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        def predict(X):\n",
    "            preds = 0\n",
    "            for mods, _ in mods_opts:\n",
    "                [s1,_,s2] = mods\n",
    "                preds += torch.sigmoid(s2(s1(X.nan_to_num())))\n",
    "            return preds/len(mods_opts)\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X)[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X, Y)\n",
    "        yield score(X, Y)\n",
    "\n",
    "def make_envs(X, Y, G, R):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "\n",
    "    too_short = set(g for g in set(G.tolist()) if (g==G).sum() < 50)\n",
    "    all_equal = set(g for g in set(G.tolist()) if any(len(set(y.tolist()))==1 for y in Y[g==G].T))\n",
    "\n",
    "    if any(all_equal): print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    for rng,g in product(range(R),sorted(set(G.tolist())-all_equal-too_short)):\n",
    "        _X, _Y = X[g==G], Y[g==G]\n",
    "        try:\n",
    "            trn,tst = next(StratifiedShuffleSplit(1,train_size=35/len(_X),random_state=rng).split(_X,_Y))\n",
    "\n",
    "            yield MyEnvironment( X[g==G][trn], Y[g==G][trn], X[g==G][tst], Y[g==G][tst], 'self', g, rng)\n",
    "        \n",
    "        except ValueError as e:\n",
    "            if 'The least populated class in y has only 1 member' in str(e): continue\n",
    "            raise\n",
    "\n",
    "lrns = [ None ]\n",
    "envs = list(make_envs(X3,np.hstack([Y1,Y2]),G,1))\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((), (len(x),30,'l','r',30,1), 0, 0, 0, 0, 2, [1], 2),\n",
    "    MyEvaluator((), (len(x),30,'l','r',30,1), 0, 0, 0, 0, 3, [1], 2),\n",
    "    MyEvaluator((), (len(x),30,'l','r',30,1), 0, 0, 0, 0, 4, [1], 2),\n",
    "    MyEvaluator((), (len(x),45,'l','r',45,1), 0, 0, 0, 0, 2, [1], 2),\n",
    "    MyEvaluator((), (len(x),45,'l','r',45,1), 0, 0, 0, 0, 3, [1], 2),\n",
    "    MyEvaluator((), (len(x),45,'l','r',45,1), 0, 0, 0, 0, 4, [1], 2),\n",
    "    MyEvaluator((), (len(x),30,'l','r',30,1), 0, 0, 0, 0, 5, [1], 2),\n",
    "    MyEvaluator((), (len(x),30,'l','r',30,1), 0, 0, 0, 0, 6, [1], 2),\n",
    "]\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/6/2.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66788ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [54, 57, 81, 82, 87, 89, 97, 99, 103, 111, 117, 118, 121, 122, 137, 146, 181, 196, 203, 206, 227, 231, 246, 251, 293, 311, 357, 371, 373, 374, 377, 382, 390, 402, 405, 426, 442, 447, 451, 452, 455, 463, 469, 486, 536]\n",
      "{'Learners': 1, 'Environments': 1500, 'Interactions': 27000}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, trn, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng, 'trn':trn}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,yi):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "        rng_order = rng.shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()\n",
    "        Y = self.train_Y[:,yi]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_order))\n",
    "        Y = list(map(Y.__getitem__,rng_order))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        def choose_unique(items,given_i):\n",
    "            if len(items) == 1:  return items[0]\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                if i != given_i:\n",
    "                    return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            add_to_index = (indexes := set()).add if len(items) > n else (indexes := []).append\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                add_to_index(i)\n",
    "                if len(indexes)==n:\n",
    "                    return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],i))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for i in range(len(X)):\n",
    "                    x,y = X[i],Y[i]\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],i))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s1, s2, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, y, n_models):\n",
    "\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "        self.n_models = n_models\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = { 's1': s1, 's2':s2, 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'y': y, 'n_models': n_models}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        mods_opts = []\n",
    "        opts = []\n",
    "\n",
    "        for _ in range(self.n_models):\n",
    "            s1 = FeedForward(self.s1)\n",
    "            s2 = FeedForward(self.s2)\n",
    "            sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "            s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "            s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "            sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "            s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "\n",
    "            mods = [s1,sb,s2]\n",
    "            opts = [s1opt,sbopt,s2opt]\n",
    "            mods_opts.append([mods,opts])\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.train()\n",
    "\n",
    "        for mods,opts in mods_opts:\n",
    "            [s1,sb,s2] = mods\n",
    "            [s1opt,sbopt,s2opt] = opts\n",
    "\n",
    "            if self.ssl_samps:\n",
    "\n",
    "                if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "                if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "                for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                    torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                    torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                    for _A, _P, _N in torch_loader:\n",
    "                        #https://arxiv.org/pdf/2002.05709\n",
    "                        _A = sb(s1(_A.nan_to_num()))\n",
    "                        _P = sb(s1(_P.nan_to_num()))\n",
    "                        _N = sb(s1(_N.nan_to_num()))\n",
    "\n",
    "                        p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                        n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                        p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                        n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                        p = torch.exp(p/self.ssl_tau)\n",
    "                        n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if sbopt: sbopt.zero_grad()\n",
    "                        (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                        if s1opt: s1opt.step()\n",
    "                        if sbopt: sbopt.step()\n",
    "\n",
    "            if self.ws_steps:\n",
    "\n",
    "                if s1opt: s1opt.zero_grad()\n",
    "                if s2opt: s2opt.zero_grad()\n",
    "\n",
    "                X, Y = env.train()\n",
    "                Y = Y[:,self.y]\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                loss = torch.nn.BCEWithLogitsLoss()\n",
    "                for _ in range(self.ws_steps):\n",
    "                    for _X,_y in torch_loader:\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if s2opt: s2opt.zero_grad()\n",
    "                        loss(s2(s1(_X.nan_to_num())),_y).backward()\n",
    "                        if s2opt: s2opt.step()\n",
    "                        if s1opt: s1opt.step()\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.eval()\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        def predict(X):\n",
    "            preds = 0\n",
    "            for mods, _ in mods_opts:\n",
    "                [s1,_,s2] = mods\n",
    "                preds += torch.sigmoid(s2(s1(X.nan_to_num())))\n",
    "            return preds/len(mods_opts)\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X)[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X, Y)\n",
    "        yield score(X, Y)\n",
    "\n",
    "def make_envs(X, Y, G, R):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "\n",
    "    too_short = set(g for g in set(G.tolist()) if (g==G).sum() < 50)\n",
    "    all_equal = set(g for g in set(G.tolist()) if any(len(set(y.tolist()))==1 for y in Y[g==G].T))\n",
    "\n",
    "    if any(all_equal): print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    for rng,g in product(range(R),sorted(set(G.tolist())-all_equal-too_short)):\n",
    "        _X, _Y = X[g==G], Y[g==G]\n",
    "        try:\n",
    "            trn,tst = next(StratifiedShuffleSplit(1,train_size=35/len(_X),random_state=rng).split(_X,_Y))\n",
    "\n",
    "            yield MyEnvironment( X[g==G][trn], Y[g==G][trn], X[g==G][tst], Y[g==G][tst], 'self', g, rng)\n",
    "\n",
    "        except ValueError as e:\n",
    "            if 'The least populated class in y has only 1 member' in str(e): continue\n",
    "            raise\n",
    "\n",
    "lrns = [ None ]\n",
    "envs = list(make_envs(X3,np.hstack([Y1,Y2]),G,10))\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((), (len(x),30,'l','r',30,1), 0, 0, 0, 0, 4, [1], 2),\n",
    "    MyEvaluator((len(x),30,'l','r'), (30,1), 1, 1, 0, 1, 4, [1], 2),\n",
    "    MyEvaluator((len(x),30,'l','r'), (30,1), 2, 1, 0, 1, 4, [1], 2),\n",
    "    MyEvaluator((len(x),30,'l','r'), (30,1), 1, 2, 0, 1, 4, [1], 2),\n",
    "    MyEvaluator((len(x),30,'l','r'), (30,1), 2, 2, 0, 1, 4, [1], 2),\n",
    "    MyEvaluator((len(x),30,'l','r'), (30,1), 1, 1, 0, .5, 4, [1], 2),\n",
    "    MyEvaluator((len(x),30,'l','r'), (30,1), 2, 1, 0, .5, 4, [1], 2),\n",
    "    MyEvaluator((len(x),30,'l','r'), (30,1), 1, 2, 0, .5, 4, [1], 2),\n",
    "    MyEvaluator((len(x),30,'l','r'), (30,1), 2, 2, 0, .5, 4, [1], 2),\n",
    "]\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/6/3.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e4baede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [54, 57, 81, 82, 87, 89, 97, 99, 103, 111, 117, 118, 121, 122, 137, 146, 181, 196, 203, 206, 227, 231, 246, 251, 293, 311, 357, 371, 373, 374, 377, 382, 390, 402, 405, 426, 442, 447, 451, 452, 455, 463, 469, 486, 536]\n",
      "{'Learners': 1, 'Environments': 750, 'Interactions': 6000}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, trn, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng, 'trn':trn}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,yi):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "        rng_order = rng.shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()\n",
    "        Y = self.train_Y[:,yi]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_order))\n",
    "        Y = list(map(Y.__getitem__,rng_order))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        def choose_unique(items,given_i):\n",
    "            if len(items) == 1:  return items[0]\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                if i != given_i:\n",
    "                    return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            add_to_index = (indexes := set()).add if len(items) > n else (indexes := []).append\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                add_to_index(i)\n",
    "                if len(indexes)==n:\n",
    "                    return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],i))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for i in range(len(X)):\n",
    "                    x,y = X[i],Y[i]\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],i))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s1, s2, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, y, n_models):\n",
    "\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "        self.n_models = n_models\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = { 's1': s1, 's2':s2, 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'y': y, 'n_models': n_models}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        mods_opts = []\n",
    "        opts = []\n",
    "\n",
    "        for _ in range(self.n_models):\n",
    "            s1 = FeedForward(self.s1)\n",
    "            s2 = FeedForward(self.s2)\n",
    "            sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "            s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "            s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "            sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "            s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "\n",
    "            mods = [s1,sb,s2]\n",
    "            opts = [s1opt,sbopt,s2opt]\n",
    "            mods_opts.append([mods,opts])\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.train()\n",
    "\n",
    "        for mods,opts in mods_opts:\n",
    "            [s1,sb,s2] = mods\n",
    "            [s1opt,sbopt,s2opt] = opts\n",
    "\n",
    "            if self.ssl_samps:\n",
    "\n",
    "                if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "                if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "                for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                    torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                    torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                    for _A, _P, _N in torch_loader:\n",
    "                        #https://arxiv.org/pdf/2002.05709\n",
    "                        _A = sb(s1(_A.nan_to_num()))\n",
    "                        _P = sb(s1(_P.nan_to_num()))\n",
    "                        _N = sb(s1(_N.nan_to_num()))\n",
    "\n",
    "                        p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                        n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                        p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                        n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                        p = torch.exp(p/self.ssl_tau)\n",
    "                        n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if sbopt: sbopt.zero_grad()\n",
    "                        (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                        if s1opt: s1opt.step()\n",
    "                        if sbopt: sbopt.step()\n",
    "\n",
    "            if self.ws_steps:\n",
    "\n",
    "                if s1opt: s1opt.zero_grad()\n",
    "                if s2opt: s2opt.zero_grad()\n",
    "\n",
    "                X, Y = env.train()\n",
    "                Y = Y[:,self.y]\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                loss = torch.nn.BCEWithLogitsLoss()\n",
    "                for _ in range(self.ws_steps):\n",
    "                    for _X,_y in torch_loader:\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if s2opt: s2opt.zero_grad()\n",
    "                        loss(s2(s1(_X.nan_to_num())),_y).backward()\n",
    "                        if s2opt: s2opt.step()\n",
    "                        if s1opt: s1opt.step()\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.eval()\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        def predict(X):\n",
    "            preds = 0\n",
    "            for mods, _ in mods_opts:\n",
    "                [s1,_,s2] = mods\n",
    "                preds += torch.sigmoid(s2(s1(X.nan_to_num())))\n",
    "            return preds/len(mods_opts)\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X)[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X, Y)\n",
    "        yield score(X, Y)\n",
    "\n",
    "def make_envs(X, Y, G, R):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "\n",
    "    too_short = set(g for g in set(G.tolist()) if (g==G).sum() < 50)\n",
    "    all_equal = set(g for g in set(G.tolist()) if any(len(set(y.tolist()))==1 for y in Y[g==G].T))\n",
    "\n",
    "    if any(all_equal): print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    for rng,g in product(range(R),sorted(set(G.tolist())-all_equal-too_short)):\n",
    "        _X, _Y = X[g==G], Y[g==G]\n",
    "        try:\n",
    "            trn,tst = next(StratifiedShuffleSplit(1,train_size=35/len(_X),random_state=rng).split(_X,_Y))\n",
    "\n",
    "            yield MyEnvironment( X[g==G][trn], Y[g==G][trn], X[g==G][tst], Y[g==G][tst], 'self', g, rng)\n",
    "\n",
    "        except ValueError as e:\n",
    "            if 'The least populated class in y has only 1 member' in str(e): continue\n",
    "            raise\n",
    "\n",
    "w = 45\n",
    "\n",
    "lrns = [ None ]\n",
    "envs = list(make_envs(X3,np.hstack([Y1,Y2]),G,5))\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((), (len(x),w,'l','r',w,1), 0, 0, 0, 0, 4, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r'), (w,1), 1, 1, 0, .5, 4, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r'), (w,1), 2, 1, 0, .5, 4, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r'), (w,1), 1, 2, 0, .5, 4, [1], 2),\n",
    "]\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/6/4.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4beb418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [54, 57, 81, 82, 87, 89, 97, 99, 103, 111, 117, 118, 121, 122, 137, 146, 181, 196, 203, 206, 227, 231, 246, 251, 293, 311, 357, 371, 373, 374, 377, 382, 390, 402, 405, 426, 442, 447, 451, 452, 455, 463, 469, 486, 536]\n",
      "{'Learners': 1, 'Environments': 750, 'Interactions': 16500}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, trn, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng, 'trn':trn}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,yi):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "        rng_order = rng.shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()\n",
    "        Y = self.train_Y[:,yi]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_order))\n",
    "        Y = list(map(Y.__getitem__,rng_order))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        def choose_unique(items,given_i):\n",
    "            if len(items) == 1:  return items[0]\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                if i != given_i:\n",
    "                    return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            add_to_index = (indexes := set()).add if len(items) > n else (indexes := []).append\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                add_to_index(i)\n",
    "                if len(indexes)==n:\n",
    "                    return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],i))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for i in range(len(X)):\n",
    "                    x,y = X[i],Y[i]\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],i))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s1, s2, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, y, n_models):\n",
    "\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "        self.n_models = n_models\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = { 's1': s1, 's2':s2, 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'y': y, 'n_models': n_models}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        mods_opts = []\n",
    "        opts = []\n",
    "\n",
    "        for _ in range(self.n_models):\n",
    "            s1 = FeedForward(self.s1)\n",
    "            s2 = FeedForward(self.s2)\n",
    "            sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "            s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "            s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "            sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "            s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "\n",
    "            mods = [s1,sb,s2]\n",
    "            opts = [s1opt,sbopt,s2opt]\n",
    "            mods_opts.append([mods,opts])\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.train()\n",
    "\n",
    "        for mods,opts in mods_opts:\n",
    "            [s1,sb,s2] = mods\n",
    "            [s1opt,sbopt,s2opt] = opts\n",
    "\n",
    "            if self.ssl_samps:\n",
    "\n",
    "                if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "                if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "                for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                    torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                    torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                    for _A, _P, _N in torch_loader:\n",
    "                        #https://arxiv.org/pdf/2002.05709\n",
    "                        _A = sb(s1(_A.nan_to_num()))\n",
    "                        _P = sb(s1(_P.nan_to_num()))\n",
    "                        _N = sb(s1(_N.nan_to_num()))\n",
    "\n",
    "                        p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                        n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                        p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                        n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                        p = torch.exp(p/self.ssl_tau)\n",
    "                        n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if sbopt: sbopt.zero_grad()\n",
    "                        (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                        if s1opt: s1opt.step()\n",
    "                        if sbopt: sbopt.step()\n",
    "\n",
    "            if self.ws_steps:\n",
    "\n",
    "                if s1opt: s1opt.zero_grad()\n",
    "                if s2opt: s2opt.zero_grad()\n",
    "\n",
    "                X, Y = env.train()\n",
    "                Y = Y[:,self.y]\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                loss = torch.nn.BCEWithLogitsLoss()\n",
    "                for _ in range(self.ws_steps):\n",
    "                    for _X,_y in torch_loader:\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if s2opt: s2opt.zero_grad()\n",
    "                        loss(s2(s1(_X.nan_to_num())),_y).backward()\n",
    "                        if s2opt: s2opt.step()\n",
    "                        if s1opt: s1opt.step()\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.eval()\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        def predict(X):\n",
    "            preds = 0\n",
    "            for mods, _ in mods_opts:\n",
    "                [s1,_,s2] = mods\n",
    "                preds += torch.sigmoid(s2(s1(X.nan_to_num())))\n",
    "            return preds/len(mods_opts)\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X)[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X, Y)\n",
    "        yield score(X, Y)\n",
    "\n",
    "def make_envs(X, Y, G, R):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "\n",
    "    too_short = set(g for g in set(G.tolist()) if (g==G).sum() < 50)\n",
    "    all_equal = set(g for g in set(G.tolist()) if any(len(set(y.tolist()))==1 for y in Y[g==G].T))\n",
    "\n",
    "    if any(all_equal): print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    for rng,g in product(range(R),sorted(set(G.tolist())-all_equal-too_short)):\n",
    "        _X, _Y = X[g==G], Y[g==G]\n",
    "        try:\n",
    "            trn,tst = next(StratifiedShuffleSplit(1,train_size=35/len(_X),random_state=rng).split(_X,_Y))\n",
    "\n",
    "            yield MyEnvironment( X[g==G][trn], Y[g==G][trn], X[g==G][tst], Y[g==G][tst], 'self', g, rng)\n",
    "\n",
    "        except ValueError as e:\n",
    "            if 'The least populated class in y has only 1 member' in str(e): continue\n",
    "            raise\n",
    "\n",
    "w = 45\n",
    "\n",
    "lrns = [ None ]\n",
    "envs = list(make_envs(X3,np.hstack([Y1,Y2]),G,5))\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((), (len(x),w,'l','r',w,'l','r',w,1), 0, 0, 0, 0, 4, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r'), (w,1), 1, 1, 0, .5, 4, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r'), (w,1), 2, 1, 0, .5, 4, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r'), (w,1), 1, 2, 0, .5, 4, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r'), (w,1), 1, 2, 3, .5, 4, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r'), (w,1), 1, 2, 0, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r'), (w,1), 1, 2, 3, .5, 2, [1], 2),\n",
    "    MyEvaluator((), (len(x),w,'l','r',w,'l','r',w,1), 0, 0, 0, 0, 3, [1], 2),\n",
    "    MyEvaluator((), (len(x),w,'l','r',w,'l','r',w,1), 0, 0, 0, 0, 2, [1], 2),\n",
    "    MyEvaluator((), (len(x),w,'l','r',w,'l','r',w,1), 0, 0, 0, 0, 1, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r'), (w,1), 1, 2, 0, .5, 1, [1], 2),\n",
    "]\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/6/5.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13e7e75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [54, 57, 81, 82, 87, 89, 97, 99, 103, 111, 117, 118, 121, 122, 137, 146, 181, 196, 203, 206, 227, 231, 246, 251, 293, 311, 357, 371, 373, 374, 377, 382, 390, 402, 405, 426, 442, 447, 451, 452, 455, 463, 469, 486, 536]\n",
      "{'Learners': 1, 'Environments': 750, 'Interactions': 6000}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, trn, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng, 'trn':trn}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,yi):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "        rng_order = rng.shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()\n",
    "        Y = self.train_Y[:,yi]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_order))\n",
    "        Y = list(map(Y.__getitem__,rng_order))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        def choose_unique(items,given_i):\n",
    "            if len(items) == 1:  return items[0]\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                if i != given_i:\n",
    "                    return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            add_to_index = (indexes := set()).add if len(items) > n else (indexes := []).append\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                add_to_index(i)\n",
    "                if len(indexes)==n:\n",
    "                    return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],i))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for i in range(len(X)):\n",
    "                    x,y = X[i],Y[i]\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],i))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s1, s2, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, y, n_models):\n",
    "\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "        self.n_models = n_models\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = { 's1': s1, 's2':s2, 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'y': y, 'n_models': n_models}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        mods_opts = []\n",
    "        opts = []\n",
    "\n",
    "        for _ in range(self.n_models):\n",
    "            s1 = FeedForward(self.s1)\n",
    "            s2 = FeedForward(self.s2)\n",
    "            sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "            s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "            s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "            sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "            s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "\n",
    "            mods = [s1,sb,s2]\n",
    "            opts = [s1opt,sbopt,s2opt]\n",
    "            mods_opts.append([mods,opts])\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.train()\n",
    "\n",
    "        for mods,opts in mods_opts:\n",
    "            [s1,sb,s2] = mods\n",
    "            [s1opt,sbopt,s2opt] = opts\n",
    "\n",
    "            if self.ssl_samps:\n",
    "\n",
    "                if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "                if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "                for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                    torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                    torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                    for _A, _P, _N in torch_loader:\n",
    "                        #https://arxiv.org/pdf/2002.05709\n",
    "                        _A = sb(s1(_A.nan_to_num()))\n",
    "                        _P = sb(s1(_P.nan_to_num()))\n",
    "                        _N = sb(s1(_N.nan_to_num()))\n",
    "\n",
    "                        p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                        n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                        p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                        n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                        p = torch.exp(p/self.ssl_tau)\n",
    "                        n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if sbopt: sbopt.zero_grad()\n",
    "                        (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                        if s1opt: s1opt.step()\n",
    "                        if sbopt: sbopt.step()\n",
    "\n",
    "            if self.ws_steps:\n",
    "\n",
    "                if s1opt: s1opt.zero_grad()\n",
    "                if s2opt: s2opt.zero_grad()\n",
    "\n",
    "                X, Y = env.train()\n",
    "                Y = Y[:,self.y]\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                loss = torch.nn.BCEWithLogitsLoss()\n",
    "                for _ in range(self.ws_steps):\n",
    "                    for _X,_y in torch_loader:\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if s2opt: s2opt.zero_grad()\n",
    "                        loss(s2(s1(_X.nan_to_num())),_y).backward()\n",
    "                        if s2opt: s2opt.step()\n",
    "                        if s1opt: s1opt.step()\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.eval()\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        def predict(X):\n",
    "            preds = 0\n",
    "            for mods, _ in mods_opts:\n",
    "                [s1,_,s2] = mods\n",
    "                preds += torch.sigmoid(s2(s1(X.nan_to_num())))\n",
    "            return preds/len(mods_opts)\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X)[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X, Y)\n",
    "        yield score(X, Y)\n",
    "\n",
    "def make_envs(X, Y, G, R):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "\n",
    "    too_short = set(g for g in set(G.tolist()) if (g==G).sum() < 50)\n",
    "    all_equal = set(g for g in set(G.tolist()) if any(len(set(y.tolist()))==1 for y in Y[g==G].T))\n",
    "\n",
    "    if any(all_equal): print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    for rng,g in product(range(R),sorted(set(G.tolist())-all_equal-too_short)):\n",
    "        _X, _Y = X[g==G], Y[g==G]\n",
    "        try:\n",
    "            trn,tst = next(StratifiedShuffleSplit(1,train_size=35/len(_X),random_state=rng).split(_X,_Y))\n",
    "\n",
    "            yield MyEnvironment( X[g==G][trn], Y[g==G][trn], X[g==G][tst], Y[g==G][tst], 'self', g, rng)\n",
    "\n",
    "        except ValueError as e:\n",
    "            if 'The least populated class in y has only 1 member' in str(e): continue\n",
    "            raise\n",
    "\n",
    "w = 45\n",
    "\n",
    "lrns = [ None ]\n",
    "envs = list(make_envs(X3,np.hstack([Y1,Y2]),G,5))\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r'), (w,1), 1, 2, 0, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r'), (w,1), 1, 2, 0, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r',w,'l','r'), (w,1), 1, 2, 0, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r',w,'l','r',w,'l','r'), (w,1), 1, 2, 0, .5, 2, [1], 2),\n",
    "]\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/6/6.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b235f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [54, 57, 81, 82, 87, 89, 97, 99, 103, 111, 117, 118, 121, 122, 137, 146, 181, 196, 203, 206, 227, 231, 246, 251, 293, 311, 357, 371, 373, 374, 377, 382, 390, 402, 405, 426, 442, 447, 451, 452, 455, 463, 469, 486, 536]\n",
      "{'Learners': 1, 'Environments': 750, 'Interactions': 18000}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, trn, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng, 'trn':trn}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,yi):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "        rng_order = rng.shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()\n",
    "        Y = self.train_Y[:,yi]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_order))\n",
    "        Y = list(map(Y.__getitem__,rng_order))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        def choose_unique(items,given_i):\n",
    "            if len(items) == 1:  return items[0]\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                if i != given_i:\n",
    "                    return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            add_to_index = (indexes := set()).add if len(items) > n else (indexes := []).append\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                add_to_index(i)\n",
    "                if len(indexes)==n:\n",
    "                    return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],i))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for i in range(len(X)):\n",
    "                    x,y = X[i],Y[i]\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],i))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s1, s2, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, y, n_models):\n",
    "\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "        self.n_models = n_models\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = { 's1': s1, 's2':s2, 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'y': y, 'n_models': n_models}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        mods_opts = []\n",
    "        opts = []\n",
    "\n",
    "        for _ in range(self.n_models):\n",
    "            s1 = FeedForward(self.s1)\n",
    "            s2 = FeedForward(self.s2)\n",
    "            sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "            s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "            s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "            sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "            s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "\n",
    "            mods = [s1,sb,s2]\n",
    "            opts = [s1opt,sbopt,s2opt]\n",
    "            mods_opts.append([mods,opts])\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.train()\n",
    "\n",
    "        for mods,opts in mods_opts:\n",
    "            [s1,sb,s2] = mods\n",
    "            [s1opt,sbopt,s2opt] = opts\n",
    "\n",
    "            if self.ssl_samps:\n",
    "\n",
    "                if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "                if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "                for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                    torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                    torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                    for _A, _P, _N in torch_loader:\n",
    "                        #https://arxiv.org/pdf/2002.05709\n",
    "                        _A = sb(s1(_A.nan_to_num()))\n",
    "                        _P = sb(s1(_P.nan_to_num()))\n",
    "                        _N = sb(s1(_N.nan_to_num()))\n",
    "\n",
    "                        p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                        n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                        p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                        n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                        p = torch.exp(p/self.ssl_tau)\n",
    "                        n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if sbopt: sbopt.zero_grad()\n",
    "                        (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                        if s1opt: s1opt.step()\n",
    "                        if sbopt: sbopt.step()\n",
    "\n",
    "            if self.ws_steps:\n",
    "\n",
    "                if s1opt: s1opt.zero_grad()\n",
    "                if s2opt: s2opt.zero_grad()\n",
    "\n",
    "                X, Y = env.train()\n",
    "                Y = Y[:,self.y]\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                loss = torch.nn.BCEWithLogitsLoss()\n",
    "                for _ in range(self.ws_steps):\n",
    "                    for _X,_y in torch_loader:\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if s2opt: s2opt.zero_grad()\n",
    "                        loss(s2(s1(_X.nan_to_num())),_y).backward()\n",
    "                        if s2opt: s2opt.step()\n",
    "                        if s1opt: s1opt.step()\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.eval()\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        def predict(X):\n",
    "            preds = 0\n",
    "            for mods, _ in mods_opts:\n",
    "                [s1,_,s2] = mods\n",
    "                preds += torch.sigmoid(s2(s1(X.nan_to_num())))\n",
    "            return preds/len(mods_opts)\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X)[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X, Y)\n",
    "        yield score(X, Y)\n",
    "\n",
    "def make_envs(X, Y, G, R):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "\n",
    "    too_short = set(g for g in set(G.tolist()) if (g==G).sum() < 50)\n",
    "    all_equal = set(g for g in set(G.tolist()) if any(len(set(y.tolist()))==1 for y in Y[g==G].T))\n",
    "\n",
    "    if any(all_equal): print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    for rng,g in product(range(R),sorted(set(G.tolist())-all_equal-too_short)):\n",
    "        _X, _Y = X[g==G], Y[g==G]\n",
    "        try:\n",
    "            trn,tst = next(StratifiedShuffleSplit(1,train_size=35/len(_X),random_state=rng).split(_X,_Y))\n",
    "\n",
    "            yield MyEnvironment( X[g==G][trn], Y[g==G][trn], X[g==G][tst], Y[g==G][tst], 'self', g, rng)\n",
    "\n",
    "        except ValueError as e:\n",
    "            if 'The least populated class in y has only 1 member' in str(e): continue\n",
    "            raise\n",
    "\n",
    "w = 45\n",
    "\n",
    "lrns = [ None ]\n",
    "envs = list(make_envs(X3,np.hstack([Y1,Y2]),G,5))\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r'), (w,1), 1, 2, 0, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r'), (w,1), 2, 2, 0, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r'), (w,1), 2, 2, 0, .75, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r'), (w,1), 2, 2, 3, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r'), (w,1), 1, 2, 3, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r'), (w,1), 1, 2, 6, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r'), (w,1), 1, 2, 0, .25, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r'), (w,1), 1, 2, 6, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),.2,w,'l','r',w,'l','r',w,'l','r'), (w,1), 1, 2, 6, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),.2,w,'l','r',w,'l','r',w,'l','r'), (w,1), 1, 2, 6, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r',w,1), (), 1, 2, 0, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r',1), (), 1, 2, 0, .5, 2, [1], 2),\n",
    "]\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/6/7.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1cc1a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [54, 57, 81, 82, 87, 89, 97, 99, 103, 111, 117, 118, 121, 122, 137, 146, 181, 196, 203, 206, 227, 231, 246, 251, 293, 311, 357, 371, 373, 374, 377, 382, 390, 402, 405, 426, 442, 447, 451, 452, 455, 463, 469, 486, 536]\n",
      "{'Learners': 1, 'Environments': 750, 'Interactions': 6000}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, trn, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng, 'trn':trn}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,yi):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "        rng_order = rng.shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()\n",
    "        Y = self.train_Y[:,yi]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_order))\n",
    "        Y = list(map(Y.__getitem__,rng_order))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        def choose_unique(items,given_i):\n",
    "            if len(items) == 1:  return items[0]\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                if i != given_i:\n",
    "                    return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            add_to_index = (indexes := set()).add if len(items) > n else (indexes := []).append\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                add_to_index(i)\n",
    "                if len(indexes)==n:\n",
    "                    return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],i))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for i in range(len(X)):\n",
    "                    x,y = X[i],Y[i]\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],i))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s1, s2, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, y, n_models):\n",
    "\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "        self.n_models = n_models\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = { 's1': s1, 's2':s2, 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'y': y, 'n_models': n_models}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        mods_opts = []\n",
    "        opts = []\n",
    "\n",
    "        for _ in range(self.n_models):\n",
    "            s1 = FeedForward(self.s1)\n",
    "            s2 = FeedForward(self.s2)\n",
    "            sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "            s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "            s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "            sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "            s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "\n",
    "            mods = [s1,sb,s2]\n",
    "            opts = [s1opt,sbopt,s2opt]\n",
    "            mods_opts.append([mods,opts])\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.train()\n",
    "\n",
    "        for mods,opts in mods_opts:\n",
    "            [s1,sb,s2] = mods\n",
    "            [s1opt,sbopt,s2opt] = opts\n",
    "\n",
    "            if self.ssl_samps:\n",
    "\n",
    "                if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "                if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "                for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                    torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                    torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                    for _A, _P, _N in torch_loader:\n",
    "                        #https://arxiv.org/pdf/2002.05709\n",
    "                        _A = sb(s1(_A.nan_to_num()))\n",
    "                        _P = sb(s1(_P.nan_to_num()))\n",
    "                        _N = sb(s1(_N.nan_to_num()))\n",
    "\n",
    "                        p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                        n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                        p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                        n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                        p = torch.exp(p/self.ssl_tau)\n",
    "                        n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if sbopt: sbopt.zero_grad()\n",
    "                        (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                        if s1opt: s1opt.step()\n",
    "                        if sbopt: sbopt.step()\n",
    "\n",
    "            if self.ws_steps:\n",
    "\n",
    "                if s1opt: s1opt.zero_grad()\n",
    "                if s2opt: s2opt.zero_grad()\n",
    "\n",
    "                X, Y = env.train()\n",
    "                Y = Y[:,self.y]\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                loss = torch.nn.BCEWithLogitsLoss()\n",
    "                for _ in range(self.ws_steps):\n",
    "                    for _X,_y in torch_loader:\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if s2opt: s2opt.zero_grad()\n",
    "                        loss(s2(s1(_X.nan_to_num())),_y).backward()\n",
    "                        if s2opt: s2opt.step()\n",
    "                        if s1opt: s1opt.step()\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.eval()\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        def predict(X):\n",
    "            preds = 0\n",
    "            for mods, _ in mods_opts:\n",
    "                [s1,_,s2] = mods\n",
    "                preds += torch.sigmoid(s2(s1(X.nan_to_num())))\n",
    "            return preds/len(mods_opts)\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X)[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X, Y)\n",
    "        yield score(X, Y)\n",
    "\n",
    "def make_envs(X, Y, G, R):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "\n",
    "    too_short = set(g for g in set(G.tolist()) if (g==G).sum() < 50)\n",
    "    all_equal = set(g for g in set(G.tolist()) if any(len(set(y.tolist()))==1 for y in Y[g==G].T))\n",
    "\n",
    "    if any(all_equal): print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    for rng,g in product(range(R),sorted(set(G.tolist())-all_equal-too_short)):\n",
    "        _X, _Y = X[g==G], Y[g==G]\n",
    "        try:\n",
    "            trn,tst = next(StratifiedShuffleSplit(1,train_size=35/len(_X),random_state=rng).split(_X,_Y))\n",
    "\n",
    "            yield MyEnvironment( X[g==G][trn], Y[g==G][trn], X[g==G][tst], Y[g==G][tst], 'self', g, rng)\n",
    "\n",
    "        except ValueError as e:\n",
    "            if 'The least populated class in y has only 1 member' in str(e): continue\n",
    "            raise\n",
    "\n",
    "w = 45\n",
    "r = lambda w:  ['l', 'r', w, 'l', 'r', w]\n",
    "\n",
    "lrns = [ None ]\n",
    "envs = list(make_envs(X3,np.hstack([Y1,Y2]),G,5))\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r'), (w,1), 1, 2, 6, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,r(w),r(w)), (w,1), 1, 2, 0, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,r(w),r(w)), (w,1), 10, 2, 0, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,r(w),r(w)), (w,1), 10, 2, 0, 1, 2, [1], 2),\n",
    "]\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/6/8.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ba6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, trn, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng, 'trn':trn}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,yi):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "        rng_order = rng.shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()\n",
    "        Y = self.train_Y[:,yi]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_order))\n",
    "        Y = list(map(Y.__getitem__,rng_order))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        def choose_unique(items,given_i):\n",
    "            if len(items) == 1:  return items[0]\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                if i != given_i:\n",
    "                    return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            add_to_index = (indexes := set()).add if len(items) > n else (indexes := []).append\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                add_to_index(i)\n",
    "                if len(indexes)==n:\n",
    "                    return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],i))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for i in range(len(X)):\n",
    "                    x,y = X[i],Y[i]\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],i))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_X, self.train_Y\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s1, s2, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps, y, n_models):\n",
    "\n",
    "        self.s1  = s1  #ssl + sl\n",
    "        self.s2  = s2  #sl\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps = ws_steps\n",
    "        self.n_models = n_models\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = { 's1': s1, 's2':s2, 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': ws_steps, 'y': y, 'n_models': n_models}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        mods_opts = []\n",
    "        opts = []\n",
    "\n",
    "        for _ in range(self.n_models):\n",
    "            s1 = FeedForward(self.s1)\n",
    "            s2 = FeedForward(self.s2)\n",
    "            sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "            s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "            s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "            sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "            s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "\n",
    "            mods = [s1,sb,s2]\n",
    "            opts = [s1opt,sbopt,s2opt]\n",
    "            mods_opts.append([mods,opts])\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.train()\n",
    "\n",
    "        for mods,opts in mods_opts:\n",
    "            [s1,sb,s2] = mods\n",
    "            [s1opt,sbopt,s2opt] = opts\n",
    "\n",
    "            if self.ssl_samps:\n",
    "\n",
    "                if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "                if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "                for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                    torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                    torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                    for _A, _P, _N in torch_loader:\n",
    "                        #https://arxiv.org/pdf/2002.05709\n",
    "                        _A = sb(s1(_A.nan_to_num()))\n",
    "                        _P = sb(s1(_P.nan_to_num()))\n",
    "                        _N = sb(s1(_N.nan_to_num()))\n",
    "\n",
    "                        p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                        n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                        p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                        n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                        p = torch.exp(p/self.ssl_tau)\n",
    "                        n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if sbopt: sbopt.zero_grad()\n",
    "                        (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                        if s1opt: s1opt.step()\n",
    "                        if sbopt: sbopt.step()\n",
    "\n",
    "            if self.ws_steps:\n",
    "\n",
    "                if s1opt: s1opt.zero_grad()\n",
    "                if s2opt: s2opt.zero_grad()\n",
    "\n",
    "                X, Y = env.train()\n",
    "                Y = Y[:,self.y]\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                loss = torch.nn.BCEWithLogitsLoss()\n",
    "                for _ in range(self.ws_steps):\n",
    "                    for _X,_y in torch_loader:\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if s2opt: s2opt.zero_grad()\n",
    "                        loss(s2(s1(_X.nan_to_num())),_y).backward()\n",
    "                        if s2opt: s2opt.step()\n",
    "                        if s1opt: s1opt.step()\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.eval()\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        def predict(X):\n",
    "            preds = 0\n",
    "            for mods, _ in mods_opts:\n",
    "                [s1,_,s2] = mods\n",
    "                preds += torch.sigmoid(s2(s1(X.nan_to_num())))\n",
    "            return preds/len(mods_opts)\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X)[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X, Y)\n",
    "        yield score(X, Y)\n",
    "\n",
    "def make_envs(X, Y, G, R):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "\n",
    "    too_short = set(g for g in set(G.tolist()) if (g==G).sum() < 50)\n",
    "    all_equal = set(g for g in set(G.tolist()) if any(len(set(y.tolist()))==1 for y in Y[g==G].T))\n",
    "\n",
    "    if any(all_equal): print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    for rng,g in product(range(R),sorted(set(G.tolist())-all_equal-too_short)):\n",
    "        _X, _Y = X[g==G], Y[g==G]\n",
    "        try:\n",
    "            trn,tst = next(StratifiedShuffleSplit(1,train_size=35/len(_X),random_state=rng).split(_X,_Y))\n",
    "\n",
    "            yield MyEnvironment(X[g!=G], Y[g!=G], X[g==G][tst], Y[g==G][tst], 'rest', g, rng)\n",
    "\n",
    "        except ValueError as e:\n",
    "            if 'The least populated class in y has only 1 member' in str(e): continue\n",
    "            raise\n",
    "\n",
    "w = 45\n",
    "r = lambda w:  ['l', 'r', w, 'l', 'r', w]\n",
    "\n",
    "lrns = [ None ]\n",
    "envs = list(make_envs(X3,np.hstack([Y1,Y2]),G,5))\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((len(x),w,'l','r',w,'l','r',w,'l','r'), (w,1), 1, 2, 6, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,r(w),r(w)), (w,1), 1, 2, 0, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,r(w),r(w)), (w,1), 10, 2, 0, .5, 2, [1], 2),\n",
    "    MyEvaluator((len(x),w,r(w),r(w)), (w,1), 10, 2, 0, 1, 2, [1], 2),\n",
    "]\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/6/8.log',processes=35,quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e6654bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Equal, no environment added for [54, 57, 81, 82, 87, 89, 97, 99, 103, 111, 117, 118, 121, 122, 137, 146, 181, 196, 203, 206, 227, 231, 246, 251, 293, 311, 357, 371, 373, 374, 377, 382, 390, 402, 405, 426, 442, 447, 451, 452, 455, 463, 469, 486, 536]\n",
      "{'Learners': 1, 'Environments': 150, 'Interactions': 2700}\n"
     ]
    }
   ],
   "source": [
    "import coba as cb\n",
    "\n",
    "class FeedForward(torch.nn.Sequential):\n",
    "    \"\"\"A Generic implementation of Feedforward Neural Network\"\"\"\n",
    "\n",
    "    class SkipModule(torch.nn.Module):\n",
    "        def __init__(self, layers):\n",
    "            super().__init__()\n",
    "            self.layers = layers\n",
    "        def forward(self,X):\n",
    "            return X + self.layers(X)\n",
    "\n",
    "    def make_layer(self,curr_dim,spec):\n",
    "        if isinstance(spec,float):\n",
    "            return torch.nn.Dropout(spec), curr_dim\n",
    "        if curr_dim is None and isinstance(spec,int):\n",
    "            return None, spec\n",
    "        if isinstance(spec,int):\n",
    "            return torch.nn.Linear(curr_dim,spec),spec\n",
    "        if spec == 'r':\n",
    "            return torch.nn.ReLU(),curr_dim\n",
    "        if spec == 'l':\n",
    "            return torch.nn.LayerNorm(curr_dim),curr_dim\n",
    "        if spec == 'b':\n",
    "            return torch.nn.BatchNorm1d(curr_dim), curr_dim\n",
    "        if spec == 's':\n",
    "            return torch.nn.Sigmoid(),curr_dim\n",
    "        if isinstance(spec,list):                \n",
    "            return FeedForward.SkipModule(FeedForward([curr_dim] + spec)), curr_dim\n",
    "        raise Exception(\"Bad Layer\")\n",
    "\n",
    "    def __init__(self, specs, rng=1):\n",
    "        \"\"\"Instantiate a Feedfoward network according to specifications.\n",
    "\n",
    "        Args:\n",
    "            specs: A sequence of layer specifications as follows:\n",
    "                -1 -- replaced with the input feature width\n",
    "                <int> -- a LinearLayer with output width equal to <int>\n",
    "                [0,1] -- a Dropout layer with the given probability\n",
    "                'l' -- a LayerNorm\n",
    "                'b' -- a BatchNorm1d\n",
    "                'r' -- a ReLU layer\n",
    "                's' -- a Sigmoid layer\n",
    "                [] -- a skip layer with the given specifications\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(rng)\n",
    "        layers,width = [],None\n",
    "        for spec in specs:\n",
    "            layer,width = self.make_layer(width,spec)\n",
    "            if layer: layers.append(layer)\n",
    "        super().__init__(*(layers or [torch.nn.Identity()]))\n",
    "        self.params = {\"specs\": specs, \"rng\": rng }\n",
    "\n",
    "class MyEnvironment:\n",
    "    def __init__(self, train_X, train_Y, train_G, test_X, test_Y, trn, g, rng):\n",
    "        self.params = {'pid': g, 'rng': rng, 'trn':trn}\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y.float()\n",
    "        self.train_G = train_G\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y.float()\n",
    "\n",
    "    def ssl(self,neg,sr,yi):\n",
    "        from itertools import compress, repeat, chain\n",
    "        from operator import eq\n",
    "\n",
    "        rng = cb.CobaRandom(self.params['rng'])\n",
    "        rng_order = rng.shuffle(range(len(self.train_X)))\n",
    "\n",
    "        X = self.train_X.tolist()\n",
    "        Y = self.train_Y[:,yi]\n",
    "        Y = list(map(tuple,Y.tolist()))\n",
    "\n",
    "        X = list(map(X.__getitem__,rng_order))\n",
    "        Y = list(map(Y.__getitem__,rng_order))\n",
    "\n",
    "        eq_class  = {y: list(compress(X,map(eq,Y,repeat(y)))) for y in set(Y)}\n",
    "        ne_class  = {y: list(chain(*[v for k,v in eq_class.items() if k != y ])) for y in set(Y)}\n",
    "\n",
    "        def choose_unique(items,given_i):\n",
    "            if len(items) == 1:  return items[0]\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                if i != given_i:\n",
    "                    return items[i]\n",
    "\n",
    "        def choose_n(items,n):\n",
    "            add_to_index = (indexes := set()).add if len(items) > n else (indexes := []).append\n",
    "            for i in rng.randints(None,0,len(items)-1):\n",
    "                add_to_index(i)\n",
    "                if len(indexes)==n:\n",
    "                    return [items[i] for i in indexes]\n",
    "\n",
    "        if sr < 1:\n",
    "            anchor, positive, negative = [], [], []\n",
    "\n",
    "            for i in range(int(len(X)*sr)):\n",
    "                x,y = X[i],Y[i]\n",
    "                anchor.append(x)\n",
    "                positive.append(choose_unique(eq_class[y],i))\n",
    "                negative.append(choose_n     (ne_class[y],neg))\n",
    "            yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "        else:\n",
    "            for _ in range(sr):\n",
    "                anchor, positive, negative = [], [], []\n",
    "                for i in range(len(X)):\n",
    "                    x,y = X[i],Y[i]\n",
    "                    anchor.append(x)\n",
    "                    positive.append(choose_unique(eq_class[y],i))\n",
    "                    negative.append(choose_n     (ne_class[y],neg))\n",
    "\n",
    "                yield torch.tensor(anchor).float(), torch.tensor(positive).float(), torch.tensor(negative).float()\n",
    "\n",
    "    def train(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.train_X)))\n",
    "        return self.train_X[rng_indexes,:], self.train_Y[rng_indexes,:], self.train_G[rng_indexes]\n",
    "\n",
    "    def test(self):\n",
    "        rng_indexes = cb.CobaRandom(self.params['rng']).shuffle(range(len(self.test_X)))\n",
    "        return self.test_X[rng_indexes,:], self.test_Y[rng_indexes]\n",
    "\n",
    "class MyEvaluator:\n",
    "    def __init__(self, s1, s2, s3, ssl_samps, ssl_neg, ssl_dropn, ssl_tau, ws_steps0, ws_steps1, y, n_models):\n",
    "\n",
    "        self.s1  = s1  #ssl sl\n",
    "        self.s2  = s2  #    sl\n",
    "        self.s3  = s3  #    sl pers\n",
    "\n",
    "        self.ssl_samps = ssl_samps\n",
    "        self.ssl_neg   = ssl_neg\n",
    "        self.ssl_tau   = ssl_tau\n",
    "        self.ssl_dropn = ssl_dropn\n",
    "\n",
    "        self.ws_steps0 = ws_steps0\n",
    "        self.ws_steps1 = ws_steps1\n",
    "        self.n_models  = n_models\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "        self.params = { 's1': s1, 's2':s2, 's3':s3, 'ssl': (ssl_samps,ssl_neg,ssl_dropn,ssl_tau), 'ws': (ws_steps0,ws_steps1), 'y': y, 'n_models': n_models}\n",
    "\n",
    "    def evaluate(self, env, lrn):\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        mods_opts = []\n",
    "        opts = []\n",
    "\n",
    "        if self.ws_steps0:\n",
    "            self.s2 = (*(self.s2)[:-1], len(set(env.train()[2].tolist()))*len(self.y))\n",
    "            self.s3 = (len(set(env.train()[2].tolist()))*len(self.y), *(self.s3)[1:])\n",
    "\n",
    "        for _ in range(self.n_models):\n",
    "            s1 = FeedForward(self.s1)\n",
    "            s2 = FeedForward(self.s2)\n",
    "            s3 = FeedForward(self.s3)\n",
    "            sb = torch.nn.Sequential(*list(s1.children())[len(self.s1)-self.ssl_dropn:])\n",
    "            s1 = torch.nn.Sequential(*list(s1.children())[:len(self.s1)-self.ssl_dropn])\n",
    "\n",
    "            s1opt = COCOB(s1.parameters()) if list(s1.parameters()) else None\n",
    "            sbopt = COCOB(sb.parameters()) if list(sb.parameters()) else None\n",
    "            s2opt = COCOB(s2.parameters()) if list(s2.parameters()) else None\n",
    "            s3opt = COCOB(s3.parameters()) if list(s3.parameters()) else None\n",
    "\n",
    "            mods = [s1,sb,s2,s3]\n",
    "            opts = [s1opt,sbopt,s2opt,s3opt]\n",
    "            mods_opts.append([mods,opts])\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.train()\n",
    "\n",
    "        for mods,opts in mods_opts:\n",
    "            [s1,sb,s2,s3] = mods\n",
    "            [s1opt,sbopt,s2opt,s3opt] = opts\n",
    "\n",
    "            if self.ssl_samps:\n",
    "\n",
    "                if self.ssl_neg == 0: raise Exception(\"neg can't be 0\")\n",
    "                if self.ssl_tau == 0: raise Exception(\"Tau can't be 0\")\n",
    "\n",
    "                for A, P, N in env.ssl(self.ssl_neg,self.ssl_samps,self.y):\n",
    "\n",
    "                    torch_dataset = torch.utils.data.TensorDataset(A,P,N)\n",
    "                    torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=2,drop_last=True,shuffle=True)\n",
    "\n",
    "                    for _A, _P, _N in torch_loader:\n",
    "                        #https://arxiv.org/pdf/2002.05709\n",
    "                        _A = sb(s1(_A.nan_to_num()))\n",
    "                        _P = sb(s1(_P.nan_to_num()))\n",
    "                        _N = sb(s1(_N.nan_to_num()))\n",
    "\n",
    "                        p = torch.einsum(\"bi,bi->b\",_A,_P)\n",
    "                        n = torch.einsum(\"bi,bji->bj\",_A,_N)\n",
    "\n",
    "                        p /= (torch.linalg.norm(_A,dim=1)*torch.linalg.norm(_P,dim=1))\n",
    "                        n /= (torch.linalg.norm(_A,dim=1).unsqueeze(1)*torch.linalg.norm(_N,dim=2))\n",
    "\n",
    "                        p = torch.exp(p/self.ssl_tau)\n",
    "                        n = torch.exp(n/self.ssl_tau)\n",
    "\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if sbopt: sbopt.zero_grad()\n",
    "                        (-torch.log(p/(p+n.sum(dim=1)))).mean().backward()\n",
    "                        if s1opt: s1opt.step()\n",
    "                        if sbopt: sbopt.step()\n",
    "\n",
    "            if self.ws_steps0 or self.ws_steps1:\n",
    "\n",
    "                if s1opt: s1opt.zero_grad()\n",
    "                if s2opt: s2opt.zero_grad()\n",
    "                if s3opt: s3opt.zero_grad()\n",
    "\n",
    "                X, Y, G = env.train()\n",
    "                Y = Y[:,self.y]\n",
    "\n",
    "                i = defaultdict(lambda c= count(0):next(c))\n",
    "                I = torch.tensor([[i[g]] for g in G.tolist()]) + torch.arange(len(self.y)).unsqueeze(0)\n",
    "                R = torch.arange(len(Y)).unsqueeze(1)\n",
    "                Z = torch.full((len(G),len(i)*len(self.y)), float('nan'))\n",
    "                Z[R,I] = Y\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(X,Z)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=8,drop_last=True,shuffle=True)\n",
    "                \n",
    "                loss = torch.nn.BCEWithLogitsLoss()\n",
    "                for _ in range(self.ws_steps0):\n",
    "                    for _X,_z in torch_loader:\n",
    "                        if s1opt: s1opt.zero_grad()\n",
    "                        if s2opt: s2opt.zero_grad()\n",
    "                        loss(s2(s1(_X.nan_to_num()))[~_z.isnan()],_z[~_z.isnan()]).backward()\n",
    "                        if s2opt: s2opt.step()\n",
    "                        if s1opt: s1opt.step()\n",
    "\n",
    "                torch_dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "                torch_loader  = torch.utils.data.DataLoader(torch_dataset,batch_size=8,drop_last=True,shuffle=True)\n",
    "\n",
    "                loss = torch.nn.BCEWithLogitsLoss()\n",
    "                for _ in range(self.ws_steps1):\n",
    "                    for _X,_y in torch_loader:\n",
    "                        if s3opt: s3opt.zero_grad()\n",
    "                        loss(s3(s2(s1(_X.nan_to_num()))),_y).backward()\n",
    "                        if s3opt: s3opt.step()\n",
    "\n",
    "        for mods,_ in mods_opts:\n",
    "            for l in mods: l.eval()\n",
    "\n",
    "        X, Y = env.test()\n",
    "        Y = Y[:,self.y]\n",
    "\n",
    "        def predict(X):\n",
    "            preds = 0\n",
    "            for mods, _ in mods_opts:\n",
    "                [s1,_,s2,s3] = mods\n",
    "                preds += torch.sigmoid(s3(s2(s1(X.nan_to_num()))))\n",
    "            return preds/len(mods_opts)\n",
    "\n",
    "        def score(X,Y):\n",
    "            with torch.no_grad():\n",
    "                return {f'auc{y}': roc_auc_score(Y[:,i],predict(X)[:,i]) for i,y in enumerate(self.y) }\n",
    "\n",
    "        yield score(X, Y)\n",
    "        yield score(X, Y)\n",
    "\n",
    "def make_envs(X, Y, G, R):\n",
    "    X, Y, G = torch.tensor(X).float(), torch.tensor(Y).float(), torch.tensor(G)\n",
    "\n",
    "    too_short = set(g for g in set(G.tolist()) if (g==G).sum() < 50)\n",
    "    all_equal = set(g for g in set(G.tolist()) if any(len(set(y.tolist()))==1 for y in Y[g==G].T))\n",
    "\n",
    "    if any(all_equal): print(f\"All Equal, no environment added for {sorted(all_equal)}\")\n",
    "\n",
    "    for rng,g in product(range(R),sorted(set(G.tolist())-all_equal-too_short)):\n",
    "        _X, _Y = X[g==G], Y[g==G]\n",
    "        try:\n",
    "            trn,tst = next(StratifiedShuffleSplit(1,train_size=35/len(_X),random_state=rng).split(_X,_Y))\n",
    "            yield MyEnvironment(X[g!=G], Y[g!=G], G[g!=G], X[g==G][tst], Y[g==G][tst], 'rest', g, rng)\n",
    "\n",
    "        except ValueError as e:\n",
    "            if 'The least populated class in y has only 1 member' in str(e): continue\n",
    "            raise\n",
    "\n",
    "w = 45\n",
    "r = lambda w:  ['l', 'r', w, 'l', 'r', w]\n",
    "\n",
    "lrns = [ None ]\n",
    "envs = list(make_envs(X3,np.hstack([Y1,Y2]),G,1))\n",
    "vals = lambda x: [\n",
    "    MyEvaluator((), (len(x),30,'l','r',-1), (-1,1), 0, 0, 0, 0, 3, 3, [1], 1),\n",
    "    MyEvaluator((), (), (len(x),30,'l','r',30,1), 0, 0, 0, 0, 0, 3, [1], 1),\n",
    "    MyEvaluator((), (len(x),30,'l','r',-1), (-1,1), 0, 0, 0, 0, 5, 2, [1], 1),\n",
    "    MyEvaluator((), (len(x),45,'l','r',-1), (-1,1), 0, 0, 0, 0, 5, 2, [1], 1),\n",
    "    MyEvaluator((), (len(x),30,'l','r',-1), (-1,1), 0, 0, 0, 0, 5, 3, [1], 1),\n",
    "    MyEvaluator((), (len(x),45,'l','r',-1), (-1,1), 0, 0, 0, 0, 6, 2, [1], 1),\n",
    "    MyEvaluator((), (len(x),45,'l','r',-1), (-1,1), 0, 0, 0, 0, 4, 2, [1], 1),\n",
    "    MyEvaluator((), (len(x),45,'l','r',-1), (-1,1), 0, 0, 0, 0, 4, 1, [1], 1),\n",
    "    MyEvaluator((), (len(x),45,'l','r',-1), (-1,1), 0, 0, 0, 0, 5, 1, [1], 1),\n",
    "]\n",
    "\n",
    "cb.Experiment(envs,lrns,vals(X3[0])).run('../logs/6/9.log',processes=35,quiet=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
